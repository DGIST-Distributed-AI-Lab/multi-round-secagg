{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "\n",
    "from utils.sampling import mnist_iid, mnist_noniid, cifar_iid, cifar_noniid, cifar_noniid_shared\n",
    "from utils.options import args_parser\n",
    "from models.Update import LocalUpdate\n",
    "from models.Nets import MLP, CNNMnist, CNNCifar, LeNet, CNNMnist2\n",
    "from models.Fed import FedAvg\n",
    "from models.Fed import FedQAvg, Quantization, Quantization_Finite, my_score, my_score_Finite\n",
    "from models.test import test_img\n",
    "\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "# from sympy import * \n",
    "from utils.functions import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "class my_argument:    \n",
    "    epochs = 200    #\"rounds of training\"\n",
    "    num_users = 40  # \"number of users: K\"\n",
    "    frac = 0.5 #\"the fraction of clients: C\"\n",
    "    local_ep=1 #\"the number of local epochs: E\"\n",
    "    local_bs=100 #\"local batch size: B\"\n",
    "    bs=100 #\"test batch size\"\n",
    "    lr=0.03 #\"learning rate\"\n",
    "    momentum=0.5 # \"SGD momentum (default: 0.5)\"\n",
    "    split='user' # \"train-test split type, user or sample\"\n",
    "    weight_decay = 5e-4\n",
    "    opt = 'SGD' #'ADAM'\n",
    "    loss = 'Cross'\n",
    "\n",
    "    # model arguments\n",
    "    model = 'cnn'\n",
    "    kernel_num=9 #, help='number of each kind of kernel')\n",
    "    kernel_sizes='3,4,5' #  help='comma-separated kernel size to use for convolution')\n",
    "    norm='batch_norm' #, help=\"batch_norm, layer_norm, or None\")\n",
    "    num_filters=32 #, help=\"number of filters for conv nets\")\n",
    "    max_pool='True' #help=\"Whether use max pooling rather than strided convolutions\")\n",
    "\n",
    "    # other arguments\n",
    "    dataset='cifar' #, help=\"name of dataset\")\n",
    "    iid=0\n",
    "    num_classes=10#, help=\"number of classes\")\n",
    "    num_channels=1#, help=\"number of channels of imges\")\n",
    "    gpu=1#, help=\"GPU ID, -1 for CPU\")\n",
    "    stopping_rounds=10#, help='rounds of early stopping')\n",
    "    verbose='False'#, help='verbose print')\n",
    "    seed=1#, help='random seed (default: 1)')\n",
    "    \n",
    "args = my_argument()\n",
    "\n",
    "args.device = torch.device('cuda:{}'.format(args.gpu) if torch.cuda.is_available() and args.gpu != -1 else 'cpu')\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(use_cuda)\n",
    "args.device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "trans_cifar = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "dataset_train = datasets.CIFAR10('./data/cifar', train=True, download=True, transform=trans_cifar)\n",
    "dataset_test = datasets.CIFAR10('./data/cifar', train=False, download=True, transform=trans_cifar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of non-shared images= 1245\n",
      "number of shared images= 200\n",
      "number of images per user= 1445\n"
     ]
    }
   ],
   "source": [
    "dict_users = cifar_noniid_shared(dataset_train, args.num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1  0.15 0.2  0.25 0.3  0.3  0.35 0.4  0.45 0.5 ]\n",
      "0 9 9\n",
      "1 1 9\n",
      "2 7 9\n",
      "3 6 9\n",
      "4 9 9\n",
      "5 3 9\n",
      "6 7 9\n",
      "7 0 9\n",
      "8 5 9\n",
      "9 7 9\n",
      "10 1 9\n",
      "11 6 9\n",
      "12 4 9\n",
      "13 9 9\n",
      "14 5 9\n",
      "15 5 9\n",
      "16 1 9\n",
      "17 9 9\n",
      "18 6 9\n",
      "19 2 9\n",
      "20 0 9\n",
      "21 3 9\n",
      "22 8 9\n",
      "23 1 9\n",
      "24 3 9\n",
      "25 8 9\n",
      "26 4 9\n",
      "27 8 9\n",
      "28 0 9\n",
      "29 3 9\n",
      "30 8 9\n",
      "31 4 9\n",
      "32 2 9\n",
      "33 0 9\n",
      "34 6 9\n",
      "35 2 9\n",
      "36 5 9\n",
      "37 4 9\n",
      "38 7 9\n",
      "39 2 9\n",
      "[0.5  0.15 0.4  0.35 0.5  0.25 0.4  0.1  0.3  0.4  0.15 0.35 0.3  0.5\n",
      " 0.3  0.3  0.15 0.5  0.35 0.2  0.1  0.25 0.45 0.15 0.25 0.45 0.3  0.45\n",
      " 0.1  0.25 0.45 0.3  0.2  0.1  0.35 0.2  0.3  0.3  0.4  0.2 ]\n",
      "hist [4. 4. 4. 4. 4. 4. 4. 4. 4. 4.]\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "N = 40\n",
    "K = 8\n",
    "\n",
    "# p_per_class = np.array([-0.1, -0.05, 0 , 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35])+0.025\n",
    "\n",
    "p_per_class = np.array([0.1, 0.15, 0.2, 0.25, 0.3, 0.3, 0.35, 0.4, 0.45, 0.5])\n",
    "print(p_per_class)\n",
    "\n",
    "p_per_user = np.zeros((N,))\n",
    "\n",
    "hist_ = np.zeros((10,))\n",
    "\n",
    "for i in range(N):\n",
    "    idxs=dict_users[i].astype(int)\n",
    "    target = np.array(dataset_train.targets)\n",
    "    cur_labels = target[idxs]\n",
    "#     print(np.shape(target))\n",
    "#     print(target[idxs])\n",
    "    \n",
    "    label_first = int(cur_labels[0])\n",
    "    label_second = int(cur_labels[-1])\n",
    "    \n",
    "#     print(i,cur_labels)\n",
    "    print(i,label_first,label_second)\n",
    "    \n",
    "    hist_[label_first] += 1\n",
    "    \n",
    "    p_per_user[i] = p_per_class[label_first]\n",
    "#     print(p_per_class[label_first] + p_per_class[label_second], p_per_user[i])\n",
    "print(p_per_user)\n",
    "\n",
    "print(\"hist\",hist_)\n",
    "\n",
    "print(np.sum(p_per_user)/120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNCifar(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.3062 \n",
      "Accuracy: 1000/10000 (10.00%)\n",
      "\n",
      "Round   0, Train average loss 2.079 Test accuracy 10.000\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.2969 \n",
      "Accuracy: 1239/10000 (12.39%)\n",
      "\n",
      "Round   1, Train average loss 1.746 Test accuracy 12.390\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.3186 \n",
      "Accuracy: 1000/10000 (10.00%)\n",
      "\n",
      "Round   2, Train average loss 1.219 Test accuracy 10.000\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.3022 \n",
      "Accuracy: 1360/10000 (13.60%)\n",
      "\n",
      "Round   3, Train average loss 1.088 Test accuracy 13.600\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.2962 \n",
      "Accuracy: 1329/10000 (13.29%)\n",
      "\n",
      "Round   4, Train average loss 1.035 Test accuracy 13.290\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.2909 \n",
      "Accuracy: 1275/10000 (12.75%)\n",
      "\n",
      "Round   5, Train average loss 0.962 Test accuracy 12.750\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.3001 \n",
      "Accuracy: 1415/10000 (14.15%)\n",
      "\n",
      "Round   6, Train average loss 0.888 Test accuracy 14.150\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.2818 \n",
      "Accuracy: 1336/10000 (13.36%)\n",
      "\n",
      "Round   7, Train average loss 0.885 Test accuracy 13.360\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.2767 \n",
      "Accuracy: 1117/10000 (11.17%)\n",
      "\n",
      "Round   8, Train average loss 0.864 Test accuracy 11.170\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.2791 \n",
      "Accuracy: 1471/10000 (14.71%)\n",
      "\n",
      "Round   9, Train average loss 0.922 Test accuracy 14.710\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.2656 \n",
      "Accuracy: 1559/10000 (15.59%)\n",
      "\n",
      "Round  10, Train average loss 0.883 Test accuracy 15.590\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.2620 \n",
      "Accuracy: 1539/10000 (15.39%)\n",
      "\n",
      "Round  11, Train average loss 0.861 Test accuracy 15.390\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.2567 \n",
      "Accuracy: 1553/10000 (15.53%)\n",
      "\n",
      "Round  12, Train average loss 0.852 Test accuracy 15.530\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.2468 \n",
      "Accuracy: 1792/10000 (17.92%)\n",
      "\n",
      "Round  13, Train average loss 0.844 Test accuracy 17.920\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.2392 \n",
      "Accuracy: 1685/10000 (16.85%)\n",
      "\n",
      "Round  14, Train average loss 0.839 Test accuracy 16.850\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.2364 \n",
      "Accuracy: 2001/10000 (20.01%)\n",
      "\n",
      "Round  15, Train average loss 0.821 Test accuracy 20.010\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.2275 \n",
      "Accuracy: 1956/10000 (19.56%)\n",
      "\n",
      "Round  16, Train average loss 0.849 Test accuracy 19.560\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.2234 \n",
      "Accuracy: 1628/10000 (16.28%)\n",
      "\n",
      "Round  17, Train average loss 0.810 Test accuracy 16.280\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.2209 \n",
      "Accuracy: 1584/10000 (15.84%)\n",
      "\n",
      "Round  18, Train average loss 0.795 Test accuracy 15.840\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.2259 \n",
      "Accuracy: 1669/10000 (16.69%)\n",
      "\n",
      "Round  19, Train average loss 0.800 Test accuracy 16.690\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.2288 \n",
      "Accuracy: 1650/10000 (16.50%)\n",
      "\n",
      "Round  20, Train average loss 0.830 Test accuracy 16.500\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.2123 \n",
      "Accuracy: 1611/10000 (16.11%)\n",
      "\n",
      "Round  21, Train average loss 0.845 Test accuracy 16.110\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.2108 \n",
      "Accuracy: 1474/10000 (14.74%)\n",
      "\n",
      "Round  22, Train average loss 0.792 Test accuracy 14.740\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.1983 \n",
      "Accuracy: 1783/10000 (17.83%)\n",
      "\n",
      "Round  23, Train average loss 0.774 Test accuracy 17.830\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.1801 \n",
      "Accuracy: 1918/10000 (19.18%)\n",
      "\n",
      "Round  24, Train average loss 0.783 Test accuracy 19.180\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.1745 \n",
      "Accuracy: 1862/10000 (18.62%)\n",
      "\n",
      "Round  25, Train average loss 0.789 Test accuracy 18.620\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.1699 \n",
      "Accuracy: 1831/10000 (18.31%)\n",
      "\n",
      "Round  26, Train average loss 0.810 Test accuracy 18.310\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.1661 \n",
      "Accuracy: 1886/10000 (18.86%)\n",
      "\n",
      "Round  27, Train average loss 0.783 Test accuracy 18.860\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.1637 \n",
      "Accuracy: 1859/10000 (18.59%)\n",
      "\n",
      "Round  28, Train average loss 0.759 Test accuracy 18.590\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.1673 \n",
      "Accuracy: 1933/10000 (19.33%)\n",
      "\n",
      "Round  29, Train average loss 0.814 Test accuracy 19.330\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.1547 \n",
      "Accuracy: 1917/10000 (19.17%)\n",
      "\n",
      "Round  30, Train average loss 0.746 Test accuracy 19.170\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.1520 \n",
      "Accuracy: 1829/10000 (18.29%)\n",
      "\n",
      "Round  31, Train average loss 0.793 Test accuracy 18.290\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.1424 \n",
      "Accuracy: 1961/10000 (19.61%)\n",
      "\n",
      "Round  32, Train average loss 0.770 Test accuracy 19.610\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.1393 \n",
      "Accuracy: 1840/10000 (18.40%)\n",
      "\n",
      "Round  33, Train average loss 0.768 Test accuracy 18.400\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.1333 \n",
      "Accuracy: 1899/10000 (18.99%)\n",
      "\n",
      "Round  34, Train average loss 0.758 Test accuracy 18.990\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.1220 \n",
      "Accuracy: 2116/10000 (21.16%)\n",
      "\n",
      "Round  35, Train average loss 0.797 Test accuracy 21.160\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.1336 \n",
      "Accuracy: 1837/10000 (18.37%)\n",
      "\n",
      "Round  36, Train average loss 0.751 Test accuracy 18.370\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.1314 \n",
      "Accuracy: 1856/10000 (18.56%)\n",
      "\n",
      "Round  37, Train average loss 0.724 Test accuracy 18.560\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.1142 \n",
      "Accuracy: 1933/10000 (19.33%)\n",
      "\n",
      "Round  38, Train average loss 0.736 Test accuracy 19.330\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.1051 \n",
      "Accuracy: 1924/10000 (19.24%)\n",
      "\n",
      "Round  39, Train average loss 0.753 Test accuracy 19.240\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0963 \n",
      "Accuracy: 2265/10000 (22.65%)\n",
      "\n",
      "Round  40, Train average loss 0.713 Test accuracy 22.650\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.1081 \n",
      "Accuracy: 2007/10000 (20.07%)\n",
      "\n",
      "Round  41, Train average loss 0.826 Test accuracy 20.070\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.1030 \n",
      "Accuracy: 2325/10000 (23.25%)\n",
      "\n",
      "Round  42, Train average loss 0.740 Test accuracy 23.250\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.1038 \n",
      "Accuracy: 1974/10000 (19.74%)\n",
      "\n",
      "Round  43, Train average loss 0.691 Test accuracy 19.740\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0890 \n",
      "Accuracy: 2423/10000 (24.23%)\n",
      "\n",
      "Round  44, Train average loss 0.719 Test accuracy 24.230\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0876 \n",
      "Accuracy: 2269/10000 (22.69%)\n",
      "\n",
      "Round  45, Train average loss 0.759 Test accuracy 22.690\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0866 \n",
      "Accuracy: 2016/10000 (20.16%)\n",
      "\n",
      "Round  46, Train average loss 0.744 Test accuracy 20.160\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0733 \n",
      "Accuracy: 2187/10000 (21.87%)\n",
      "\n",
      "Round  47, Train average loss 0.731 Test accuracy 21.870\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0751 \n",
      "Accuracy: 2173/10000 (21.73%)\n",
      "\n",
      "Round  48, Train average loss 0.752 Test accuracy 21.730\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0715 \n",
      "Accuracy: 2252/10000 (22.52%)\n",
      "\n",
      "Round  49, Train average loss 0.731 Test accuracy 22.520\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0738 \n",
      "Accuracy: 2067/10000 (20.67%)\n",
      "\n",
      "Round  50, Train average loss 0.728 Test accuracy 20.670\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0678 \n",
      "Accuracy: 2357/10000 (23.57%)\n",
      "\n",
      "Round  51, Train average loss 0.755 Test accuracy 23.570\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0691 \n",
      "Accuracy: 2308/10000 (23.08%)\n",
      "\n",
      "Round  52, Train average loss 0.753 Test accuracy 23.080\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0667 \n",
      "Accuracy: 2238/10000 (22.38%)\n",
      "\n",
      "Round  53, Train average loss 0.700 Test accuracy 22.380\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0664 \n",
      "Accuracy: 2333/10000 (23.33%)\n",
      "\n",
      "Round  54, Train average loss 0.700 Test accuracy 23.330\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0625 \n",
      "Accuracy: 2167/10000 (21.67%)\n",
      "\n",
      "Round  55, Train average loss 0.775 Test accuracy 21.670\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0703 \n",
      "Accuracy: 2036/10000 (20.36%)\n",
      "\n",
      "Round  56, Train average loss 0.668 Test accuracy 20.360\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0803 \n",
      "Accuracy: 2022/10000 (20.22%)\n",
      "\n",
      "Round  57, Train average loss 0.744 Test accuracy 20.220\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0806 \n",
      "Accuracy: 2165/10000 (21.65%)\n",
      "\n",
      "Round  58, Train average loss 0.758 Test accuracy 21.650\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0627 \n",
      "Accuracy: 2018/10000 (20.18%)\n",
      "\n",
      "Round  59, Train average loss 0.707 Test accuracy 20.180\n",
      "lr= 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.0578 \n",
      "Accuracy: 2074/10000 (20.74%)\n",
      "\n",
      "Round  60, Train average loss 0.713 Test accuracy 20.740\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0570 \n",
      "Accuracy: 2039/10000 (20.39%)\n",
      "\n",
      "Round  61, Train average loss 0.732 Test accuracy 20.390\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0445 \n",
      "Accuracy: 2431/10000 (24.31%)\n",
      "\n",
      "Round  62, Train average loss 0.704 Test accuracy 24.310\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0510 \n",
      "Accuracy: 2094/10000 (20.94%)\n",
      "\n",
      "Round  63, Train average loss 0.702 Test accuracy 20.940\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0407 \n",
      "Accuracy: 2452/10000 (24.52%)\n",
      "\n",
      "Round  64, Train average loss 0.726 Test accuracy 24.520\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0442 \n",
      "Accuracy: 2486/10000 (24.86%)\n",
      "\n",
      "Round  65, Train average loss 0.685 Test accuracy 24.860\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0357 \n",
      "Accuracy: 2430/10000 (24.30%)\n",
      "\n",
      "Round  66, Train average loss 0.703 Test accuracy 24.300\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0315 \n",
      "Accuracy: 2281/10000 (22.81%)\n",
      "\n",
      "Round  67, Train average loss 0.726 Test accuracy 22.810\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0298 \n",
      "Accuracy: 2590/10000 (25.90%)\n",
      "\n",
      "Round  68, Train average loss 0.707 Test accuracy 25.900\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0263 \n",
      "Accuracy: 2516/10000 (25.16%)\n",
      "\n",
      "Round  69, Train average loss 0.704 Test accuracy 25.160\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0393 \n",
      "Accuracy: 2446/10000 (24.46%)\n",
      "\n",
      "Round  70, Train average loss 0.679 Test accuracy 24.460\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0221 \n",
      "Accuracy: 2599/10000 (25.99%)\n",
      "\n",
      "Round  71, Train average loss 0.693 Test accuracy 25.990\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0280 \n",
      "Accuracy: 2200/10000 (22.00%)\n",
      "\n",
      "Round  72, Train average loss 0.692 Test accuracy 22.000\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0209 \n",
      "Accuracy: 2483/10000 (24.83%)\n",
      "\n",
      "Round  73, Train average loss 0.722 Test accuracy 24.830\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0175 \n",
      "Accuracy: 2474/10000 (24.74%)\n",
      "\n",
      "Round  74, Train average loss 0.701 Test accuracy 24.740\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0223 \n",
      "Accuracy: 2444/10000 (24.44%)\n",
      "\n",
      "Round  75, Train average loss 0.637 Test accuracy 24.440\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0236 \n",
      "Accuracy: 2449/10000 (24.49%)\n",
      "\n",
      "Round  76, Train average loss 0.655 Test accuracy 24.490\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0195 \n",
      "Accuracy: 2416/10000 (24.16%)\n",
      "\n",
      "Round  77, Train average loss 0.714 Test accuracy 24.160\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0222 \n",
      "Accuracy: 2452/10000 (24.52%)\n",
      "\n",
      "Round  78, Train average loss 0.704 Test accuracy 24.520\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0438 \n",
      "Accuracy: 2397/10000 (23.97%)\n",
      "\n",
      "Round  79, Train average loss 0.709 Test accuracy 23.970\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0255 \n",
      "Accuracy: 2447/10000 (24.47%)\n",
      "\n",
      "Round  80, Train average loss 0.698 Test accuracy 24.470\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0059 \n",
      "Accuracy: 2628/10000 (26.28%)\n",
      "\n",
      "Round  81, Train average loss 0.690 Test accuracy 26.280\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0062 \n",
      "Accuracy: 2598/10000 (25.98%)\n",
      "\n",
      "Round  82, Train average loss 0.704 Test accuracy 25.980\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0002 \n",
      "Accuracy: 2640/10000 (26.40%)\n",
      "\n",
      "Round  83, Train average loss 0.669 Test accuracy 26.400\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0034 \n",
      "Accuracy: 2703/10000 (27.03%)\n",
      "\n",
      "Round  84, Train average loss 0.686 Test accuracy 27.030\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0096 \n",
      "Accuracy: 2683/10000 (26.83%)\n",
      "\n",
      "Round  85, Train average loss 0.723 Test accuracy 26.830\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0024 \n",
      "Accuracy: 2533/10000 (25.33%)\n",
      "\n",
      "Round  86, Train average loss 0.678 Test accuracy 25.330\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0013 \n",
      "Accuracy: 2581/10000 (25.81%)\n",
      "\n",
      "Round  87, Train average loss 0.689 Test accuracy 25.810\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9905 \n",
      "Accuracy: 2794/10000 (27.94%)\n",
      "\n",
      "Round  88, Train average loss 0.675 Test accuracy 27.940\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9950 \n",
      "Accuracy: 2710/10000 (27.10%)\n",
      "\n",
      "Round  89, Train average loss 0.653 Test accuracy 27.100\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9967 \n",
      "Accuracy: 2748/10000 (27.48%)\n",
      "\n",
      "Round  90, Train average loss 0.635 Test accuracy 27.480\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9864 \n",
      "Accuracy: 2870/10000 (28.70%)\n",
      "\n",
      "Round  91, Train average loss 0.688 Test accuracy 28.700\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9854 \n",
      "Accuracy: 2860/10000 (28.60%)\n",
      "\n",
      "Round  92, Train average loss 0.669 Test accuracy 28.600\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9892 \n",
      "Accuracy: 2741/10000 (27.41%)\n",
      "\n",
      "Round  93, Train average loss 0.657 Test accuracy 27.410\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9899 \n",
      "Accuracy: 2573/10000 (25.73%)\n",
      "\n",
      "Round  94, Train average loss 0.709 Test accuracy 25.730\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9909 \n",
      "Accuracy: 2852/10000 (28.52%)\n",
      "\n",
      "Round  95, Train average loss 0.636 Test accuracy 28.520\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9804 \n",
      "Accuracy: 2723/10000 (27.23%)\n",
      "\n",
      "Round  96, Train average loss 0.660 Test accuracy 27.230\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9842 \n",
      "Accuracy: 2597/10000 (25.97%)\n",
      "\n",
      "Round  97, Train average loss 0.686 Test accuracy 25.970\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9929 \n",
      "Accuracy: 2664/10000 (26.64%)\n",
      "\n",
      "Round  98, Train average loss 0.656 Test accuracy 26.640\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9940 \n",
      "Accuracy: 2495/10000 (24.95%)\n",
      "\n",
      "Round  99, Train average loss 0.731 Test accuracy 24.950\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9787 \n",
      "Accuracy: 2818/10000 (28.18%)\n",
      "\n",
      "Round 100, Train average loss 0.631 Test accuracy 28.180\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9714 \n",
      "Accuracy: 2940/10000 (29.40%)\n",
      "\n",
      "Round 101, Train average loss 0.631 Test accuracy 29.400\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9675 \n",
      "Accuracy: 2860/10000 (28.60%)\n",
      "\n",
      "Round 102, Train average loss 0.637 Test accuracy 28.600\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9693 \n",
      "Accuracy: 2792/10000 (27.92%)\n",
      "\n",
      "Round 103, Train average loss 0.672 Test accuracy 27.920\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9726 \n",
      "Accuracy: 2758/10000 (27.58%)\n",
      "\n",
      "Round 104, Train average loss 0.666 Test accuracy 27.580\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9752 \n",
      "Accuracy: 2672/10000 (26.72%)\n",
      "\n",
      "Round 105, Train average loss 0.624 Test accuracy 26.720\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9807 \n",
      "Accuracy: 2603/10000 (26.03%)\n",
      "\n",
      "Round 106, Train average loss 0.667 Test accuracy 26.030\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9739 \n",
      "Accuracy: 2714/10000 (27.14%)\n",
      "\n",
      "Round 107, Train average loss 0.652 Test accuracy 27.140\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9737 \n",
      "Accuracy: 2757/10000 (27.57%)\n",
      "\n",
      "Round 108, Train average loss 0.652 Test accuracy 27.570\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9636 \n",
      "Accuracy: 2797/10000 (27.97%)\n",
      "\n",
      "Round 109, Train average loss 0.643 Test accuracy 27.970\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9638 \n",
      "Accuracy: 2750/10000 (27.50%)\n",
      "\n",
      "Round 110, Train average loss 0.660 Test accuracy 27.500\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9567 \n",
      "Accuracy: 2864/10000 (28.64%)\n",
      "\n",
      "Round 111, Train average loss 0.641 Test accuracy 28.640\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9590 \n",
      "Accuracy: 2926/10000 (29.26%)\n",
      "\n",
      "Round 112, Train average loss 0.650 Test accuracy 29.260\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9585 \n",
      "Accuracy: 2940/10000 (29.40%)\n",
      "\n",
      "Round 113, Train average loss 0.651 Test accuracy 29.400\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9612 \n",
      "Accuracy: 2714/10000 (27.14%)\n",
      "\n",
      "Round 114, Train average loss 0.658 Test accuracy 27.140\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9763 \n",
      "Accuracy: 2535/10000 (25.35%)\n",
      "\n",
      "Round 115, Train average loss 0.652 Test accuracy 25.350\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9654 \n",
      "Accuracy: 2599/10000 (25.99%)\n",
      "\n",
      "Round 116, Train average loss 0.633 Test accuracy 25.990\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9657 \n",
      "Accuracy: 2706/10000 (27.06%)\n",
      "\n",
      "Round 117, Train average loss 0.663 Test accuracy 27.060\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9631 \n",
      "Accuracy: 2708/10000 (27.08%)\n",
      "\n",
      "Round 118, Train average loss 0.643 Test accuracy 27.080\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9621 \n",
      "Accuracy: 2627/10000 (26.27%)\n",
      "\n",
      "Round 119, Train average loss 0.642 Test accuracy 26.270\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9562 \n",
      "Accuracy: 2710/10000 (27.10%)\n",
      "\n",
      "Round 120, Train average loss 0.645 Test accuracy 27.100\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9477 \n",
      "Accuracy: 2866/10000 (28.66%)\n",
      "\n",
      "Round 121, Train average loss 0.636 Test accuracy 28.660\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9478 \n",
      "Accuracy: 2932/10000 (29.32%)\n",
      "\n",
      "Round 122, Train average loss 0.603 Test accuracy 29.320\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9544 \n",
      "Accuracy: 2850/10000 (28.50%)\n",
      "\n",
      "Round 123, Train average loss 0.693 Test accuracy 28.500\n",
      "lr= 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.9547 \n",
      "Accuracy: 2754/10000 (27.54%)\n",
      "\n",
      "Round 124, Train average loss 0.621 Test accuracy 27.540\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9507 \n",
      "Accuracy: 2804/10000 (28.04%)\n",
      "\n",
      "Round 125, Train average loss 0.639 Test accuracy 28.040\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9530 \n",
      "Accuracy: 2747/10000 (27.47%)\n",
      "\n",
      "Round 126, Train average loss 0.648 Test accuracy 27.470\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9485 \n",
      "Accuracy: 2685/10000 (26.85%)\n",
      "\n",
      "Round 127, Train average loss 0.636 Test accuracy 26.850\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9551 \n",
      "Accuracy: 2656/10000 (26.56%)\n",
      "\n",
      "Round 128, Train average loss 0.630 Test accuracy 26.560\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9488 \n",
      "Accuracy: 2811/10000 (28.11%)\n",
      "\n",
      "Round 129, Train average loss 0.621 Test accuracy 28.110\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9346 \n",
      "Accuracy: 2915/10000 (29.15%)\n",
      "\n",
      "Round 130, Train average loss 0.630 Test accuracy 29.150\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9297 \n",
      "Accuracy: 2927/10000 (29.27%)\n",
      "\n",
      "Round 131, Train average loss 0.584 Test accuracy 29.270\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9191 \n",
      "Accuracy: 2973/10000 (29.73%)\n",
      "\n",
      "Round 132, Train average loss 0.598 Test accuracy 29.730\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9210 \n",
      "Accuracy: 2954/10000 (29.54%)\n",
      "\n",
      "Round 133, Train average loss 0.646 Test accuracy 29.540\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9208 \n",
      "Accuracy: 3009/10000 (30.09%)\n",
      "\n",
      "Round 134, Train average loss 0.620 Test accuracy 30.090\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9325 \n",
      "Accuracy: 2839/10000 (28.39%)\n",
      "\n",
      "Round 135, Train average loss 0.612 Test accuracy 28.390\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9305 \n",
      "Accuracy: 2862/10000 (28.62%)\n",
      "\n",
      "Round 136, Train average loss 0.614 Test accuracy 28.620\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9210 \n",
      "Accuracy: 2927/10000 (29.27%)\n",
      "\n",
      "Round 137, Train average loss 0.599 Test accuracy 29.270\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9221 \n",
      "Accuracy: 2963/10000 (29.63%)\n",
      "\n",
      "Round 138, Train average loss 0.595 Test accuracy 29.630\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9179 \n",
      "Accuracy: 2974/10000 (29.74%)\n",
      "\n",
      "Round 139, Train average loss 0.621 Test accuracy 29.740\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9243 \n",
      "Accuracy: 2839/10000 (28.39%)\n",
      "\n",
      "Round 140, Train average loss 0.625 Test accuracy 28.390\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9175 \n",
      "Accuracy: 2967/10000 (29.67%)\n",
      "\n",
      "Round 141, Train average loss 0.579 Test accuracy 29.670\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9057 \n",
      "Accuracy: 3007/10000 (30.07%)\n",
      "\n",
      "Round 142, Train average loss 0.580 Test accuracy 30.070\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8993 \n",
      "Accuracy: 3114/10000 (31.14%)\n",
      "\n",
      "Round 143, Train average loss 0.570 Test accuracy 31.140\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8999 \n",
      "Accuracy: 3105/10000 (31.05%)\n",
      "\n",
      "Round 144, Train average loss 0.613 Test accuracy 31.050\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8985 \n",
      "Accuracy: 3113/10000 (31.13%)\n",
      "\n",
      "Round 145, Train average loss 0.612 Test accuracy 31.130\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9018 \n",
      "Accuracy: 3159/10000 (31.59%)\n",
      "\n",
      "Round 146, Train average loss 0.591 Test accuracy 31.590\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8957 \n",
      "Accuracy: 3095/10000 (30.95%)\n",
      "\n",
      "Round 147, Train average loss 0.572 Test accuracy 30.950\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8993 \n",
      "Accuracy: 2970/10000 (29.70%)\n",
      "\n",
      "Round 148, Train average loss 0.625 Test accuracy 29.700\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9108 \n",
      "Accuracy: 2884/10000 (28.84%)\n",
      "\n",
      "Round 149, Train average loss 0.597 Test accuracy 28.840\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9063 \n",
      "Accuracy: 2896/10000 (28.96%)\n",
      "\n",
      "Round 150, Train average loss 0.559 Test accuracy 28.960\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9045 \n",
      "Accuracy: 2924/10000 (29.24%)\n",
      "\n",
      "Round 151, Train average loss 0.579 Test accuracy 29.240\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8986 \n",
      "Accuracy: 3001/10000 (30.01%)\n",
      "\n",
      "Round 152, Train average loss 0.546 Test accuracy 30.010\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9035 \n",
      "Accuracy: 2966/10000 (29.66%)\n",
      "\n",
      "Round 153, Train average loss 0.587 Test accuracy 29.660\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9082 \n",
      "Accuracy: 2853/10000 (28.53%)\n",
      "\n",
      "Round 154, Train average loss 0.579 Test accuracy 28.530\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8988 \n",
      "Accuracy: 3004/10000 (30.04%)\n",
      "\n",
      "Round 155, Train average loss 0.602 Test accuracy 30.040\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8970 \n",
      "Accuracy: 2942/10000 (29.42%)\n",
      "\n",
      "Round 156, Train average loss 0.542 Test accuracy 29.420\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8936 \n",
      "Accuracy: 2888/10000 (28.88%)\n",
      "\n",
      "Round 157, Train average loss 0.584 Test accuracy 28.880\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8958 \n",
      "Accuracy: 2959/10000 (29.59%)\n",
      "\n",
      "Round 158, Train average loss 0.574 Test accuracy 29.590\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8878 \n",
      "Accuracy: 3007/10000 (30.07%)\n",
      "\n",
      "Round 159, Train average loss 0.538 Test accuracy 30.070\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8859 \n",
      "Accuracy: 2995/10000 (29.95%)\n",
      "\n",
      "Round 160, Train average loss 0.581 Test accuracy 29.950\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8792 \n",
      "Accuracy: 3037/10000 (30.37%)\n",
      "\n",
      "Round 161, Train average loss 0.564 Test accuracy 30.370\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8824 \n",
      "Accuracy: 3065/10000 (30.65%)\n",
      "\n",
      "Round 162, Train average loss 0.579 Test accuracy 30.650\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8909 \n",
      "Accuracy: 2939/10000 (29.39%)\n",
      "\n",
      "Round 163, Train average loss 0.514 Test accuracy 29.390\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8922 \n",
      "Accuracy: 2986/10000 (29.86%)\n",
      "\n",
      "Round 164, Train average loss 0.589 Test accuracy 29.860\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8923 \n",
      "Accuracy: 2966/10000 (29.66%)\n",
      "\n",
      "Round 165, Train average loss 0.558 Test accuracy 29.660\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8703 \n",
      "Accuracy: 3096/10000 (30.96%)\n",
      "\n",
      "Round 166, Train average loss 0.524 Test accuracy 30.960\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8617 \n",
      "Accuracy: 3199/10000 (31.99%)\n",
      "\n",
      "Round 167, Train average loss 0.522 Test accuracy 31.990\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8612 \n",
      "Accuracy: 3173/10000 (31.73%)\n",
      "\n",
      "Round 168, Train average loss 0.540 Test accuracy 31.730\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8616 \n",
      "Accuracy: 3269/10000 (32.69%)\n",
      "\n",
      "Round 169, Train average loss 0.565 Test accuracy 32.690\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8655 \n",
      "Accuracy: 3206/10000 (32.06%)\n",
      "\n",
      "Round 170, Train average loss 0.576 Test accuracy 32.060\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8608 \n",
      "Accuracy: 3202/10000 (32.02%)\n",
      "\n",
      "Round 171, Train average loss 0.527 Test accuracy 32.020\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8778 \n",
      "Accuracy: 3045/10000 (30.45%)\n",
      "\n",
      "Round 172, Train average loss 0.557 Test accuracy 30.450\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8749 \n",
      "Accuracy: 3056/10000 (30.56%)\n",
      "\n",
      "Round 173, Train average loss 0.560 Test accuracy 30.560\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8542 \n",
      "Accuracy: 3186/10000 (31.86%)\n",
      "\n",
      "Round 174, Train average loss 0.514 Test accuracy 31.860\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8536 \n",
      "Accuracy: 3254/10000 (32.54%)\n",
      "\n",
      "Round 175, Train average loss 0.519 Test accuracy 32.540\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8663 \n",
      "Accuracy: 3199/10000 (31.99%)\n",
      "\n",
      "Round 176, Train average loss 0.557 Test accuracy 31.990\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8601 \n",
      "Accuracy: 3142/10000 (31.42%)\n",
      "\n",
      "Round 177, Train average loss 0.488 Test accuracy 31.420\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8700 \n",
      "Accuracy: 3125/10000 (31.25%)\n",
      "\n",
      "Round 178, Train average loss 0.556 Test accuracy 31.250\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8668 \n",
      "Accuracy: 3184/10000 (31.84%)\n",
      "\n",
      "Round 179, Train average loss 0.550 Test accuracy 31.840\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8613 \n",
      "Accuracy: 3233/10000 (32.33%)\n",
      "\n",
      "Round 180, Train average loss 0.518 Test accuracy 32.330\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8696 \n",
      "Accuracy: 3220/10000 (32.20%)\n",
      "\n",
      "Round 181, Train average loss 0.545 Test accuracy 32.200\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8722 \n",
      "Accuracy: 3141/10000 (31.41%)\n",
      "\n",
      "Round 182, Train average loss 0.524 Test accuracy 31.410\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8640 \n",
      "Accuracy: 3264/10000 (32.64%)\n",
      "\n",
      "Round 183, Train average loss 0.532 Test accuracy 32.640\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8582 \n",
      "Accuracy: 3298/10000 (32.98%)\n",
      "\n",
      "Round 184, Train average loss 0.526 Test accuracy 32.980\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8491 \n",
      "Accuracy: 3206/10000 (32.06%)\n",
      "\n",
      "Round 185, Train average loss 0.522 Test accuracy 32.060\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8482 \n",
      "Accuracy: 3203/10000 (32.03%)\n",
      "\n",
      "Round 186, Train average loss 0.522 Test accuracy 32.030\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8553 \n",
      "Accuracy: 3228/10000 (32.28%)\n",
      "\n",
      "Round 187, Train average loss 0.519 Test accuracy 32.280\n",
      "lr= 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.8501 \n",
      "Accuracy: 3109/10000 (31.09%)\n",
      "\n",
      "Round 188, Train average loss 0.463 Test accuracy 31.090\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8600 \n",
      "Accuracy: 3115/10000 (31.15%)\n",
      "\n",
      "Round 189, Train average loss 0.559 Test accuracy 31.150\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8449 \n",
      "Accuracy: 3287/10000 (32.87%)\n",
      "\n",
      "Round 190, Train average loss 0.523 Test accuracy 32.870\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8545 \n",
      "Accuracy: 3236/10000 (32.36%)\n",
      "\n",
      "Round 191, Train average loss 0.535 Test accuracy 32.360\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8505 \n",
      "Accuracy: 3273/10000 (32.73%)\n",
      "\n",
      "Round 192, Train average loss 0.494 Test accuracy 32.730\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8389 \n",
      "Accuracy: 3255/10000 (32.55%)\n",
      "\n",
      "Round 193, Train average loss 0.510 Test accuracy 32.550\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8394 \n",
      "Accuracy: 3169/10000 (31.69%)\n",
      "\n",
      "Round 194, Train average loss 0.490 Test accuracy 31.690\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8476 \n",
      "Accuracy: 3190/10000 (31.90%)\n",
      "\n",
      "Round 195, Train average loss 0.505 Test accuracy 31.900\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8473 \n",
      "Accuracy: 3167/10000 (31.67%)\n",
      "\n",
      "Round 196, Train average loss 0.437 Test accuracy 31.670\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8474 \n",
      "Accuracy: 3220/10000 (32.20%)\n",
      "\n",
      "Round 197, Train average loss 0.538 Test accuracy 32.200\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8548 \n",
      "Accuracy: 3285/10000 (32.85%)\n",
      "\n",
      "Round 198, Train average loss 0.534 Test accuracy 32.850\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8490 \n",
      "Accuracy: 3280/10000 (32.80%)\n",
      "\n",
      "Round 199, Train average loss 0.506 Test accuracy 32.800\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8455 \n",
      "Accuracy: 3205/10000 (32.05%)\n",
      "\n",
      "Round 200, Train average loss 0.507 Test accuracy 32.050\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8457 \n",
      "Accuracy: 3215/10000 (32.15%)\n",
      "\n",
      "Round 201, Train average loss 0.507 Test accuracy 32.150\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8454 \n",
      "Accuracy: 3196/10000 (31.96%)\n",
      "\n",
      "Round 202, Train average loss 0.447 Test accuracy 31.960\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8316 \n",
      "Accuracy: 3211/10000 (32.11%)\n",
      "\n",
      "Round 203, Train average loss 0.497 Test accuracy 32.110\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8335 \n",
      "Accuracy: 3308/10000 (33.08%)\n",
      "\n",
      "Round 204, Train average loss 0.497 Test accuracy 33.080\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8316 \n",
      "Accuracy: 3394/10000 (33.94%)\n",
      "\n",
      "Round 205, Train average loss 0.470 Test accuracy 33.940\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8298 \n",
      "Accuracy: 3299/10000 (32.99%)\n",
      "\n",
      "Round 206, Train average loss 0.462 Test accuracy 32.990\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8327 \n",
      "Accuracy: 3304/10000 (33.04%)\n",
      "\n",
      "Round 207, Train average loss 0.455 Test accuracy 33.040\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8378 \n",
      "Accuracy: 3365/10000 (33.65%)\n",
      "\n",
      "Round 208, Train average loss 0.507 Test accuracy 33.650\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8348 \n",
      "Accuracy: 3246/10000 (32.46%)\n",
      "\n",
      "Round 209, Train average loss 0.480 Test accuracy 32.460\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8412 \n",
      "Accuracy: 3290/10000 (32.90%)\n",
      "\n",
      "Round 210, Train average loss 0.482 Test accuracy 32.900\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8417 \n",
      "Accuracy: 3277/10000 (32.77%)\n",
      "\n",
      "Round 211, Train average loss 0.517 Test accuracy 32.770\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8430 \n",
      "Accuracy: 3268/10000 (32.68%)\n",
      "\n",
      "Round 212, Train average loss 0.468 Test accuracy 32.680\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8419 \n",
      "Accuracy: 3342/10000 (33.42%)\n",
      "\n",
      "Round 213, Train average loss 0.491 Test accuracy 33.420\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8540 \n",
      "Accuracy: 3285/10000 (32.85%)\n",
      "\n",
      "Round 214, Train average loss 0.459 Test accuracy 32.850\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8533 \n",
      "Accuracy: 3260/10000 (32.60%)\n",
      "\n",
      "Round 215, Train average loss 0.477 Test accuracy 32.600\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8399 \n",
      "Accuracy: 3321/10000 (33.21%)\n",
      "\n",
      "Round 216, Train average loss 0.477 Test accuracy 33.210\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8401 \n",
      "Accuracy: 3349/10000 (33.49%)\n",
      "\n",
      "Round 217, Train average loss 0.464 Test accuracy 33.490\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8394 \n",
      "Accuracy: 3345/10000 (33.45%)\n",
      "\n",
      "Round 218, Train average loss 0.433 Test accuracy 33.450\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8236 \n",
      "Accuracy: 3347/10000 (33.47%)\n",
      "\n",
      "Round 219, Train average loss 0.443 Test accuracy 33.470\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8121 \n",
      "Accuracy: 3361/10000 (33.61%)\n",
      "\n",
      "Round 220, Train average loss 0.441 Test accuracy 33.610\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8207 \n",
      "Accuracy: 3443/10000 (34.43%)\n",
      "\n",
      "Round 221, Train average loss 0.426 Test accuracy 34.430\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8342 \n",
      "Accuracy: 3347/10000 (33.47%)\n",
      "\n",
      "Round 222, Train average loss 0.507 Test accuracy 33.470\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8264 \n",
      "Accuracy: 3393/10000 (33.93%)\n",
      "\n",
      "Round 223, Train average loss 0.441 Test accuracy 33.930\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8216 \n",
      "Accuracy: 3320/10000 (33.20%)\n",
      "\n",
      "Round 224, Train average loss 0.439 Test accuracy 33.200\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8213 \n",
      "Accuracy: 3336/10000 (33.36%)\n",
      "\n",
      "Round 225, Train average loss 0.476 Test accuracy 33.360\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8249 \n",
      "Accuracy: 3334/10000 (33.34%)\n",
      "\n",
      "Round 226, Train average loss 0.494 Test accuracy 33.340\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8200 \n",
      "Accuracy: 3455/10000 (34.55%)\n",
      "\n",
      "Round 227, Train average loss 0.455 Test accuracy 34.550\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8167 \n",
      "Accuracy: 3449/10000 (34.49%)\n",
      "\n",
      "Round 228, Train average loss 0.433 Test accuracy 34.490\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8202 \n",
      "Accuracy: 3372/10000 (33.72%)\n",
      "\n",
      "Round 229, Train average loss 0.440 Test accuracy 33.720\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8114 \n",
      "Accuracy: 3394/10000 (33.94%)\n",
      "\n",
      "Round 230, Train average loss 0.409 Test accuracy 33.940\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8157 \n",
      "Accuracy: 3364/10000 (33.64%)\n",
      "\n",
      "Round 231, Train average loss 0.426 Test accuracy 33.640\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8135 \n",
      "Accuracy: 3357/10000 (33.57%)\n",
      "\n",
      "Round 232, Train average loss 0.425 Test accuracy 33.570\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8310 \n",
      "Accuracy: 3400/10000 (34.00%)\n",
      "\n",
      "Round 233, Train average loss 0.462 Test accuracy 34.000\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8298 \n",
      "Accuracy: 3424/10000 (34.24%)\n",
      "\n",
      "Round 234, Train average loss 0.423 Test accuracy 34.240\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8261 \n",
      "Accuracy: 3430/10000 (34.30%)\n",
      "\n",
      "Round 235, Train average loss 0.436 Test accuracy 34.300\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8309 \n",
      "Accuracy: 3387/10000 (33.87%)\n",
      "\n",
      "Round 236, Train average loss 0.443 Test accuracy 33.870\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8259 \n",
      "Accuracy: 3393/10000 (33.93%)\n",
      "\n",
      "Round 237, Train average loss 0.408 Test accuracy 33.930\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8314 \n",
      "Accuracy: 3365/10000 (33.65%)\n",
      "\n",
      "Round 238, Train average loss 0.451 Test accuracy 33.650\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8334 \n",
      "Accuracy: 3349/10000 (33.49%)\n",
      "\n",
      "Round 239, Train average loss 0.425 Test accuracy 33.490\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8060 \n",
      "Accuracy: 3432/10000 (34.32%)\n",
      "\n",
      "Round 240, Train average loss 0.413 Test accuracy 34.320\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8065 \n",
      "Accuracy: 3493/10000 (34.93%)\n",
      "\n",
      "Round 241, Train average loss 0.403 Test accuracy 34.930\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8181 \n",
      "Accuracy: 3481/10000 (34.81%)\n",
      "\n",
      "Round 242, Train average loss 0.431 Test accuracy 34.810\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8218 \n",
      "Accuracy: 3502/10000 (35.02%)\n",
      "\n",
      "Round 243, Train average loss 0.418 Test accuracy 35.020\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8350 \n",
      "Accuracy: 3480/10000 (34.80%)\n",
      "\n",
      "Round 244, Train average loss 0.422 Test accuracy 34.800\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8222 \n",
      "Accuracy: 3463/10000 (34.63%)\n",
      "\n",
      "Round 245, Train average loss 0.419 Test accuracy 34.630\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8240 \n",
      "Accuracy: 3441/10000 (34.41%)\n",
      "\n",
      "Round 246, Train average loss 0.408 Test accuracy 34.410\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8274 \n",
      "Accuracy: 3480/10000 (34.80%)\n",
      "\n",
      "Round 247, Train average loss 0.408 Test accuracy 34.800\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8313 \n",
      "Accuracy: 3464/10000 (34.64%)\n",
      "\n",
      "Round 248, Train average loss 0.420 Test accuracy 34.640\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8284 \n",
      "Accuracy: 3473/10000 (34.73%)\n",
      "\n",
      "Round 249, Train average loss 0.403 Test accuracy 34.730\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8340 \n",
      "Accuracy: 3464/10000 (34.64%)\n",
      "\n",
      "Round 250, Train average loss 0.415 Test accuracy 34.640\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8394 \n",
      "Accuracy: 3441/10000 (34.41%)\n",
      "\n",
      "Round 251, Train average loss 0.445 Test accuracy 34.410\n",
      "lr= 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.8298 \n",
      "Accuracy: 3516/10000 (35.16%)\n",
      "\n",
      "Round 252, Train average loss 0.432 Test accuracy 35.160\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8249 \n",
      "Accuracy: 3478/10000 (34.78%)\n",
      "\n",
      "Round 253, Train average loss 0.409 Test accuracy 34.780\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8217 \n",
      "Accuracy: 3491/10000 (34.91%)\n",
      "\n",
      "Round 254, Train average loss 0.406 Test accuracy 34.910\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8309 \n",
      "Accuracy: 3423/10000 (34.23%)\n",
      "\n",
      "Round 255, Train average loss 0.410 Test accuracy 34.230\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8240 \n",
      "Accuracy: 3504/10000 (35.04%)\n",
      "\n",
      "Round 256, Train average loss 0.365 Test accuracy 35.040\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8191 \n",
      "Accuracy: 3524/10000 (35.24%)\n",
      "\n",
      "Round 257, Train average loss 0.419 Test accuracy 35.240\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8140 \n",
      "Accuracy: 3457/10000 (34.57%)\n",
      "\n",
      "Round 258, Train average loss 0.367 Test accuracy 34.570\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8153 \n",
      "Accuracy: 3532/10000 (35.32%)\n",
      "\n",
      "Round 259, Train average loss 0.399 Test accuracy 35.320\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8193 \n",
      "Accuracy: 3561/10000 (35.61%)\n",
      "\n",
      "Round 260, Train average loss 0.381 Test accuracy 35.610\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8174 \n",
      "Accuracy: 3534/10000 (35.34%)\n",
      "\n",
      "Round 261, Train average loss 0.381 Test accuracy 35.340\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8226 \n",
      "Accuracy: 3513/10000 (35.13%)\n",
      "\n",
      "Round 262, Train average loss 0.391 Test accuracy 35.130\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8163 \n",
      "Accuracy: 3532/10000 (35.32%)\n",
      "\n",
      "Round 263, Train average loss 0.389 Test accuracy 35.320\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8319 \n",
      "Accuracy: 3497/10000 (34.97%)\n",
      "\n",
      "Round 264, Train average loss 0.392 Test accuracy 34.970\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8230 \n",
      "Accuracy: 3493/10000 (34.93%)\n",
      "\n",
      "Round 265, Train average loss 0.375 Test accuracy 34.930\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8261 \n",
      "Accuracy: 3567/10000 (35.67%)\n",
      "\n",
      "Round 266, Train average loss 0.375 Test accuracy 35.670\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8231 \n",
      "Accuracy: 3543/10000 (35.43%)\n",
      "\n",
      "Round 267, Train average loss 0.364 Test accuracy 35.430\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8225 \n",
      "Accuracy: 3509/10000 (35.09%)\n",
      "\n",
      "Round 268, Train average loss 0.356 Test accuracy 35.090\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8242 \n",
      "Accuracy: 3554/10000 (35.54%)\n",
      "\n",
      "Round 269, Train average loss 0.371 Test accuracy 35.540\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8241 \n",
      "Accuracy: 3536/10000 (35.36%)\n",
      "\n",
      "Round 270, Train average loss 0.369 Test accuracy 35.360\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8249 \n",
      "Accuracy: 3577/10000 (35.77%)\n",
      "\n",
      "Round 271, Train average loss 0.377 Test accuracy 35.770\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8188 \n",
      "Accuracy: 3577/10000 (35.77%)\n",
      "\n",
      "Round 272, Train average loss 0.335 Test accuracy 35.770\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8212 \n",
      "Accuracy: 3591/10000 (35.91%)\n",
      "\n",
      "Round 273, Train average loss 0.334 Test accuracy 35.910\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8247 \n",
      "Accuracy: 3594/10000 (35.94%)\n",
      "\n",
      "Round 274, Train average loss 0.333 Test accuracy 35.940\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8411 \n",
      "Accuracy: 3527/10000 (35.27%)\n",
      "\n",
      "Round 275, Train average loss 0.342 Test accuracy 35.270\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8283 \n",
      "Accuracy: 3581/10000 (35.81%)\n",
      "\n",
      "Round 276, Train average loss 0.346 Test accuracy 35.810\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8297 \n",
      "Accuracy: 3597/10000 (35.97%)\n",
      "\n",
      "Round 277, Train average loss 0.371 Test accuracy 35.970\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8348 \n",
      "Accuracy: 3602/10000 (36.02%)\n",
      "\n",
      "Round 278, Train average loss 0.359 Test accuracy 36.020\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8315 \n",
      "Accuracy: 3622/10000 (36.22%)\n",
      "\n",
      "Round 279, Train average loss 0.331 Test accuracy 36.220\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8400 \n",
      "Accuracy: 3603/10000 (36.03%)\n",
      "\n",
      "Round 280, Train average loss 0.379 Test accuracy 36.030\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8527 \n",
      "Accuracy: 3545/10000 (35.45%)\n",
      "\n",
      "Round 281, Train average loss 0.328 Test accuracy 35.450\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8503 \n",
      "Accuracy: 3546/10000 (35.46%)\n",
      "\n",
      "Round 282, Train average loss 0.360 Test accuracy 35.460\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8692 \n",
      "Accuracy: 3571/10000 (35.71%)\n",
      "\n",
      "Round 283, Train average loss 0.357 Test accuracy 35.710\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8459 \n",
      "Accuracy: 3540/10000 (35.40%)\n",
      "\n",
      "Round 284, Train average loss 0.343 Test accuracy 35.400\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8348 \n",
      "Accuracy: 3583/10000 (35.83%)\n",
      "\n",
      "Round 285, Train average loss 0.361 Test accuracy 35.830\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8223 \n",
      "Accuracy: 3609/10000 (36.09%)\n",
      "\n",
      "Round 286, Train average loss 0.351 Test accuracy 36.090\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8358 \n",
      "Accuracy: 3623/10000 (36.23%)\n",
      "\n",
      "Round 287, Train average loss 0.340 Test accuracy 36.230\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8379 \n",
      "Accuracy: 3577/10000 (35.77%)\n",
      "\n",
      "Round 288, Train average loss 0.343 Test accuracy 35.770\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8313 \n",
      "Accuracy: 3594/10000 (35.94%)\n",
      "\n",
      "Round 289, Train average loss 0.332 Test accuracy 35.940\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8356 \n",
      "Accuracy: 3624/10000 (36.24%)\n",
      "\n",
      "Round 290, Train average loss 0.357 Test accuracy 36.240\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8519 \n",
      "Accuracy: 3584/10000 (35.84%)\n",
      "\n",
      "Round 291, Train average loss 0.338 Test accuracy 35.840\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8454 \n",
      "Accuracy: 3638/10000 (36.38%)\n",
      "\n",
      "Round 292, Train average loss 0.302 Test accuracy 36.380\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8330 \n",
      "Accuracy: 3601/10000 (36.01%)\n",
      "\n",
      "Round 293, Train average loss 0.327 Test accuracy 36.010\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8398 \n",
      "Accuracy: 3629/10000 (36.29%)\n",
      "\n",
      "Round 294, Train average loss 0.325 Test accuracy 36.290\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8347 \n",
      "Accuracy: 3638/10000 (36.38%)\n",
      "\n",
      "Round 295, Train average loss 0.312 Test accuracy 36.380\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8564 \n",
      "Accuracy: 3584/10000 (35.84%)\n",
      "\n",
      "Round 296, Train average loss 0.357 Test accuracy 35.840\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8611 \n",
      "Accuracy: 3595/10000 (35.95%)\n",
      "\n",
      "Round 297, Train average loss 0.336 Test accuracy 35.950\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8552 \n",
      "Accuracy: 3558/10000 (35.58%)\n",
      "\n",
      "Round 298, Train average loss 0.338 Test accuracy 35.580\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8468 \n",
      "Accuracy: 3643/10000 (36.43%)\n",
      "\n",
      "Round 299, Train average loss 0.342 Test accuracy 36.430\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8569 \n",
      "Accuracy: 3620/10000 (36.20%)\n",
      "\n",
      "Round 300, Train average loss 0.329 Test accuracy 36.200\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8597 \n",
      "Accuracy: 3592/10000 (35.92%)\n",
      "\n",
      "Round 301, Train average loss 0.322 Test accuracy 35.920\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8734 \n",
      "Accuracy: 3583/10000 (35.83%)\n",
      "\n",
      "Round 302, Train average loss 0.330 Test accuracy 35.830\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8800 \n",
      "Accuracy: 3551/10000 (35.51%)\n",
      "\n",
      "Round 303, Train average loss 0.304 Test accuracy 35.510\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8738 \n",
      "Accuracy: 3590/10000 (35.90%)\n",
      "\n",
      "Round 304, Train average loss 0.349 Test accuracy 35.900\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8726 \n",
      "Accuracy: 3593/10000 (35.93%)\n",
      "\n",
      "Round 305, Train average loss 0.290 Test accuracy 35.930\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8660 \n",
      "Accuracy: 3638/10000 (36.38%)\n",
      "\n",
      "Round 306, Train average loss 0.315 Test accuracy 36.380\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8854 \n",
      "Accuracy: 3638/10000 (36.38%)\n",
      "\n",
      "Round 307, Train average loss 0.307 Test accuracy 36.380\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8789 \n",
      "Accuracy: 3638/10000 (36.38%)\n",
      "\n",
      "Round 308, Train average loss 0.279 Test accuracy 36.380\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8900 \n",
      "Accuracy: 3614/10000 (36.14%)\n",
      "\n",
      "Round 309, Train average loss 0.282 Test accuracy 36.140\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8806 \n",
      "Accuracy: 3604/10000 (36.04%)\n",
      "\n",
      "Round 310, Train average loss 0.298 Test accuracy 36.040\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8775 \n",
      "Accuracy: 3585/10000 (35.85%)\n",
      "\n",
      "Round 311, Train average loss 0.319 Test accuracy 35.850\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8835 \n",
      "Accuracy: 3616/10000 (36.16%)\n",
      "\n",
      "Round 312, Train average loss 0.324 Test accuracy 36.160\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9138 \n",
      "Accuracy: 3599/10000 (35.99%)\n",
      "\n",
      "Round 313, Train average loss 0.307 Test accuracy 35.990\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8875 \n",
      "Accuracy: 3593/10000 (35.93%)\n",
      "\n",
      "Round 314, Train average loss 0.297 Test accuracy 35.930\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8825 \n",
      "Accuracy: 3647/10000 (36.47%)\n",
      "\n",
      "Round 315, Train average loss 0.306 Test accuracy 36.470\n",
      "lr= 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.9161 \n",
      "Accuracy: 3574/10000 (35.74%)\n",
      "\n",
      "Round 316, Train average loss 0.329 Test accuracy 35.740\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9066 \n",
      "Accuracy: 3597/10000 (35.97%)\n",
      "\n",
      "Round 317, Train average loss 0.267 Test accuracy 35.970\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9098 \n",
      "Accuracy: 3578/10000 (35.78%)\n",
      "\n",
      "Round 318, Train average loss 0.294 Test accuracy 35.780\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9019 \n",
      "Accuracy: 3591/10000 (35.91%)\n",
      "\n",
      "Round 319, Train average loss 0.292 Test accuracy 35.910\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9233 \n",
      "Accuracy: 3546/10000 (35.46%)\n",
      "\n",
      "Round 320, Train average loss 0.305 Test accuracy 35.460\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9065 \n",
      "Accuracy: 3606/10000 (36.06%)\n",
      "\n",
      "Round 321, Train average loss 0.285 Test accuracy 36.060\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8920 \n",
      "Accuracy: 3620/10000 (36.20%)\n",
      "\n",
      "Round 322, Train average loss 0.281 Test accuracy 36.200\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8846 \n",
      "Accuracy: 3648/10000 (36.48%)\n",
      "\n",
      "Round 323, Train average loss 0.266 Test accuracy 36.480\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8988 \n",
      "Accuracy: 3593/10000 (35.93%)\n",
      "\n",
      "Round 324, Train average loss 0.274 Test accuracy 35.930\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8849 \n",
      "Accuracy: 3603/10000 (36.03%)\n",
      "\n",
      "Round 325, Train average loss 0.280 Test accuracy 36.030\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9000 \n",
      "Accuracy: 3612/10000 (36.12%)\n",
      "\n",
      "Round 326, Train average loss 0.291 Test accuracy 36.120\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8931 \n",
      "Accuracy: 3622/10000 (36.22%)\n",
      "\n",
      "Round 327, Train average loss 0.288 Test accuracy 36.220\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9201 \n",
      "Accuracy: 3626/10000 (36.26%)\n",
      "\n",
      "Round 328, Train average loss 0.275 Test accuracy 36.260\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9165 \n",
      "Accuracy: 3639/10000 (36.39%)\n",
      "\n",
      "Round 329, Train average loss 0.269 Test accuracy 36.390\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9158 \n",
      "Accuracy: 3603/10000 (36.03%)\n",
      "\n",
      "Round 330, Train average loss 0.270 Test accuracy 36.030\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8971 \n",
      "Accuracy: 3620/10000 (36.20%)\n",
      "\n",
      "Round 331, Train average loss 0.276 Test accuracy 36.200\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9082 \n",
      "Accuracy: 3625/10000 (36.25%)\n",
      "\n",
      "Round 332, Train average loss 0.286 Test accuracy 36.250\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9067 \n",
      "Accuracy: 3632/10000 (36.32%)\n",
      "\n",
      "Round 333, Train average loss 0.266 Test accuracy 36.320\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9024 \n",
      "Accuracy: 3657/10000 (36.57%)\n",
      "\n",
      "Round 334, Train average loss 0.260 Test accuracy 36.570\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8911 \n",
      "Accuracy: 3693/10000 (36.93%)\n",
      "\n",
      "Round 335, Train average loss 0.258 Test accuracy 36.930\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9038 \n",
      "Accuracy: 3625/10000 (36.25%)\n",
      "\n",
      "Round 336, Train average loss 0.269 Test accuracy 36.250\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9036 \n",
      "Accuracy: 3616/10000 (36.16%)\n",
      "\n",
      "Round 337, Train average loss 0.260 Test accuracy 36.160\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9168 \n",
      "Accuracy: 3599/10000 (35.99%)\n",
      "\n",
      "Round 338, Train average loss 0.292 Test accuracy 35.990\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9068 \n",
      "Accuracy: 3639/10000 (36.39%)\n",
      "\n",
      "Round 339, Train average loss 0.265 Test accuracy 36.390\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9035 \n",
      "Accuracy: 3619/10000 (36.19%)\n",
      "\n",
      "Round 340, Train average loss 0.259 Test accuracy 36.190\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9299 \n",
      "Accuracy: 3594/10000 (35.94%)\n",
      "\n",
      "Round 341, Train average loss 0.273 Test accuracy 35.940\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.8893 \n",
      "Accuracy: 3635/10000 (36.35%)\n",
      "\n",
      "Round 342, Train average loss 0.257 Test accuracy 36.350\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9133 \n",
      "Accuracy: 3625/10000 (36.25%)\n",
      "\n",
      "Round 343, Train average loss 0.242 Test accuracy 36.250\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9097 \n",
      "Accuracy: 3656/10000 (36.56%)\n",
      "\n",
      "Round 344, Train average loss 0.253 Test accuracy 36.560\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9015 \n",
      "Accuracy: 3649/10000 (36.49%)\n",
      "\n",
      "Round 345, Train average loss 0.275 Test accuracy 36.490\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9100 \n",
      "Accuracy: 3605/10000 (36.05%)\n",
      "\n",
      "Round 346, Train average loss 0.271 Test accuracy 36.050\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9230 \n",
      "Accuracy: 3616/10000 (36.16%)\n",
      "\n",
      "Round 347, Train average loss 0.254 Test accuracy 36.160\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9215 \n",
      "Accuracy: 3603/10000 (36.03%)\n",
      "\n",
      "Round 348, Train average loss 0.265 Test accuracy 36.030\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9119 \n",
      "Accuracy: 3625/10000 (36.25%)\n",
      "\n",
      "Round 349, Train average loss 0.241 Test accuracy 36.250\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9162 \n",
      "Accuracy: 3675/10000 (36.75%)\n",
      "\n",
      "Round 350, Train average loss 0.238 Test accuracy 36.750\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9334 \n",
      "Accuracy: 3622/10000 (36.22%)\n",
      "\n",
      "Round 351, Train average loss 0.244 Test accuracy 36.220\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9284 \n",
      "Accuracy: 3617/10000 (36.17%)\n",
      "\n",
      "Round 352, Train average loss 0.256 Test accuracy 36.170\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9065 \n",
      "Accuracy: 3655/10000 (36.55%)\n",
      "\n",
      "Round 353, Train average loss 0.248 Test accuracy 36.550\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9237 \n",
      "Accuracy: 3636/10000 (36.36%)\n",
      "\n",
      "Round 354, Train average loss 0.258 Test accuracy 36.360\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9181 \n",
      "Accuracy: 3656/10000 (36.56%)\n",
      "\n",
      "Round 355, Train average loss 0.229 Test accuracy 36.560\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9303 \n",
      "Accuracy: 3637/10000 (36.37%)\n",
      "\n",
      "Round 356, Train average loss 0.231 Test accuracy 36.370\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9647 \n",
      "Accuracy: 3616/10000 (36.16%)\n",
      "\n",
      "Round 357, Train average loss 0.242 Test accuracy 36.160\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9273 \n",
      "Accuracy: 3603/10000 (36.03%)\n",
      "\n",
      "Round 358, Train average loss 0.268 Test accuracy 36.030\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9444 \n",
      "Accuracy: 3604/10000 (36.04%)\n",
      "\n",
      "Round 359, Train average loss 0.258 Test accuracy 36.040\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9163 \n",
      "Accuracy: 3650/10000 (36.50%)\n",
      "\n",
      "Round 360, Train average loss 0.240 Test accuracy 36.500\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9403 \n",
      "Accuracy: 3566/10000 (35.66%)\n",
      "\n",
      "Round 361, Train average loss 0.260 Test accuracy 35.660\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9169 \n",
      "Accuracy: 3611/10000 (36.11%)\n",
      "\n",
      "Round 362, Train average loss 0.230 Test accuracy 36.110\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9459 \n",
      "Accuracy: 3604/10000 (36.04%)\n",
      "\n",
      "Round 363, Train average loss 0.204 Test accuracy 36.040\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9356 \n",
      "Accuracy: 3611/10000 (36.11%)\n",
      "\n",
      "Round 364, Train average loss 0.245 Test accuracy 36.110\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9424 \n",
      "Accuracy: 3632/10000 (36.32%)\n",
      "\n",
      "Round 365, Train average loss 0.214 Test accuracy 36.320\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9265 \n",
      "Accuracy: 3628/10000 (36.28%)\n",
      "\n",
      "Round 366, Train average loss 0.227 Test accuracy 36.280\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9193 \n",
      "Accuracy: 3638/10000 (36.38%)\n",
      "\n",
      "Round 367, Train average loss 0.235 Test accuracy 36.380\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9536 \n",
      "Accuracy: 3605/10000 (36.05%)\n",
      "\n",
      "Round 368, Train average loss 0.234 Test accuracy 36.050\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9583 \n",
      "Accuracy: 3569/10000 (35.69%)\n",
      "\n",
      "Round 369, Train average loss 0.230 Test accuracy 35.690\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9437 \n",
      "Accuracy: 3615/10000 (36.15%)\n",
      "\n",
      "Round 370, Train average loss 0.251 Test accuracy 36.150\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9319 \n",
      "Accuracy: 3637/10000 (36.37%)\n",
      "\n",
      "Round 371, Train average loss 0.218 Test accuracy 36.370\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9377 \n",
      "Accuracy: 3620/10000 (36.20%)\n",
      "\n",
      "Round 372, Train average loss 0.238 Test accuracy 36.200\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9962 \n",
      "Accuracy: 3586/10000 (35.86%)\n",
      "\n",
      "Round 373, Train average loss 0.227 Test accuracy 35.860\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9830 \n",
      "Accuracy: 3590/10000 (35.90%)\n",
      "\n",
      "Round 374, Train average loss 0.219 Test accuracy 35.900\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9672 \n",
      "Accuracy: 3636/10000 (36.36%)\n",
      "\n",
      "Round 375, Train average loss 0.228 Test accuracy 36.360\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9607 \n",
      "Accuracy: 3632/10000 (36.32%)\n",
      "\n",
      "Round 376, Train average loss 0.221 Test accuracy 36.320\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9468 \n",
      "Accuracy: 3625/10000 (36.25%)\n",
      "\n",
      "Round 377, Train average loss 0.225 Test accuracy 36.250\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9961 \n",
      "Accuracy: 3583/10000 (35.83%)\n",
      "\n",
      "Round 378, Train average loss 0.215 Test accuracy 35.830\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9729 \n",
      "Accuracy: 3593/10000 (35.93%)\n",
      "\n",
      "Round 379, Train average loss 0.226 Test accuracy 35.930\n",
      "lr= 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.9609 \n",
      "Accuracy: 3640/10000 (36.40%)\n",
      "\n",
      "Round 380, Train average loss 0.207 Test accuracy 36.400\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9877 \n",
      "Accuracy: 3577/10000 (35.77%)\n",
      "\n",
      "Round 381, Train average loss 0.209 Test accuracy 35.770\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9468 \n",
      "Accuracy: 3630/10000 (36.30%)\n",
      "\n",
      "Round 382, Train average loss 0.221 Test accuracy 36.300\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9783 \n",
      "Accuracy: 3598/10000 (35.98%)\n",
      "\n",
      "Round 383, Train average loss 0.219 Test accuracy 35.980\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9704 \n",
      "Accuracy: 3628/10000 (36.28%)\n",
      "\n",
      "Round 384, Train average loss 0.222 Test accuracy 36.280\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9622 \n",
      "Accuracy: 3610/10000 (36.10%)\n",
      "\n",
      "Round 385, Train average loss 0.233 Test accuracy 36.100\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9810 \n",
      "Accuracy: 3612/10000 (36.12%)\n",
      "\n",
      "Round 386, Train average loss 0.201 Test accuracy 36.120\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9780 \n",
      "Accuracy: 3626/10000 (36.26%)\n",
      "\n",
      "Round 387, Train average loss 0.224 Test accuracy 36.260\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0110 \n",
      "Accuracy: 3591/10000 (35.91%)\n",
      "\n",
      "Round 388, Train average loss 0.213 Test accuracy 35.910\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9578 \n",
      "Accuracy: 3683/10000 (36.83%)\n",
      "\n",
      "Round 389, Train average loss 0.213 Test accuracy 36.830\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0083 \n",
      "Accuracy: 3598/10000 (35.98%)\n",
      "\n",
      "Round 390, Train average loss 0.212 Test accuracy 35.980\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0106 \n",
      "Accuracy: 3601/10000 (36.01%)\n",
      "\n",
      "Round 391, Train average loss 0.224 Test accuracy 36.010\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9754 \n",
      "Accuracy: 3661/10000 (36.61%)\n",
      "\n",
      "Round 392, Train average loss 0.188 Test accuracy 36.610\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0016 \n",
      "Accuracy: 3590/10000 (35.90%)\n",
      "\n",
      "Round 393, Train average loss 0.224 Test accuracy 35.900\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0428 \n",
      "Accuracy: 3499/10000 (34.99%)\n",
      "\n",
      "Round 394, Train average loss 0.223 Test accuracy 34.990\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9868 \n",
      "Accuracy: 3599/10000 (35.99%)\n",
      "\n",
      "Round 395, Train average loss 0.212 Test accuracy 35.990\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0099 \n",
      "Accuracy: 3601/10000 (36.01%)\n",
      "\n",
      "Round 396, Train average loss 0.191 Test accuracy 36.010\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0375 \n",
      "Accuracy: 3572/10000 (35.72%)\n",
      "\n",
      "Round 397, Train average loss 0.199 Test accuracy 35.720\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 2.0457 \n",
      "Accuracy: 3586/10000 (35.86%)\n",
      "\n",
      "Round 398, Train average loss 0.202 Test accuracy 35.860\n",
      "lr= 0.01\n",
      "\n",
      "Test set: Average loss: 1.9946 \n",
      "Accuracy: 3615/10000 (36.15%)\n",
      "\n",
      "Round 399, Train average loss 0.197 Test accuracy 36.150\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0656 \n",
      "Accuracy: 3483/10000 (34.83%)\n",
      "\n",
      "Round 400, Train average loss 0.333 Test accuracy 34.830\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0564 \n",
      "Accuracy: 3534/10000 (35.34%)\n",
      "\n",
      "Round 401, Train average loss 0.291 Test accuracy 35.340\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0607 \n",
      "Accuracy: 3510/10000 (35.10%)\n",
      "\n",
      "Round 402, Train average loss 0.310 Test accuracy 35.100\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1215 \n",
      "Accuracy: 3506/10000 (35.06%)\n",
      "\n",
      "Round 403, Train average loss 0.292 Test accuracy 35.060\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0871 \n",
      "Accuracy: 3563/10000 (35.63%)\n",
      "\n",
      "Round 404, Train average loss 0.268 Test accuracy 35.630\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0716 \n",
      "Accuracy: 3576/10000 (35.76%)\n",
      "\n",
      "Round 405, Train average loss 0.286 Test accuracy 35.760\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0467 \n",
      "Accuracy: 3638/10000 (36.38%)\n",
      "\n",
      "Round 406, Train average loss 0.261 Test accuracy 36.380\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0591 \n",
      "Accuracy: 3657/10000 (36.57%)\n",
      "\n",
      "Round 407, Train average loss 0.279 Test accuracy 36.570\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0936 \n",
      "Accuracy: 3632/10000 (36.32%)\n",
      "\n",
      "Round 408, Train average loss 0.259 Test accuracy 36.320\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0604 \n",
      "Accuracy: 3564/10000 (35.64%)\n",
      "\n",
      "Round 409, Train average loss 0.280 Test accuracy 35.640\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0694 \n",
      "Accuracy: 3633/10000 (36.33%)\n",
      "\n",
      "Round 410, Train average loss 0.259 Test accuracy 36.330\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0628 \n",
      "Accuracy: 3614/10000 (36.14%)\n",
      "\n",
      "Round 411, Train average loss 0.288 Test accuracy 36.140\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0472 \n",
      "Accuracy: 3660/10000 (36.60%)\n",
      "\n",
      "Round 412, Train average loss 0.247 Test accuracy 36.600\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0554 \n",
      "Accuracy: 3655/10000 (36.55%)\n",
      "\n",
      "Round 413, Train average loss 0.244 Test accuracy 36.550\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0689 \n",
      "Accuracy: 3703/10000 (37.03%)\n",
      "\n",
      "Round 414, Train average loss 0.256 Test accuracy 37.030\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0293 \n",
      "Accuracy: 3708/10000 (37.08%)\n",
      "\n",
      "Round 415, Train average loss 0.248 Test accuracy 37.080\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0382 \n",
      "Accuracy: 3667/10000 (36.67%)\n",
      "\n",
      "Round 416, Train average loss 0.258 Test accuracy 36.670\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0355 \n",
      "Accuracy: 3707/10000 (37.07%)\n",
      "\n",
      "Round 417, Train average loss 0.222 Test accuracy 37.070\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0505 \n",
      "Accuracy: 3710/10000 (37.10%)\n",
      "\n",
      "Round 418, Train average loss 0.237 Test accuracy 37.100\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0410 \n",
      "Accuracy: 3670/10000 (36.70%)\n",
      "\n",
      "Round 419, Train average loss 0.263 Test accuracy 36.700\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0303 \n",
      "Accuracy: 3654/10000 (36.54%)\n",
      "\n",
      "Round 420, Train average loss 0.254 Test accuracy 36.540\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0574 \n",
      "Accuracy: 3650/10000 (36.50%)\n",
      "\n",
      "Round 421, Train average loss 0.253 Test accuracy 36.500\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0462 \n",
      "Accuracy: 3671/10000 (36.71%)\n",
      "\n",
      "Round 422, Train average loss 0.245 Test accuracy 36.710\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0702 \n",
      "Accuracy: 3642/10000 (36.42%)\n",
      "\n",
      "Round 423, Train average loss 0.245 Test accuracy 36.420\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1160 \n",
      "Accuracy: 3595/10000 (35.95%)\n",
      "\n",
      "Round 424, Train average loss 0.254 Test accuracy 35.950\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0876 \n",
      "Accuracy: 3573/10000 (35.73%)\n",
      "\n",
      "Round 425, Train average loss 0.259 Test accuracy 35.730\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0338 \n",
      "Accuracy: 3727/10000 (37.27%)\n",
      "\n",
      "Round 426, Train average loss 0.237 Test accuracy 37.270\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0633 \n",
      "Accuracy: 3663/10000 (36.63%)\n",
      "\n",
      "Round 427, Train average loss 0.233 Test accuracy 36.630\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0655 \n",
      "Accuracy: 3644/10000 (36.44%)\n",
      "\n",
      "Round 428, Train average loss 0.248 Test accuracy 36.440\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0804 \n",
      "Accuracy: 3636/10000 (36.36%)\n",
      "\n",
      "Round 429, Train average loss 0.237 Test accuracy 36.360\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0820 \n",
      "Accuracy: 3686/10000 (36.86%)\n",
      "\n",
      "Round 430, Train average loss 0.219 Test accuracy 36.860\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0608 \n",
      "Accuracy: 3683/10000 (36.83%)\n",
      "\n",
      "Round 431, Train average loss 0.237 Test accuracy 36.830\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0615 \n",
      "Accuracy: 3720/10000 (37.20%)\n",
      "\n",
      "Round 432, Train average loss 0.210 Test accuracy 37.200\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0367 \n",
      "Accuracy: 3747/10000 (37.47%)\n",
      "\n",
      "Round 433, Train average loss 0.212 Test accuracy 37.470\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0270 \n",
      "Accuracy: 3746/10000 (37.46%)\n",
      "\n",
      "Round 434, Train average loss 0.217 Test accuracy 37.460\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0380 \n",
      "Accuracy: 3745/10000 (37.45%)\n",
      "\n",
      "Round 435, Train average loss 0.232 Test accuracy 37.450\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0635 \n",
      "Accuracy: 3673/10000 (36.73%)\n",
      "\n",
      "Round 436, Train average loss 0.233 Test accuracy 36.730\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1132 \n",
      "Accuracy: 3636/10000 (36.36%)\n",
      "\n",
      "Round 437, Train average loss 0.225 Test accuracy 36.360\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0821 \n",
      "Accuracy: 3643/10000 (36.43%)\n",
      "\n",
      "Round 438, Train average loss 0.230 Test accuracy 36.430\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0718 \n",
      "Accuracy: 3627/10000 (36.27%)\n",
      "\n",
      "Round 439, Train average loss 0.251 Test accuracy 36.270\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0333 \n",
      "Accuracy: 3714/10000 (37.14%)\n",
      "\n",
      "Round 440, Train average loss 0.221 Test accuracy 37.140\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0578 \n",
      "Accuracy: 3633/10000 (36.33%)\n",
      "\n",
      "Round 441, Train average loss 0.231 Test accuracy 36.330\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1171 \n",
      "Accuracy: 3574/10000 (35.74%)\n",
      "\n",
      "Round 442, Train average loss 0.214 Test accuracy 35.740\n",
      "lr= 0.004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.1370 \n",
      "Accuracy: 3609/10000 (36.09%)\n",
      "\n",
      "Round 443, Train average loss 0.205 Test accuracy 36.090\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0304 \n",
      "Accuracy: 3748/10000 (37.48%)\n",
      "\n",
      "Round 444, Train average loss 0.217 Test accuracy 37.480\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0951 \n",
      "Accuracy: 3662/10000 (36.62%)\n",
      "\n",
      "Round 445, Train average loss 0.213 Test accuracy 36.620\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0446 \n",
      "Accuracy: 3744/10000 (37.44%)\n",
      "\n",
      "Round 446, Train average loss 0.217 Test accuracy 37.440\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0780 \n",
      "Accuracy: 3631/10000 (36.31%)\n",
      "\n",
      "Round 447, Train average loss 0.214 Test accuracy 36.310\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0806 \n",
      "Accuracy: 3720/10000 (37.20%)\n",
      "\n",
      "Round 448, Train average loss 0.206 Test accuracy 37.200\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0978 \n",
      "Accuracy: 3643/10000 (36.43%)\n",
      "\n",
      "Round 449, Train average loss 0.222 Test accuracy 36.430\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0726 \n",
      "Accuracy: 3694/10000 (36.94%)\n",
      "\n",
      "Round 450, Train average loss 0.200 Test accuracy 36.940\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0448 \n",
      "Accuracy: 3771/10000 (37.71%)\n",
      "\n",
      "Round 451, Train average loss 0.197 Test accuracy 37.710\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0636 \n",
      "Accuracy: 3684/10000 (36.84%)\n",
      "\n",
      "Round 452, Train average loss 0.208 Test accuracy 36.840\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0728 \n",
      "Accuracy: 3661/10000 (36.61%)\n",
      "\n",
      "Round 453, Train average loss 0.209 Test accuracy 36.610\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0600 \n",
      "Accuracy: 3655/10000 (36.55%)\n",
      "\n",
      "Round 454, Train average loss 0.228 Test accuracy 36.550\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0517 \n",
      "Accuracy: 3693/10000 (36.93%)\n",
      "\n",
      "Round 455, Train average loss 0.209 Test accuracy 36.930\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1014 \n",
      "Accuracy: 3647/10000 (36.47%)\n",
      "\n",
      "Round 456, Train average loss 0.223 Test accuracy 36.470\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0461 \n",
      "Accuracy: 3719/10000 (37.19%)\n",
      "\n",
      "Round 457, Train average loss 0.215 Test accuracy 37.190\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0615 \n",
      "Accuracy: 3723/10000 (37.23%)\n",
      "\n",
      "Round 458, Train average loss 0.194 Test accuracy 37.230\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0701 \n",
      "Accuracy: 3704/10000 (37.04%)\n",
      "\n",
      "Round 459, Train average loss 0.205 Test accuracy 37.040\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0698 \n",
      "Accuracy: 3722/10000 (37.22%)\n",
      "\n",
      "Round 460, Train average loss 0.197 Test accuracy 37.220\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0584 \n",
      "Accuracy: 3727/10000 (37.27%)\n",
      "\n",
      "Round 461, Train average loss 0.190 Test accuracy 37.270\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1312 \n",
      "Accuracy: 3619/10000 (36.19%)\n",
      "\n",
      "Round 462, Train average loss 0.218 Test accuracy 36.190\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0499 \n",
      "Accuracy: 3758/10000 (37.58%)\n",
      "\n",
      "Round 463, Train average loss 0.196 Test accuracy 37.580\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0415 \n",
      "Accuracy: 3784/10000 (37.84%)\n",
      "\n",
      "Round 464, Train average loss 0.168 Test accuracy 37.840\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0442 \n",
      "Accuracy: 3711/10000 (37.11%)\n",
      "\n",
      "Round 465, Train average loss 0.215 Test accuracy 37.110\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0426 \n",
      "Accuracy: 3678/10000 (36.78%)\n",
      "\n",
      "Round 466, Train average loss 0.211 Test accuracy 36.780\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0588 \n",
      "Accuracy: 3703/10000 (37.03%)\n",
      "\n",
      "Round 467, Train average loss 0.205 Test accuracy 37.030\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1865 \n",
      "Accuracy: 3561/10000 (35.61%)\n",
      "\n",
      "Round 468, Train average loss 0.202 Test accuracy 35.610\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1187 \n",
      "Accuracy: 3527/10000 (35.27%)\n",
      "\n",
      "Round 469, Train average loss 0.234 Test accuracy 35.270\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0458 \n",
      "Accuracy: 3722/10000 (37.22%)\n",
      "\n",
      "Round 470, Train average loss 0.199 Test accuracy 37.220\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0753 \n",
      "Accuracy: 3618/10000 (36.18%)\n",
      "\n",
      "Round 471, Train average loss 0.204 Test accuracy 36.180\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0576 \n",
      "Accuracy: 3685/10000 (36.85%)\n",
      "\n",
      "Round 472, Train average loss 0.209 Test accuracy 36.850\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0591 \n",
      "Accuracy: 3699/10000 (36.99%)\n",
      "\n",
      "Round 473, Train average loss 0.196 Test accuracy 36.990\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0854 \n",
      "Accuracy: 3701/10000 (37.01%)\n",
      "\n",
      "Round 474, Train average loss 0.198 Test accuracy 37.010\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0513 \n",
      "Accuracy: 3741/10000 (37.41%)\n",
      "\n",
      "Round 475, Train average loss 0.175 Test accuracy 37.410\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0537 \n",
      "Accuracy: 3720/10000 (37.20%)\n",
      "\n",
      "Round 476, Train average loss 0.197 Test accuracy 37.200\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0782 \n",
      "Accuracy: 3715/10000 (37.15%)\n",
      "\n",
      "Round 477, Train average loss 0.170 Test accuracy 37.150\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0866 \n",
      "Accuracy: 3683/10000 (36.83%)\n",
      "\n",
      "Round 478, Train average loss 0.202 Test accuracy 36.830\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0736 \n",
      "Accuracy: 3701/10000 (37.01%)\n",
      "\n",
      "Round 479, Train average loss 0.186 Test accuracy 37.010\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0839 \n",
      "Accuracy: 3684/10000 (36.84%)\n",
      "\n",
      "Round 480, Train average loss 0.188 Test accuracy 36.840\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1361 \n",
      "Accuracy: 3627/10000 (36.27%)\n",
      "\n",
      "Round 481, Train average loss 0.178 Test accuracy 36.270\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0964 \n",
      "Accuracy: 3668/10000 (36.68%)\n",
      "\n",
      "Round 482, Train average loss 0.191 Test accuracy 36.680\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0956 \n",
      "Accuracy: 3697/10000 (36.97%)\n",
      "\n",
      "Round 483, Train average loss 0.204 Test accuracy 36.970\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1520 \n",
      "Accuracy: 3545/10000 (35.45%)\n",
      "\n",
      "Round 484, Train average loss 0.207 Test accuracy 35.450\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1073 \n",
      "Accuracy: 3678/10000 (36.78%)\n",
      "\n",
      "Round 485, Train average loss 0.177 Test accuracy 36.780\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1176 \n",
      "Accuracy: 3743/10000 (37.43%)\n",
      "\n",
      "Round 486, Train average loss 0.162 Test accuracy 37.430\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0887 \n",
      "Accuracy: 3739/10000 (37.39%)\n",
      "\n",
      "Round 487, Train average loss 0.191 Test accuracy 37.390\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1158 \n",
      "Accuracy: 3661/10000 (36.61%)\n",
      "\n",
      "Round 488, Train average loss 0.183 Test accuracy 36.610\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1260 \n",
      "Accuracy: 3640/10000 (36.40%)\n",
      "\n",
      "Round 489, Train average loss 0.183 Test accuracy 36.400\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1117 \n",
      "Accuracy: 3630/10000 (36.30%)\n",
      "\n",
      "Round 490, Train average loss 0.194 Test accuracy 36.300\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1409 \n",
      "Accuracy: 3674/10000 (36.74%)\n",
      "\n",
      "Round 491, Train average loss 0.185 Test accuracy 36.740\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0824 \n",
      "Accuracy: 3684/10000 (36.84%)\n",
      "\n",
      "Round 492, Train average loss 0.193 Test accuracy 36.840\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1218 \n",
      "Accuracy: 3628/10000 (36.28%)\n",
      "\n",
      "Round 493, Train average loss 0.192 Test accuracy 36.280\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1154 \n",
      "Accuracy: 3635/10000 (36.35%)\n",
      "\n",
      "Round 494, Train average loss 0.191 Test accuracy 36.350\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1116 \n",
      "Accuracy: 3693/10000 (36.93%)\n",
      "\n",
      "Round 495, Train average loss 0.178 Test accuracy 36.930\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1642 \n",
      "Accuracy: 3591/10000 (35.91%)\n",
      "\n",
      "Round 496, Train average loss 0.173 Test accuracy 35.910\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0936 \n",
      "Accuracy: 3676/10000 (36.76%)\n",
      "\n",
      "Round 497, Train average loss 0.182 Test accuracy 36.760\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1396 \n",
      "Accuracy: 3541/10000 (35.41%)\n",
      "\n",
      "Round 498, Train average loss 0.198 Test accuracy 35.410\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1068 \n",
      "Accuracy: 3641/10000 (36.41%)\n",
      "\n",
      "Round 499, Train average loss 0.180 Test accuracy 36.410\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1489 \n",
      "Accuracy: 3608/10000 (36.08%)\n",
      "\n",
      "Round 500, Train average loss 0.187 Test accuracy 36.080\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2070 \n",
      "Accuracy: 3490/10000 (34.90%)\n",
      "\n",
      "Round 501, Train average loss 0.188 Test accuracy 34.900\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1084 \n",
      "Accuracy: 3633/10000 (36.33%)\n",
      "\n",
      "Round 502, Train average loss 0.190 Test accuracy 36.330\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0891 \n",
      "Accuracy: 3700/10000 (37.00%)\n",
      "\n",
      "Round 503, Train average loss 0.182 Test accuracy 37.000\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1226 \n",
      "Accuracy: 3649/10000 (36.49%)\n",
      "\n",
      "Round 504, Train average loss 0.179 Test accuracy 36.490\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1860 \n",
      "Accuracy: 3550/10000 (35.50%)\n",
      "\n",
      "Round 505, Train average loss 0.181 Test accuracy 35.500\n",
      "lr= 0.004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.1993 \n",
      "Accuracy: 3625/10000 (36.25%)\n",
      "\n",
      "Round 506, Train average loss 0.164 Test accuracy 36.250\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1233 \n",
      "Accuracy: 3695/10000 (36.95%)\n",
      "\n",
      "Round 507, Train average loss 0.169 Test accuracy 36.950\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1047 \n",
      "Accuracy: 3652/10000 (36.52%)\n",
      "\n",
      "Round 508, Train average loss 0.183 Test accuracy 36.520\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2121 \n",
      "Accuracy: 3535/10000 (35.35%)\n",
      "\n",
      "Round 509, Train average loss 0.185 Test accuracy 35.350\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0693 \n",
      "Accuracy: 3728/10000 (37.28%)\n",
      "\n",
      "Round 510, Train average loss 0.185 Test accuracy 37.280\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0578 \n",
      "Accuracy: 3807/10000 (38.07%)\n",
      "\n",
      "Round 511, Train average loss 0.166 Test accuracy 38.070\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0461 \n",
      "Accuracy: 3758/10000 (37.58%)\n",
      "\n",
      "Round 512, Train average loss 0.173 Test accuracy 37.580\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0804 \n",
      "Accuracy: 3710/10000 (37.10%)\n",
      "\n",
      "Round 513, Train average loss 0.173 Test accuracy 37.100\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1087 \n",
      "Accuracy: 3675/10000 (36.75%)\n",
      "\n",
      "Round 514, Train average loss 0.161 Test accuracy 36.750\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0833 \n",
      "Accuracy: 3705/10000 (37.05%)\n",
      "\n",
      "Round 515, Train average loss 0.177 Test accuracy 37.050\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0966 \n",
      "Accuracy: 3713/10000 (37.13%)\n",
      "\n",
      "Round 516, Train average loss 0.172 Test accuracy 37.130\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0769 \n",
      "Accuracy: 3737/10000 (37.37%)\n",
      "\n",
      "Round 517, Train average loss 0.171 Test accuracy 37.370\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1271 \n",
      "Accuracy: 3675/10000 (36.75%)\n",
      "\n",
      "Round 518, Train average loss 0.183 Test accuracy 36.750\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0844 \n",
      "Accuracy: 3743/10000 (37.43%)\n",
      "\n",
      "Round 519, Train average loss 0.163 Test accuracy 37.430\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1805 \n",
      "Accuracy: 3616/10000 (36.16%)\n",
      "\n",
      "Round 520, Train average loss 0.161 Test accuracy 36.160\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0895 \n",
      "Accuracy: 3683/10000 (36.83%)\n",
      "\n",
      "Round 521, Train average loss 0.179 Test accuracy 36.830\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0905 \n",
      "Accuracy: 3681/10000 (36.81%)\n",
      "\n",
      "Round 522, Train average loss 0.178 Test accuracy 36.810\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1528 \n",
      "Accuracy: 3708/10000 (37.08%)\n",
      "\n",
      "Round 523, Train average loss 0.166 Test accuracy 37.080\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1314 \n",
      "Accuracy: 3671/10000 (36.71%)\n",
      "\n",
      "Round 524, Train average loss 0.185 Test accuracy 36.710\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1129 \n",
      "Accuracy: 3701/10000 (37.01%)\n",
      "\n",
      "Round 525, Train average loss 0.171 Test accuracy 37.010\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1510 \n",
      "Accuracy: 3612/10000 (36.12%)\n",
      "\n",
      "Round 526, Train average loss 0.173 Test accuracy 36.120\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0855 \n",
      "Accuracy: 3717/10000 (37.17%)\n",
      "\n",
      "Round 527, Train average loss 0.174 Test accuracy 37.170\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0733 \n",
      "Accuracy: 3729/10000 (37.29%)\n",
      "\n",
      "Round 528, Train average loss 0.163 Test accuracy 37.290\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1272 \n",
      "Accuracy: 3635/10000 (36.35%)\n",
      "\n",
      "Round 529, Train average loss 0.163 Test accuracy 36.350\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1515 \n",
      "Accuracy: 3640/10000 (36.40%)\n",
      "\n",
      "Round 530, Train average loss 0.159 Test accuracy 36.400\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1532 \n",
      "Accuracy: 3649/10000 (36.49%)\n",
      "\n",
      "Round 531, Train average loss 0.163 Test accuracy 36.490\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1076 \n",
      "Accuracy: 3719/10000 (37.19%)\n",
      "\n",
      "Round 532, Train average loss 0.153 Test accuracy 37.190\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1256 \n",
      "Accuracy: 3670/10000 (36.70%)\n",
      "\n",
      "Round 533, Train average loss 0.175 Test accuracy 36.700\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1360 \n",
      "Accuracy: 3637/10000 (36.37%)\n",
      "\n",
      "Round 534, Train average loss 0.168 Test accuracy 36.370\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0542 \n",
      "Accuracy: 3767/10000 (37.67%)\n",
      "\n",
      "Round 535, Train average loss 0.162 Test accuracy 37.670\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1307 \n",
      "Accuracy: 3714/10000 (37.14%)\n",
      "\n",
      "Round 536, Train average loss 0.157 Test accuracy 37.140\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1578 \n",
      "Accuracy: 3620/10000 (36.20%)\n",
      "\n",
      "Round 537, Train average loss 0.179 Test accuracy 36.200\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1034 \n",
      "Accuracy: 3664/10000 (36.64%)\n",
      "\n",
      "Round 538, Train average loss 0.165 Test accuracy 36.640\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1400 \n",
      "Accuracy: 3643/10000 (36.43%)\n",
      "\n",
      "Round 539, Train average loss 0.151 Test accuracy 36.430\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2092 \n",
      "Accuracy: 3540/10000 (35.40%)\n",
      "\n",
      "Round 540, Train average loss 0.163 Test accuracy 35.400\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1758 \n",
      "Accuracy: 3607/10000 (36.07%)\n",
      "\n",
      "Round 541, Train average loss 0.161 Test accuracy 36.070\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1558 \n",
      "Accuracy: 3674/10000 (36.74%)\n",
      "\n",
      "Round 542, Train average loss 0.161 Test accuracy 36.740\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0950 \n",
      "Accuracy: 3694/10000 (36.94%)\n",
      "\n",
      "Round 543, Train average loss 0.170 Test accuracy 36.940\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1363 \n",
      "Accuracy: 3694/10000 (36.94%)\n",
      "\n",
      "Round 544, Train average loss 0.143 Test accuracy 36.940\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0909 \n",
      "Accuracy: 3758/10000 (37.58%)\n",
      "\n",
      "Round 545, Train average loss 0.151 Test accuracy 37.580\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1052 \n",
      "Accuracy: 3733/10000 (37.33%)\n",
      "\n",
      "Round 546, Train average loss 0.154 Test accuracy 37.330\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1687 \n",
      "Accuracy: 3667/10000 (36.67%)\n",
      "\n",
      "Round 547, Train average loss 0.134 Test accuracy 36.670\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0753 \n",
      "Accuracy: 3765/10000 (37.65%)\n",
      "\n",
      "Round 548, Train average loss 0.164 Test accuracy 37.650\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1321 \n",
      "Accuracy: 3713/10000 (37.13%)\n",
      "\n",
      "Round 549, Train average loss 0.150 Test accuracy 37.130\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2204 \n",
      "Accuracy: 3571/10000 (35.71%)\n",
      "\n",
      "Round 550, Train average loss 0.159 Test accuracy 35.710\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1917 \n",
      "Accuracy: 3612/10000 (36.12%)\n",
      "\n",
      "Round 551, Train average loss 0.173 Test accuracy 36.120\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1565 \n",
      "Accuracy: 3633/10000 (36.33%)\n",
      "\n",
      "Round 552, Train average loss 0.154 Test accuracy 36.330\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2118 \n",
      "Accuracy: 3579/10000 (35.79%)\n",
      "\n",
      "Round 553, Train average loss 0.146 Test accuracy 35.790\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1730 \n",
      "Accuracy: 3643/10000 (36.43%)\n",
      "\n",
      "Round 554, Train average loss 0.165 Test accuracy 36.430\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2207 \n",
      "Accuracy: 3534/10000 (35.34%)\n",
      "\n",
      "Round 555, Train average loss 0.156 Test accuracy 35.340\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1670 \n",
      "Accuracy: 3618/10000 (36.18%)\n",
      "\n",
      "Round 556, Train average loss 0.168 Test accuracy 36.180\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1141 \n",
      "Accuracy: 3674/10000 (36.74%)\n",
      "\n",
      "Round 557, Train average loss 0.155 Test accuracy 36.740\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1654 \n",
      "Accuracy: 3671/10000 (36.71%)\n",
      "\n",
      "Round 558, Train average loss 0.153 Test accuracy 36.710\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1497 \n",
      "Accuracy: 3655/10000 (36.55%)\n",
      "\n",
      "Round 559, Train average loss 0.153 Test accuracy 36.550\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1446 \n",
      "Accuracy: 3683/10000 (36.83%)\n",
      "\n",
      "Round 560, Train average loss 0.157 Test accuracy 36.830\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1391 \n",
      "Accuracy: 3699/10000 (36.99%)\n",
      "\n",
      "Round 561, Train average loss 0.156 Test accuracy 36.990\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1536 \n",
      "Accuracy: 3729/10000 (37.29%)\n",
      "\n",
      "Round 562, Train average loss 0.143 Test accuracy 37.290\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1320 \n",
      "Accuracy: 3678/10000 (36.78%)\n",
      "\n",
      "Round 563, Train average loss 0.156 Test accuracy 36.780\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1013 \n",
      "Accuracy: 3739/10000 (37.39%)\n",
      "\n",
      "Round 564, Train average loss 0.157 Test accuracy 37.390\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1006 \n",
      "Accuracy: 3724/10000 (37.24%)\n",
      "\n",
      "Round 565, Train average loss 0.155 Test accuracy 37.240\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1181 \n",
      "Accuracy: 3677/10000 (36.77%)\n",
      "\n",
      "Round 566, Train average loss 0.159 Test accuracy 36.770\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.0926 \n",
      "Accuracy: 3749/10000 (37.49%)\n",
      "\n",
      "Round 567, Train average loss 0.142 Test accuracy 37.490\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1309 \n",
      "Accuracy: 3697/10000 (36.97%)\n",
      "\n",
      "Round 568, Train average loss 0.162 Test accuracy 36.970\n",
      "lr= 0.004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.1152 \n",
      "Accuracy: 3762/10000 (37.62%)\n",
      "\n",
      "Round 569, Train average loss 0.141 Test accuracy 37.620\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2429 \n",
      "Accuracy: 3569/10000 (35.69%)\n",
      "\n",
      "Round 570, Train average loss 0.150 Test accuracy 35.690\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1911 \n",
      "Accuracy: 3669/10000 (36.69%)\n",
      "\n",
      "Round 571, Train average loss 0.142 Test accuracy 36.690\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1601 \n",
      "Accuracy: 3697/10000 (36.97%)\n",
      "\n",
      "Round 572, Train average loss 0.143 Test accuracy 36.970\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1253 \n",
      "Accuracy: 3727/10000 (37.27%)\n",
      "\n",
      "Round 573, Train average loss 0.146 Test accuracy 37.270\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2212 \n",
      "Accuracy: 3634/10000 (36.34%)\n",
      "\n",
      "Round 574, Train average loss 0.153 Test accuracy 36.340\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1411 \n",
      "Accuracy: 3743/10000 (37.43%)\n",
      "\n",
      "Round 575, Train average loss 0.146 Test accuracy 37.430\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1569 \n",
      "Accuracy: 3732/10000 (37.32%)\n",
      "\n",
      "Round 576, Train average loss 0.144 Test accuracy 37.320\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1642 \n",
      "Accuracy: 3771/10000 (37.71%)\n",
      "\n",
      "Round 577, Train average loss 0.134 Test accuracy 37.710\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1296 \n",
      "Accuracy: 3754/10000 (37.54%)\n",
      "\n",
      "Round 578, Train average loss 0.137 Test accuracy 37.540\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1135 \n",
      "Accuracy: 3813/10000 (38.13%)\n",
      "\n",
      "Round 579, Train average loss 0.139 Test accuracy 38.130\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1423 \n",
      "Accuracy: 3803/10000 (38.03%)\n",
      "\n",
      "Round 580, Train average loss 0.131 Test accuracy 38.030\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1652 \n",
      "Accuracy: 3712/10000 (37.12%)\n",
      "\n",
      "Round 581, Train average loss 0.138 Test accuracy 37.120\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1124 \n",
      "Accuracy: 3763/10000 (37.63%)\n",
      "\n",
      "Round 582, Train average loss 0.152 Test accuracy 37.630\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1424 \n",
      "Accuracy: 3769/10000 (37.69%)\n",
      "\n",
      "Round 583, Train average loss 0.140 Test accuracy 37.690\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1419 \n",
      "Accuracy: 3716/10000 (37.16%)\n",
      "\n",
      "Round 584, Train average loss 0.154 Test accuracy 37.160\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1468 \n",
      "Accuracy: 3733/10000 (37.33%)\n",
      "\n",
      "Round 585, Train average loss 0.136 Test accuracy 37.330\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2138 \n",
      "Accuracy: 3723/10000 (37.23%)\n",
      "\n",
      "Round 586, Train average loss 0.124 Test accuracy 37.230\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1250 \n",
      "Accuracy: 3823/10000 (38.23%)\n",
      "\n",
      "Round 587, Train average loss 0.142 Test accuracy 38.230\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1507 \n",
      "Accuracy: 3772/10000 (37.72%)\n",
      "\n",
      "Round 588, Train average loss 0.133 Test accuracy 37.720\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1746 \n",
      "Accuracy: 3695/10000 (36.95%)\n",
      "\n",
      "Round 589, Train average loss 0.155 Test accuracy 36.950\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1715 \n",
      "Accuracy: 3709/10000 (37.09%)\n",
      "\n",
      "Round 590, Train average loss 0.147 Test accuracy 37.090\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1503 \n",
      "Accuracy: 3790/10000 (37.90%)\n",
      "\n",
      "Round 591, Train average loss 0.130 Test accuracy 37.900\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1729 \n",
      "Accuracy: 3702/10000 (37.02%)\n",
      "\n",
      "Round 592, Train average loss 0.149 Test accuracy 37.020\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2100 \n",
      "Accuracy: 3711/10000 (37.11%)\n",
      "\n",
      "Round 593, Train average loss 0.141 Test accuracy 37.110\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1636 \n",
      "Accuracy: 3692/10000 (36.92%)\n",
      "\n",
      "Round 594, Train average loss 0.136 Test accuracy 36.920\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1165 \n",
      "Accuracy: 3755/10000 (37.55%)\n",
      "\n",
      "Round 595, Train average loss 0.141 Test accuracy 37.550\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1746 \n",
      "Accuracy: 3718/10000 (37.18%)\n",
      "\n",
      "Round 596, Train average loss 0.130 Test accuracy 37.180\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1765 \n",
      "Accuracy: 3719/10000 (37.19%)\n",
      "\n",
      "Round 597, Train average loss 0.137 Test accuracy 37.190\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1741 \n",
      "Accuracy: 3755/10000 (37.55%)\n",
      "\n",
      "Round 598, Train average loss 0.130 Test accuracy 37.550\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2089 \n",
      "Accuracy: 3644/10000 (36.44%)\n",
      "\n",
      "Round 599, Train average loss 0.142 Test accuracy 36.440\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2071 \n",
      "Accuracy: 3626/10000 (36.26%)\n",
      "\n",
      "Round 600, Train average loss 0.138 Test accuracy 36.260\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1951 \n",
      "Accuracy: 3632/10000 (36.32%)\n",
      "\n",
      "Round 601, Train average loss 0.139 Test accuracy 36.320\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1561 \n",
      "Accuracy: 3755/10000 (37.55%)\n",
      "\n",
      "Round 602, Train average loss 0.130 Test accuracy 37.550\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2235 \n",
      "Accuracy: 3665/10000 (36.65%)\n",
      "\n",
      "Round 603, Train average loss 0.135 Test accuracy 36.650\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1306 \n",
      "Accuracy: 3747/10000 (37.47%)\n",
      "\n",
      "Round 604, Train average loss 0.139 Test accuracy 37.470\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2409 \n",
      "Accuracy: 3705/10000 (37.05%)\n",
      "\n",
      "Round 605, Train average loss 0.118 Test accuracy 37.050\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1647 \n",
      "Accuracy: 3727/10000 (37.27%)\n",
      "\n",
      "Round 606, Train average loss 0.130 Test accuracy 37.270\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1581 \n",
      "Accuracy: 3691/10000 (36.91%)\n",
      "\n",
      "Round 607, Train average loss 0.149 Test accuracy 36.910\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1938 \n",
      "Accuracy: 3674/10000 (36.74%)\n",
      "\n",
      "Round 608, Train average loss 0.138 Test accuracy 36.740\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1484 \n",
      "Accuracy: 3742/10000 (37.42%)\n",
      "\n",
      "Round 609, Train average loss 0.135 Test accuracy 37.420\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1526 \n",
      "Accuracy: 3739/10000 (37.39%)\n",
      "\n",
      "Round 610, Train average loss 0.138 Test accuracy 37.390\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1563 \n",
      "Accuracy: 3740/10000 (37.40%)\n",
      "\n",
      "Round 611, Train average loss 0.130 Test accuracy 37.400\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1438 \n",
      "Accuracy: 3782/10000 (37.82%)\n",
      "\n",
      "Round 612, Train average loss 0.130 Test accuracy 37.820\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2020 \n",
      "Accuracy: 3723/10000 (37.23%)\n",
      "\n",
      "Round 613, Train average loss 0.122 Test accuracy 37.230\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1812 \n",
      "Accuracy: 3766/10000 (37.66%)\n",
      "\n",
      "Round 614, Train average loss 0.124 Test accuracy 37.660\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2027 \n",
      "Accuracy: 3700/10000 (37.00%)\n",
      "\n",
      "Round 615, Train average loss 0.136 Test accuracy 37.000\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1740 \n",
      "Accuracy: 3673/10000 (36.73%)\n",
      "\n",
      "Round 616, Train average loss 0.145 Test accuracy 36.730\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2205 \n",
      "Accuracy: 3759/10000 (37.59%)\n",
      "\n",
      "Round 617, Train average loss 0.119 Test accuracy 37.590\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1576 \n",
      "Accuracy: 3750/10000 (37.50%)\n",
      "\n",
      "Round 618, Train average loss 0.142 Test accuracy 37.500\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1405 \n",
      "Accuracy: 3750/10000 (37.50%)\n",
      "\n",
      "Round 619, Train average loss 0.142 Test accuracy 37.500\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2872 \n",
      "Accuracy: 3577/10000 (35.77%)\n",
      "\n",
      "Round 620, Train average loss 0.137 Test accuracy 35.770\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2146 \n",
      "Accuracy: 3700/10000 (37.00%)\n",
      "\n",
      "Round 621, Train average loss 0.128 Test accuracy 37.000\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2156 \n",
      "Accuracy: 3639/10000 (36.39%)\n",
      "\n",
      "Round 622, Train average loss 0.122 Test accuracy 36.390\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1386 \n",
      "Accuracy: 3742/10000 (37.42%)\n",
      "\n",
      "Round 623, Train average loss 0.138 Test accuracy 37.420\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1703 \n",
      "Accuracy: 3733/10000 (37.33%)\n",
      "\n",
      "Round 624, Train average loss 0.138 Test accuracy 37.330\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1851 \n",
      "Accuracy: 3740/10000 (37.40%)\n",
      "\n",
      "Round 625, Train average loss 0.121 Test accuracy 37.400\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2271 \n",
      "Accuracy: 3722/10000 (37.22%)\n",
      "\n",
      "Round 626, Train average loss 0.122 Test accuracy 37.220\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1571 \n",
      "Accuracy: 3780/10000 (37.80%)\n",
      "\n",
      "Round 627, Train average loss 0.124 Test accuracy 37.800\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1735 \n",
      "Accuracy: 3799/10000 (37.99%)\n",
      "\n",
      "Round 628, Train average loss 0.118 Test accuracy 37.990\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1725 \n",
      "Accuracy: 3777/10000 (37.77%)\n",
      "\n",
      "Round 629, Train average loss 0.120 Test accuracy 37.770\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2753 \n",
      "Accuracy: 3548/10000 (35.48%)\n",
      "\n",
      "Round 630, Train average loss 0.136 Test accuracy 35.480\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1699 \n",
      "Accuracy: 3755/10000 (37.55%)\n",
      "\n",
      "Round 631, Train average loss 0.130 Test accuracy 37.550\n",
      "lr= 0.004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.1959 \n",
      "Accuracy: 3766/10000 (37.66%)\n",
      "\n",
      "Round 632, Train average loss 0.125 Test accuracy 37.660\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1406 \n",
      "Accuracy: 3727/10000 (37.27%)\n",
      "\n",
      "Round 633, Train average loss 0.137 Test accuracy 37.270\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1370 \n",
      "Accuracy: 3792/10000 (37.92%)\n",
      "\n",
      "Round 634, Train average loss 0.125 Test accuracy 37.920\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2296 \n",
      "Accuracy: 3693/10000 (36.93%)\n",
      "\n",
      "Round 635, Train average loss 0.112 Test accuracy 36.930\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1872 \n",
      "Accuracy: 3710/10000 (37.10%)\n",
      "\n",
      "Round 636, Train average loss 0.120 Test accuracy 37.100\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2201 \n",
      "Accuracy: 3729/10000 (37.29%)\n",
      "\n",
      "Round 637, Train average loss 0.108 Test accuracy 37.290\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2475 \n",
      "Accuracy: 3701/10000 (37.01%)\n",
      "\n",
      "Round 638, Train average loss 0.124 Test accuracy 37.010\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2260 \n",
      "Accuracy: 3731/10000 (37.31%)\n",
      "\n",
      "Round 639, Train average loss 0.114 Test accuracy 37.310\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2530 \n",
      "Accuracy: 3618/10000 (36.18%)\n",
      "\n",
      "Round 640, Train average loss 0.131 Test accuracy 36.180\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2276 \n",
      "Accuracy: 3703/10000 (37.03%)\n",
      "\n",
      "Round 641, Train average loss 0.128 Test accuracy 37.030\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2637 \n",
      "Accuracy: 3776/10000 (37.76%)\n",
      "\n",
      "Round 642, Train average loss 0.107 Test accuracy 37.760\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2399 \n",
      "Accuracy: 3628/10000 (36.28%)\n",
      "\n",
      "Round 643, Train average loss 0.138 Test accuracy 36.280\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2956 \n",
      "Accuracy: 3632/10000 (36.32%)\n",
      "\n",
      "Round 644, Train average loss 0.127 Test accuracy 36.320\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2433 \n",
      "Accuracy: 3755/10000 (37.55%)\n",
      "\n",
      "Round 645, Train average loss 0.111 Test accuracy 37.550\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2458 \n",
      "Accuracy: 3698/10000 (36.98%)\n",
      "\n",
      "Round 646, Train average loss 0.135 Test accuracy 36.980\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3290 \n",
      "Accuracy: 3604/10000 (36.04%)\n",
      "\n",
      "Round 647, Train average loss 0.121 Test accuracy 36.040\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1586 \n",
      "Accuracy: 3778/10000 (37.78%)\n",
      "\n",
      "Round 648, Train average loss 0.137 Test accuracy 37.780\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2187 \n",
      "Accuracy: 3804/10000 (38.04%)\n",
      "\n",
      "Round 649, Train average loss 0.101 Test accuracy 38.040\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1662 \n",
      "Accuracy: 3782/10000 (37.82%)\n",
      "\n",
      "Round 650, Train average loss 0.122 Test accuracy 37.820\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1887 \n",
      "Accuracy: 3732/10000 (37.32%)\n",
      "\n",
      "Round 651, Train average loss 0.119 Test accuracy 37.320\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1806 \n",
      "Accuracy: 3793/10000 (37.93%)\n",
      "\n",
      "Round 652, Train average loss 0.112 Test accuracy 37.930\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1732 \n",
      "Accuracy: 3776/10000 (37.76%)\n",
      "\n",
      "Round 653, Train average loss 0.130 Test accuracy 37.760\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2722 \n",
      "Accuracy: 3685/10000 (36.85%)\n",
      "\n",
      "Round 654, Train average loss 0.119 Test accuracy 36.850\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2592 \n",
      "Accuracy: 3746/10000 (37.46%)\n",
      "\n",
      "Round 655, Train average loss 0.115 Test accuracy 37.460\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3145 \n",
      "Accuracy: 3709/10000 (37.09%)\n",
      "\n",
      "Round 656, Train average loss 0.122 Test accuracy 37.090\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2038 \n",
      "Accuracy: 3733/10000 (37.33%)\n",
      "\n",
      "Round 657, Train average loss 0.141 Test accuracy 37.330\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1965 \n",
      "Accuracy: 3736/10000 (37.36%)\n",
      "\n",
      "Round 658, Train average loss 0.120 Test accuracy 37.360\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2323 \n",
      "Accuracy: 3707/10000 (37.07%)\n",
      "\n",
      "Round 659, Train average loss 0.118 Test accuracy 37.070\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2373 \n",
      "Accuracy: 3697/10000 (36.97%)\n",
      "\n",
      "Round 660, Train average loss 0.118 Test accuracy 36.970\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2069 \n",
      "Accuracy: 3719/10000 (37.19%)\n",
      "\n",
      "Round 661, Train average loss 0.111 Test accuracy 37.190\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1890 \n",
      "Accuracy: 3796/10000 (37.96%)\n",
      "\n",
      "Round 662, Train average loss 0.127 Test accuracy 37.960\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2197 \n",
      "Accuracy: 3781/10000 (37.81%)\n",
      "\n",
      "Round 663, Train average loss 0.114 Test accuracy 37.810\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1851 \n",
      "Accuracy: 3806/10000 (38.06%)\n",
      "\n",
      "Round 664, Train average loss 0.108 Test accuracy 38.060\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1788 \n",
      "Accuracy: 3857/10000 (38.57%)\n",
      "\n",
      "Round 665, Train average loss 0.103 Test accuracy 38.570\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1646 \n",
      "Accuracy: 3835/10000 (38.35%)\n",
      "\n",
      "Round 666, Train average loss 0.116 Test accuracy 38.350\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2714 \n",
      "Accuracy: 3717/10000 (37.17%)\n",
      "\n",
      "Round 667, Train average loss 0.116 Test accuracy 37.170\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3502 \n",
      "Accuracy: 3642/10000 (36.42%)\n",
      "\n",
      "Round 668, Train average loss 0.107 Test accuracy 36.420\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2090 \n",
      "Accuracy: 3809/10000 (38.09%)\n",
      "\n",
      "Round 669, Train average loss 0.113 Test accuracy 38.090\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2315 \n",
      "Accuracy: 3827/10000 (38.27%)\n",
      "\n",
      "Round 670, Train average loss 0.098 Test accuracy 38.270\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1810 \n",
      "Accuracy: 3865/10000 (38.65%)\n",
      "\n",
      "Round 671, Train average loss 0.108 Test accuracy 38.650\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2334 \n",
      "Accuracy: 3763/10000 (37.63%)\n",
      "\n",
      "Round 672, Train average loss 0.116 Test accuracy 37.630\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2654 \n",
      "Accuracy: 3738/10000 (37.38%)\n",
      "\n",
      "Round 673, Train average loss 0.119 Test accuracy 37.380\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2050 \n",
      "Accuracy: 3848/10000 (38.48%)\n",
      "\n",
      "Round 674, Train average loss 0.111 Test accuracy 38.480\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2894 \n",
      "Accuracy: 3675/10000 (36.75%)\n",
      "\n",
      "Round 675, Train average loss 0.127 Test accuracy 36.750\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2520 \n",
      "Accuracy: 3730/10000 (37.30%)\n",
      "\n",
      "Round 676, Train average loss 0.108 Test accuracy 37.300\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3539 \n",
      "Accuracy: 3703/10000 (37.03%)\n",
      "\n",
      "Round 677, Train average loss 0.123 Test accuracy 37.030\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1949 \n",
      "Accuracy: 3827/10000 (38.27%)\n",
      "\n",
      "Round 678, Train average loss 0.115 Test accuracy 38.270\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1972 \n",
      "Accuracy: 3782/10000 (37.82%)\n",
      "\n",
      "Round 679, Train average loss 0.122 Test accuracy 37.820\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2706 \n",
      "Accuracy: 3730/10000 (37.30%)\n",
      "\n",
      "Round 680, Train average loss 0.105 Test accuracy 37.300\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3164 \n",
      "Accuracy: 3654/10000 (36.54%)\n",
      "\n",
      "Round 681, Train average loss 0.112 Test accuracy 36.540\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3180 \n",
      "Accuracy: 3669/10000 (36.69%)\n",
      "\n",
      "Round 682, Train average loss 0.126 Test accuracy 36.690\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3805 \n",
      "Accuracy: 3598/10000 (35.98%)\n",
      "\n",
      "Round 683, Train average loss 0.102 Test accuracy 35.980\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2966 \n",
      "Accuracy: 3771/10000 (37.71%)\n",
      "\n",
      "Round 684, Train average loss 0.102 Test accuracy 37.710\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2009 \n",
      "Accuracy: 3809/10000 (38.09%)\n",
      "\n",
      "Round 685, Train average loss 0.111 Test accuracy 38.090\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2121 \n",
      "Accuracy: 3820/10000 (38.20%)\n",
      "\n",
      "Round 686, Train average loss 0.108 Test accuracy 38.200\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1905 \n",
      "Accuracy: 3788/10000 (37.88%)\n",
      "\n",
      "Round 687, Train average loss 0.109 Test accuracy 37.880\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2321 \n",
      "Accuracy: 3822/10000 (38.22%)\n",
      "\n",
      "Round 688, Train average loss 0.096 Test accuracy 38.220\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2059 \n",
      "Accuracy: 3749/10000 (37.49%)\n",
      "\n",
      "Round 689, Train average loss 0.120 Test accuracy 37.490\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2476 \n",
      "Accuracy: 3715/10000 (37.15%)\n",
      "\n",
      "Round 690, Train average loss 0.110 Test accuracy 37.150\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2192 \n",
      "Accuracy: 3735/10000 (37.35%)\n",
      "\n",
      "Round 691, Train average loss 0.120 Test accuracy 37.350\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3065 \n",
      "Accuracy: 3703/10000 (37.03%)\n",
      "\n",
      "Round 692, Train average loss 0.109 Test accuracy 37.030\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2124 \n",
      "Accuracy: 3795/10000 (37.95%)\n",
      "\n",
      "Round 693, Train average loss 0.113 Test accuracy 37.950\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3042 \n",
      "Accuracy: 3695/10000 (36.95%)\n",
      "\n",
      "Round 694, Train average loss 0.113 Test accuracy 36.950\n",
      "lr= 0.004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.1747 \n",
      "Accuracy: 3763/10000 (37.63%)\n",
      "\n",
      "Round 695, Train average loss 0.124 Test accuracy 37.630\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2184 \n",
      "Accuracy: 3819/10000 (38.19%)\n",
      "\n",
      "Round 696, Train average loss 0.107 Test accuracy 38.190\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2569 \n",
      "Accuracy: 3805/10000 (38.05%)\n",
      "\n",
      "Round 697, Train average loss 0.103 Test accuracy 38.050\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3140 \n",
      "Accuracy: 3720/10000 (37.20%)\n",
      "\n",
      "Round 698, Train average loss 0.101 Test accuracy 37.200\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2462 \n",
      "Accuracy: 3735/10000 (37.35%)\n",
      "\n",
      "Round 699, Train average loss 0.113 Test accuracy 37.350\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3096 \n",
      "Accuracy: 3749/10000 (37.49%)\n",
      "\n",
      "Round 700, Train average loss 0.102 Test accuracy 37.490\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2964 \n",
      "Accuracy: 3706/10000 (37.06%)\n",
      "\n",
      "Round 701, Train average loss 0.114 Test accuracy 37.060\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3888 \n",
      "Accuracy: 3628/10000 (36.28%)\n",
      "\n",
      "Round 702, Train average loss 0.106 Test accuracy 36.280\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2355 \n",
      "Accuracy: 3809/10000 (38.09%)\n",
      "\n",
      "Round 703, Train average loss 0.115 Test accuracy 38.090\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3181 \n",
      "Accuracy: 3832/10000 (38.32%)\n",
      "\n",
      "Round 704, Train average loss 0.096 Test accuracy 38.320\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2875 \n",
      "Accuracy: 3683/10000 (36.83%)\n",
      "\n",
      "Round 705, Train average loss 0.126 Test accuracy 36.830\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2775 \n",
      "Accuracy: 3692/10000 (36.92%)\n",
      "\n",
      "Round 706, Train average loss 0.108 Test accuracy 36.920\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2975 \n",
      "Accuracy: 3785/10000 (37.85%)\n",
      "\n",
      "Round 707, Train average loss 0.106 Test accuracy 37.850\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2059 \n",
      "Accuracy: 3817/10000 (38.17%)\n",
      "\n",
      "Round 708, Train average loss 0.116 Test accuracy 38.170\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2314 \n",
      "Accuracy: 3760/10000 (37.60%)\n",
      "\n",
      "Round 709, Train average loss 0.109 Test accuracy 37.600\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2225 \n",
      "Accuracy: 3757/10000 (37.57%)\n",
      "\n",
      "Round 710, Train average loss 0.109 Test accuracy 37.570\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.1888 \n",
      "Accuracy: 3839/10000 (38.39%)\n",
      "\n",
      "Round 711, Train average loss 0.112 Test accuracy 38.390\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2342 \n",
      "Accuracy: 3832/10000 (38.32%)\n",
      "\n",
      "Round 712, Train average loss 0.099 Test accuracy 38.320\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2806 \n",
      "Accuracy: 3738/10000 (37.38%)\n",
      "\n",
      "Round 713, Train average loss 0.113 Test accuracy 37.380\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2554 \n",
      "Accuracy: 3739/10000 (37.39%)\n",
      "\n",
      "Round 714, Train average loss 0.119 Test accuracy 37.390\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2376 \n",
      "Accuracy: 3801/10000 (38.01%)\n",
      "\n",
      "Round 715, Train average loss 0.103 Test accuracy 38.010\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2309 \n",
      "Accuracy: 3750/10000 (37.50%)\n",
      "\n",
      "Round 716, Train average loss 0.111 Test accuracy 37.500\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3195 \n",
      "Accuracy: 3688/10000 (36.88%)\n",
      "\n",
      "Round 717, Train average loss 0.092 Test accuracy 36.880\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2674 \n",
      "Accuracy: 3710/10000 (37.10%)\n",
      "\n",
      "Round 718, Train average loss 0.112 Test accuracy 37.100\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3445 \n",
      "Accuracy: 3643/10000 (36.43%)\n",
      "\n",
      "Round 719, Train average loss 0.099 Test accuracy 36.430\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3486 \n",
      "Accuracy: 3723/10000 (37.23%)\n",
      "\n",
      "Round 720, Train average loss 0.093 Test accuracy 37.230\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2649 \n",
      "Accuracy: 3819/10000 (38.19%)\n",
      "\n",
      "Round 721, Train average loss 0.097 Test accuracy 38.190\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2646 \n",
      "Accuracy: 3803/10000 (38.03%)\n",
      "\n",
      "Round 722, Train average loss 0.104 Test accuracy 38.030\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2667 \n",
      "Accuracy: 3776/10000 (37.76%)\n",
      "\n",
      "Round 723, Train average loss 0.117 Test accuracy 37.760\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3340 \n",
      "Accuracy: 3778/10000 (37.78%)\n",
      "\n",
      "Round 724, Train average loss 0.098 Test accuracy 37.780\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2365 \n",
      "Accuracy: 3798/10000 (37.98%)\n",
      "\n",
      "Round 725, Train average loss 0.105 Test accuracy 37.980\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2691 \n",
      "Accuracy: 3725/10000 (37.25%)\n",
      "\n",
      "Round 726, Train average loss 0.095 Test accuracy 37.250\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2642 \n",
      "Accuracy: 3797/10000 (37.97%)\n",
      "\n",
      "Round 727, Train average loss 0.097 Test accuracy 37.970\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2935 \n",
      "Accuracy: 3817/10000 (38.17%)\n",
      "\n",
      "Round 728, Train average loss 0.100 Test accuracy 38.170\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3895 \n",
      "Accuracy: 3778/10000 (37.78%)\n",
      "\n",
      "Round 729, Train average loss 0.083 Test accuracy 37.780\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.4739 \n",
      "Accuracy: 3638/10000 (36.38%)\n",
      "\n",
      "Round 730, Train average loss 0.090 Test accuracy 36.380\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2526 \n",
      "Accuracy: 3856/10000 (38.56%)\n",
      "\n",
      "Round 731, Train average loss 0.104 Test accuracy 38.560\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2829 \n",
      "Accuracy: 3801/10000 (38.01%)\n",
      "\n",
      "Round 732, Train average loss 0.092 Test accuracy 38.010\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3460 \n",
      "Accuracy: 3749/10000 (37.49%)\n",
      "\n",
      "Round 733, Train average loss 0.113 Test accuracy 37.490\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2916 \n",
      "Accuracy: 3777/10000 (37.77%)\n",
      "\n",
      "Round 734, Train average loss 0.104 Test accuracy 37.770\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2381 \n",
      "Accuracy: 3848/10000 (38.48%)\n",
      "\n",
      "Round 735, Train average loss 0.104 Test accuracy 38.480\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3071 \n",
      "Accuracy: 3711/10000 (37.11%)\n",
      "\n",
      "Round 736, Train average loss 0.103 Test accuracy 37.110\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2185 \n",
      "Accuracy: 3762/10000 (37.62%)\n",
      "\n",
      "Round 737, Train average loss 0.118 Test accuracy 37.620\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2972 \n",
      "Accuracy: 3709/10000 (37.09%)\n",
      "\n",
      "Round 738, Train average loss 0.103 Test accuracy 37.090\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2424 \n",
      "Accuracy: 3737/10000 (37.37%)\n",
      "\n",
      "Round 739, Train average loss 0.107 Test accuracy 37.370\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2995 \n",
      "Accuracy: 3744/10000 (37.44%)\n",
      "\n",
      "Round 740, Train average loss 0.094 Test accuracy 37.440\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3187 \n",
      "Accuracy: 3705/10000 (37.05%)\n",
      "\n",
      "Round 741, Train average loss 0.098 Test accuracy 37.050\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2767 \n",
      "Accuracy: 3786/10000 (37.86%)\n",
      "\n",
      "Round 742, Train average loss 0.103 Test accuracy 37.860\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2387 \n",
      "Accuracy: 3725/10000 (37.25%)\n",
      "\n",
      "Round 743, Train average loss 0.113 Test accuracy 37.250\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3556 \n",
      "Accuracy: 3659/10000 (36.59%)\n",
      "\n",
      "Round 744, Train average loss 0.088 Test accuracy 36.590\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.4080 \n",
      "Accuracy: 3576/10000 (35.76%)\n",
      "\n",
      "Round 745, Train average loss 0.104 Test accuracy 35.760\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2675 \n",
      "Accuracy: 3737/10000 (37.37%)\n",
      "\n",
      "Round 746, Train average loss 0.107 Test accuracy 37.370\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2593 \n",
      "Accuracy: 3777/10000 (37.77%)\n",
      "\n",
      "Round 747, Train average loss 0.106 Test accuracy 37.770\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3125 \n",
      "Accuracy: 3735/10000 (37.35%)\n",
      "\n",
      "Round 748, Train average loss 0.098 Test accuracy 37.350\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.4678 \n",
      "Accuracy: 3581/10000 (35.81%)\n",
      "\n",
      "Round 749, Train average loss 0.093 Test accuracy 35.810\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2264 \n",
      "Accuracy: 3734/10000 (37.34%)\n",
      "\n",
      "Round 750, Train average loss 0.117 Test accuracy 37.340\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2670 \n",
      "Accuracy: 3735/10000 (37.35%)\n",
      "\n",
      "Round 751, Train average loss 0.099 Test accuracy 37.350\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3129 \n",
      "Accuracy: 3763/10000 (37.63%)\n",
      "\n",
      "Round 752, Train average loss 0.090 Test accuracy 37.630\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2651 \n",
      "Accuracy: 3749/10000 (37.49%)\n",
      "\n",
      "Round 753, Train average loss 0.112 Test accuracy 37.490\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2600 \n",
      "Accuracy: 3796/10000 (37.96%)\n",
      "\n",
      "Round 754, Train average loss 0.104 Test accuracy 37.960\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3375 \n",
      "Accuracy: 3623/10000 (36.23%)\n",
      "\n",
      "Round 755, Train average loss 0.109 Test accuracy 36.230\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3222 \n",
      "Accuracy: 3780/10000 (37.80%)\n",
      "\n",
      "Round 756, Train average loss 0.084 Test accuracy 37.800\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2666 \n",
      "Accuracy: 3744/10000 (37.44%)\n",
      "\n",
      "Round 757, Train average loss 0.112 Test accuracy 37.440\n",
      "lr= 0.004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.3459 \n",
      "Accuracy: 3665/10000 (36.65%)\n",
      "\n",
      "Round 758, Train average loss 0.109 Test accuracy 36.650\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2487 \n",
      "Accuracy: 3785/10000 (37.85%)\n",
      "\n",
      "Round 759, Train average loss 0.105 Test accuracy 37.850\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2942 \n",
      "Accuracy: 3777/10000 (37.77%)\n",
      "\n",
      "Round 760, Train average loss 0.104 Test accuracy 37.770\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2962 \n",
      "Accuracy: 3763/10000 (37.63%)\n",
      "\n",
      "Round 761, Train average loss 0.105 Test accuracy 37.630\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2734 \n",
      "Accuracy: 3698/10000 (36.98%)\n",
      "\n",
      "Round 762, Train average loss 0.107 Test accuracy 36.980\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3117 \n",
      "Accuracy: 3782/10000 (37.82%)\n",
      "\n",
      "Round 763, Train average loss 0.089 Test accuracy 37.820\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2505 \n",
      "Accuracy: 3819/10000 (38.19%)\n",
      "\n",
      "Round 764, Train average loss 0.108 Test accuracy 38.190\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2338 \n",
      "Accuracy: 3850/10000 (38.50%)\n",
      "\n",
      "Round 765, Train average loss 0.095 Test accuracy 38.500\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2465 \n",
      "Accuracy: 3768/10000 (37.68%)\n",
      "\n",
      "Round 766, Train average loss 0.103 Test accuracy 37.680\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3163 \n",
      "Accuracy: 3796/10000 (37.96%)\n",
      "\n",
      "Round 767, Train average loss 0.085 Test accuracy 37.960\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3792 \n",
      "Accuracy: 3603/10000 (36.03%)\n",
      "\n",
      "Round 768, Train average loss 0.109 Test accuracy 36.030\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2612 \n",
      "Accuracy: 3806/10000 (38.06%)\n",
      "\n",
      "Round 769, Train average loss 0.092 Test accuracy 38.060\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3990 \n",
      "Accuracy: 3694/10000 (36.94%)\n",
      "\n",
      "Round 770, Train average loss 0.075 Test accuracy 36.940\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3027 \n",
      "Accuracy: 3673/10000 (36.73%)\n",
      "\n",
      "Round 771, Train average loss 0.121 Test accuracy 36.730\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3390 \n",
      "Accuracy: 3743/10000 (37.43%)\n",
      "\n",
      "Round 772, Train average loss 0.093 Test accuracy 37.430\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2073 \n",
      "Accuracy: 3825/10000 (38.25%)\n",
      "\n",
      "Round 773, Train average loss 0.109 Test accuracy 38.250\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2794 \n",
      "Accuracy: 3738/10000 (37.38%)\n",
      "\n",
      "Round 774, Train average loss 0.101 Test accuracy 37.380\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3524 \n",
      "Accuracy: 3726/10000 (37.26%)\n",
      "\n",
      "Round 775, Train average loss 0.093 Test accuracy 37.260\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3829 \n",
      "Accuracy: 3709/10000 (37.09%)\n",
      "\n",
      "Round 776, Train average loss 0.098 Test accuracy 37.090\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3174 \n",
      "Accuracy: 3700/10000 (37.00%)\n",
      "\n",
      "Round 777, Train average loss 0.100 Test accuracy 37.000\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.4213 \n",
      "Accuracy: 3628/10000 (36.28%)\n",
      "\n",
      "Round 778, Train average loss 0.090 Test accuracy 36.280\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3750 \n",
      "Accuracy: 3692/10000 (36.92%)\n",
      "\n",
      "Round 779, Train average loss 0.079 Test accuracy 36.920\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3081 \n",
      "Accuracy: 3776/10000 (37.76%)\n",
      "\n",
      "Round 780, Train average loss 0.100 Test accuracy 37.760\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3212 \n",
      "Accuracy: 3693/10000 (36.93%)\n",
      "\n",
      "Round 781, Train average loss 0.093 Test accuracy 36.930\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.4337 \n",
      "Accuracy: 3606/10000 (36.06%)\n",
      "\n",
      "Round 782, Train average loss 0.092 Test accuracy 36.060\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3257 \n",
      "Accuracy: 3700/10000 (37.00%)\n",
      "\n",
      "Round 783, Train average loss 0.096 Test accuracy 37.000\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.4204 \n",
      "Accuracy: 3708/10000 (37.08%)\n",
      "\n",
      "Round 784, Train average loss 0.088 Test accuracy 37.080\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3012 \n",
      "Accuracy: 3798/10000 (37.98%)\n",
      "\n",
      "Round 785, Train average loss 0.095 Test accuracy 37.980\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3959 \n",
      "Accuracy: 3623/10000 (36.23%)\n",
      "\n",
      "Round 786, Train average loss 0.098 Test accuracy 36.230\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2882 \n",
      "Accuracy: 3695/10000 (36.95%)\n",
      "\n",
      "Round 787, Train average loss 0.108 Test accuracy 36.950\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.4056 \n",
      "Accuracy: 3601/10000 (36.01%)\n",
      "\n",
      "Round 788, Train average loss 0.104 Test accuracy 36.010\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2580 \n",
      "Accuracy: 3837/10000 (38.37%)\n",
      "\n",
      "Round 789, Train average loss 0.098 Test accuracy 38.370\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3049 \n",
      "Accuracy: 3769/10000 (37.69%)\n",
      "\n",
      "Round 790, Train average loss 0.085 Test accuracy 37.690\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3019 \n",
      "Accuracy: 3823/10000 (38.23%)\n",
      "\n",
      "Round 791, Train average loss 0.085 Test accuracy 38.230\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3271 \n",
      "Accuracy: 3836/10000 (38.36%)\n",
      "\n",
      "Round 792, Train average loss 0.085 Test accuracy 38.360\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2498 \n",
      "Accuracy: 3822/10000 (38.22%)\n",
      "\n",
      "Round 793, Train average loss 0.097 Test accuracy 38.220\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.4277 \n",
      "Accuracy: 3640/10000 (36.40%)\n",
      "\n",
      "Round 794, Train average loss 0.095 Test accuracy 36.400\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2191 \n",
      "Accuracy: 3888/10000 (38.88%)\n",
      "\n",
      "Round 795, Train average loss 0.096 Test accuracy 38.880\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3243 \n",
      "Accuracy: 3839/10000 (38.39%)\n",
      "\n",
      "Round 796, Train average loss 0.078 Test accuracy 38.390\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.3491 \n",
      "Accuracy: 3741/10000 (37.41%)\n",
      "\n",
      "Round 797, Train average loss 0.093 Test accuracy 37.410\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.2765 \n",
      "Accuracy: 3854/10000 (38.54%)\n",
      "\n",
      "Round 798, Train average loss 0.085 Test accuracy 38.540\n",
      "lr= 0.004\n",
      "\n",
      "Test set: Average loss: 2.4159 \n",
      "Accuracy: 3686/10000 (36.86%)\n",
      "\n",
      "Round 799, Train average loss 0.091 Test accuracy 36.860\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3465 \n",
      "Accuracy: 3703/10000 (37.03%)\n",
      "\n",
      "Round 800, Train average loss 0.157 Test accuracy 37.030\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4451 \n",
      "Accuracy: 3641/10000 (36.41%)\n",
      "\n",
      "Round 801, Train average loss 0.142 Test accuracy 36.410\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3312 \n",
      "Accuracy: 3732/10000 (37.32%)\n",
      "\n",
      "Round 802, Train average loss 0.172 Test accuracy 37.320\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3088 \n",
      "Accuracy: 3848/10000 (38.48%)\n",
      "\n",
      "Round 803, Train average loss 0.143 Test accuracy 38.480\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2707 \n",
      "Accuracy: 3896/10000 (38.96%)\n",
      "\n",
      "Round 804, Train average loss 0.139 Test accuracy 38.960\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3170 \n",
      "Accuracy: 3782/10000 (37.82%)\n",
      "\n",
      "Round 805, Train average loss 0.147 Test accuracy 37.820\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5052 \n",
      "Accuracy: 3689/10000 (36.89%)\n",
      "\n",
      "Round 806, Train average loss 0.127 Test accuracy 36.890\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4289 \n",
      "Accuracy: 3749/10000 (37.49%)\n",
      "\n",
      "Round 807, Train average loss 0.140 Test accuracy 37.490\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4505 \n",
      "Accuracy: 3780/10000 (37.80%)\n",
      "\n",
      "Round 808, Train average loss 0.122 Test accuracy 37.800\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5103 \n",
      "Accuracy: 3758/10000 (37.58%)\n",
      "\n",
      "Round 809, Train average loss 0.125 Test accuracy 37.580\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5067 \n",
      "Accuracy: 3792/10000 (37.92%)\n",
      "\n",
      "Round 810, Train average loss 0.120 Test accuracy 37.920\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.6155 \n",
      "Accuracy: 3619/10000 (36.19%)\n",
      "\n",
      "Round 811, Train average loss 0.102 Test accuracy 36.190\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4502 \n",
      "Accuracy: 3695/10000 (36.95%)\n",
      "\n",
      "Round 812, Train average loss 0.138 Test accuracy 36.950\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4625 \n",
      "Accuracy: 3767/10000 (37.67%)\n",
      "\n",
      "Round 813, Train average loss 0.124 Test accuracy 37.670\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.6864 \n",
      "Accuracy: 3541/10000 (35.41%)\n",
      "\n",
      "Round 814, Train average loss 0.122 Test accuracy 35.410\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3054 \n",
      "Accuracy: 3948/10000 (39.48%)\n",
      "\n",
      "Round 815, Train average loss 0.162 Test accuracy 39.480\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3327 \n",
      "Accuracy: 3877/10000 (38.77%)\n",
      "\n",
      "Round 816, Train average loss 0.117 Test accuracy 38.770\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.6120 \n",
      "Accuracy: 3716/10000 (37.16%)\n",
      "\n",
      "Round 817, Train average loss 0.095 Test accuracy 37.160\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.6321 \n",
      "Accuracy: 3664/10000 (36.64%)\n",
      "\n",
      "Round 818, Train average loss 0.101 Test accuracy 36.640\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3691 \n",
      "Accuracy: 3839/10000 (38.39%)\n",
      "\n",
      "Round 819, Train average loss 0.148 Test accuracy 38.390\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4679 \n",
      "Accuracy: 3752/10000 (37.52%)\n",
      "\n",
      "Round 820, Train average loss 0.113 Test accuracy 37.520\n",
      "lr= 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.4118 \n",
      "Accuracy: 3777/10000 (37.77%)\n",
      "\n",
      "Round 821, Train average loss 0.121 Test accuracy 37.770\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3616 \n",
      "Accuracy: 3839/10000 (38.39%)\n",
      "\n",
      "Round 822, Train average loss 0.117 Test accuracy 38.390\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3390 \n",
      "Accuracy: 3769/10000 (37.69%)\n",
      "\n",
      "Round 823, Train average loss 0.135 Test accuracy 37.690\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5335 \n",
      "Accuracy: 3620/10000 (36.20%)\n",
      "\n",
      "Round 824, Train average loss 0.123 Test accuracy 36.200\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4597 \n",
      "Accuracy: 3681/10000 (36.81%)\n",
      "\n",
      "Round 825, Train average loss 0.119 Test accuracy 36.810\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5100 \n",
      "Accuracy: 3643/10000 (36.43%)\n",
      "\n",
      "Round 826, Train average loss 0.135 Test accuracy 36.430\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4254 \n",
      "Accuracy: 3753/10000 (37.53%)\n",
      "\n",
      "Round 827, Train average loss 0.121 Test accuracy 37.530\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3281 \n",
      "Accuracy: 3863/10000 (38.63%)\n",
      "\n",
      "Round 828, Train average loss 0.123 Test accuracy 38.630\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4367 \n",
      "Accuracy: 3757/10000 (37.57%)\n",
      "\n",
      "Round 829, Train average loss 0.107 Test accuracy 37.570\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3379 \n",
      "Accuracy: 3799/10000 (37.99%)\n",
      "\n",
      "Round 830, Train average loss 0.129 Test accuracy 37.990\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2717 \n",
      "Accuracy: 3888/10000 (38.88%)\n",
      "\n",
      "Round 831, Train average loss 0.128 Test accuracy 38.880\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4228 \n",
      "Accuracy: 3746/10000 (37.46%)\n",
      "\n",
      "Round 832, Train average loss 0.098 Test accuracy 37.460\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4422 \n",
      "Accuracy: 3737/10000 (37.37%)\n",
      "\n",
      "Round 833, Train average loss 0.119 Test accuracy 37.370\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3910 \n",
      "Accuracy: 3798/10000 (37.98%)\n",
      "\n",
      "Round 834, Train average loss 0.117 Test accuracy 37.980\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4222 \n",
      "Accuracy: 3704/10000 (37.04%)\n",
      "\n",
      "Round 835, Train average loss 0.128 Test accuracy 37.040\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4508 \n",
      "Accuracy: 3619/10000 (36.19%)\n",
      "\n",
      "Round 836, Train average loss 0.129 Test accuracy 36.190\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4420 \n",
      "Accuracy: 3663/10000 (36.63%)\n",
      "\n",
      "Round 837, Train average loss 0.111 Test accuracy 36.630\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3767 \n",
      "Accuracy: 3728/10000 (37.28%)\n",
      "\n",
      "Round 838, Train average loss 0.142 Test accuracy 37.280\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3634 \n",
      "Accuracy: 3786/10000 (37.86%)\n",
      "\n",
      "Round 839, Train average loss 0.123 Test accuracy 37.860\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.7215 \n",
      "Accuracy: 3344/10000 (33.44%)\n",
      "\n",
      "Round 840, Train average loss 0.104 Test accuracy 33.440\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.6849 \n",
      "Accuracy: 3336/10000 (33.36%)\n",
      "\n",
      "Round 841, Train average loss 0.130 Test accuracy 33.360\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3040 \n",
      "Accuracy: 3841/10000 (38.41%)\n",
      "\n",
      "Round 842, Train average loss 0.131 Test accuracy 38.410\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3151 \n",
      "Accuracy: 3745/10000 (37.45%)\n",
      "\n",
      "Round 843, Train average loss 0.125 Test accuracy 37.450\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4965 \n",
      "Accuracy: 3568/10000 (35.68%)\n",
      "\n",
      "Round 844, Train average loss 0.129 Test accuracy 35.680\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3855 \n",
      "Accuracy: 3736/10000 (37.36%)\n",
      "\n",
      "Round 845, Train average loss 0.114 Test accuracy 37.360\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2874 \n",
      "Accuracy: 3860/10000 (38.60%)\n",
      "\n",
      "Round 846, Train average loss 0.108 Test accuracy 38.600\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3059 \n",
      "Accuracy: 3839/10000 (38.39%)\n",
      "\n",
      "Round 847, Train average loss 0.121 Test accuracy 38.390\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5446 \n",
      "Accuracy: 3522/10000 (35.22%)\n",
      "\n",
      "Round 848, Train average loss 0.113 Test accuracy 35.220\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3562 \n",
      "Accuracy: 3715/10000 (37.15%)\n",
      "\n",
      "Round 849, Train average loss 0.117 Test accuracy 37.150\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3158 \n",
      "Accuracy: 3823/10000 (38.23%)\n",
      "\n",
      "Round 850, Train average loss 0.112 Test accuracy 38.230\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3797 \n",
      "Accuracy: 3737/10000 (37.37%)\n",
      "\n",
      "Round 851, Train average loss 0.118 Test accuracy 37.370\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4016 \n",
      "Accuracy: 3662/10000 (36.62%)\n",
      "\n",
      "Round 852, Train average loss 0.119 Test accuracy 36.620\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3524 \n",
      "Accuracy: 3839/10000 (38.39%)\n",
      "\n",
      "Round 853, Train average loss 0.102 Test accuracy 38.390\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.7904 \n",
      "Accuracy: 3534/10000 (35.34%)\n",
      "\n",
      "Round 854, Train average loss 0.128 Test accuracy 35.340\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3973 \n",
      "Accuracy: 3753/10000 (37.53%)\n",
      "\n",
      "Round 855, Train average loss 0.128 Test accuracy 37.530\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3640 \n",
      "Accuracy: 3838/10000 (38.38%)\n",
      "\n",
      "Round 856, Train average loss 0.098 Test accuracy 38.380\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3763 \n",
      "Accuracy: 3755/10000 (37.55%)\n",
      "\n",
      "Round 857, Train average loss 0.123 Test accuracy 37.550\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3600 \n",
      "Accuracy: 3741/10000 (37.41%)\n",
      "\n",
      "Round 858, Train average loss 0.132 Test accuracy 37.410\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3230 \n",
      "Accuracy: 3771/10000 (37.71%)\n",
      "\n",
      "Round 859, Train average loss 0.114 Test accuracy 37.710\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3055 \n",
      "Accuracy: 3818/10000 (38.18%)\n",
      "\n",
      "Round 860, Train average loss 0.110 Test accuracy 38.180\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3420 \n",
      "Accuracy: 3749/10000 (37.49%)\n",
      "\n",
      "Round 861, Train average loss 0.107 Test accuracy 37.490\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.6666 \n",
      "Accuracy: 3473/10000 (34.73%)\n",
      "\n",
      "Round 862, Train average loss 0.094 Test accuracy 34.730\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2990 \n",
      "Accuracy: 3853/10000 (38.53%)\n",
      "\n",
      "Round 863, Train average loss 0.130 Test accuracy 38.530\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3485 \n",
      "Accuracy: 3761/10000 (37.61%)\n",
      "\n",
      "Round 864, Train average loss 0.114 Test accuracy 37.610\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2827 \n",
      "Accuracy: 3861/10000 (38.61%)\n",
      "\n",
      "Round 865, Train average loss 0.112 Test accuracy 38.610\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4341 \n",
      "Accuracy: 3733/10000 (37.33%)\n",
      "\n",
      "Round 866, Train average loss 0.088 Test accuracy 37.330\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5376 \n",
      "Accuracy: 3603/10000 (36.03%)\n",
      "\n",
      "Round 867, Train average loss 0.085 Test accuracy 36.030\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4461 \n",
      "Accuracy: 3670/10000 (36.70%)\n",
      "\n",
      "Round 868, Train average loss 0.120 Test accuracy 36.700\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3545 \n",
      "Accuracy: 3843/10000 (38.43%)\n",
      "\n",
      "Round 869, Train average loss 0.105 Test accuracy 38.430\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3937 \n",
      "Accuracy: 3758/10000 (37.58%)\n",
      "\n",
      "Round 870, Train average loss 0.101 Test accuracy 37.580\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5275 \n",
      "Accuracy: 3570/10000 (35.70%)\n",
      "\n",
      "Round 871, Train average loss 0.099 Test accuracy 35.700\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5158 \n",
      "Accuracy: 3646/10000 (36.46%)\n",
      "\n",
      "Round 872, Train average loss 0.097 Test accuracy 36.460\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3337 \n",
      "Accuracy: 3826/10000 (38.26%)\n",
      "\n",
      "Round 873, Train average loss 0.128 Test accuracy 38.260\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5331 \n",
      "Accuracy: 3572/10000 (35.72%)\n",
      "\n",
      "Round 874, Train average loss 0.115 Test accuracy 35.720\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3583 \n",
      "Accuracy: 3738/10000 (37.38%)\n",
      "\n",
      "Round 875, Train average loss 0.119 Test accuracy 37.380\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5090 \n",
      "Accuracy: 3575/10000 (35.75%)\n",
      "\n",
      "Round 876, Train average loss 0.111 Test accuracy 35.750\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3788 \n",
      "Accuracy: 3776/10000 (37.76%)\n",
      "\n",
      "Round 877, Train average loss 0.100 Test accuracy 37.760\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3752 \n",
      "Accuracy: 3760/10000 (37.60%)\n",
      "\n",
      "Round 878, Train average loss 0.103 Test accuracy 37.600\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3764 \n",
      "Accuracy: 3782/10000 (37.82%)\n",
      "\n",
      "Round 879, Train average loss 0.108 Test accuracy 37.820\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3597 \n",
      "Accuracy: 3749/10000 (37.49%)\n",
      "\n",
      "Round 880, Train average loss 0.109 Test accuracy 37.490\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3113 \n",
      "Accuracy: 3852/10000 (38.52%)\n",
      "\n",
      "Round 881, Train average loss 0.108 Test accuracy 38.520\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5210 \n",
      "Accuracy: 3600/10000 (36.00%)\n",
      "\n",
      "Round 882, Train average loss 0.097 Test accuracy 36.000\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5921 \n",
      "Accuracy: 3618/10000 (36.18%)\n",
      "\n",
      "Round 883, Train average loss 0.083 Test accuracy 36.180\n",
      "lr= 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.5346 \n",
      "Accuracy: 3738/10000 (37.38%)\n",
      "\n",
      "Round 884, Train average loss 0.098 Test accuracy 37.380\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4466 \n",
      "Accuracy: 3790/10000 (37.90%)\n",
      "\n",
      "Round 885, Train average loss 0.093 Test accuracy 37.900\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4096 \n",
      "Accuracy: 3808/10000 (38.08%)\n",
      "\n",
      "Round 886, Train average loss 0.092 Test accuracy 38.080\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4787 \n",
      "Accuracy: 3707/10000 (37.07%)\n",
      "\n",
      "Round 887, Train average loss 0.085 Test accuracy 37.070\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3971 \n",
      "Accuracy: 3770/10000 (37.70%)\n",
      "\n",
      "Round 888, Train average loss 0.111 Test accuracy 37.700\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3949 \n",
      "Accuracy: 3765/10000 (37.65%)\n",
      "\n",
      "Round 889, Train average loss 0.105 Test accuracy 37.650\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3891 \n",
      "Accuracy: 3831/10000 (38.31%)\n",
      "\n",
      "Round 890, Train average loss 0.096 Test accuracy 38.310\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4895 \n",
      "Accuracy: 3729/10000 (37.29%)\n",
      "\n",
      "Round 891, Train average loss 0.096 Test accuracy 37.290\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3926 \n",
      "Accuracy: 3731/10000 (37.31%)\n",
      "\n",
      "Round 892, Train average loss 0.106 Test accuracy 37.310\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4598 \n",
      "Accuracy: 3662/10000 (36.62%)\n",
      "\n",
      "Round 893, Train average loss 0.097 Test accuracy 36.620\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2786 \n",
      "Accuracy: 3894/10000 (38.94%)\n",
      "\n",
      "Round 894, Train average loss 0.114 Test accuracy 38.940\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3871 \n",
      "Accuracy: 3732/10000 (37.32%)\n",
      "\n",
      "Round 895, Train average loss 0.111 Test accuracy 37.320\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3793 \n",
      "Accuracy: 3730/10000 (37.30%)\n",
      "\n",
      "Round 896, Train average loss 0.094 Test accuracy 37.300\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3744 \n",
      "Accuracy: 3796/10000 (37.96%)\n",
      "\n",
      "Round 897, Train average loss 0.097 Test accuracy 37.960\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4224 \n",
      "Accuracy: 3795/10000 (37.95%)\n",
      "\n",
      "Round 898, Train average loss 0.101 Test accuracy 37.950\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3500 \n",
      "Accuracy: 3774/10000 (37.74%)\n",
      "\n",
      "Round 899, Train average loss 0.123 Test accuracy 37.740\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5242 \n",
      "Accuracy: 3572/10000 (35.72%)\n",
      "\n",
      "Round 900, Train average loss 0.095 Test accuracy 35.720\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3528 \n",
      "Accuracy: 3897/10000 (38.97%)\n",
      "\n",
      "Round 901, Train average loss 0.100 Test accuracy 38.970\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4769 \n",
      "Accuracy: 3672/10000 (36.72%)\n",
      "\n",
      "Round 902, Train average loss 0.089 Test accuracy 36.720\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5429 \n",
      "Accuracy: 3591/10000 (35.91%)\n",
      "\n",
      "Round 903, Train average loss 0.106 Test accuracy 35.910\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3878 \n",
      "Accuracy: 3752/10000 (37.52%)\n",
      "\n",
      "Round 904, Train average loss 0.101 Test accuracy 37.520\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3876 \n",
      "Accuracy: 3743/10000 (37.43%)\n",
      "\n",
      "Round 905, Train average loss 0.119 Test accuracy 37.430\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3678 \n",
      "Accuracy: 3775/10000 (37.75%)\n",
      "\n",
      "Round 906, Train average loss 0.099 Test accuracy 37.750\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5700 \n",
      "Accuracy: 3509/10000 (35.09%)\n",
      "\n",
      "Round 907, Train average loss 0.092 Test accuracy 35.090\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3900 \n",
      "Accuracy: 3634/10000 (36.34%)\n",
      "\n",
      "Round 908, Train average loss 0.111 Test accuracy 36.340\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3609 \n",
      "Accuracy: 3744/10000 (37.44%)\n",
      "\n",
      "Round 909, Train average loss 0.105 Test accuracy 37.440\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2747 \n",
      "Accuracy: 3856/10000 (38.56%)\n",
      "\n",
      "Round 910, Train average loss 0.101 Test accuracy 38.560\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3126 \n",
      "Accuracy: 3875/10000 (38.75%)\n",
      "\n",
      "Round 911, Train average loss 0.085 Test accuracy 38.750\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4148 \n",
      "Accuracy: 3782/10000 (37.82%)\n",
      "\n",
      "Round 912, Train average loss 0.106 Test accuracy 37.820\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4311 \n",
      "Accuracy: 3723/10000 (37.23%)\n",
      "\n",
      "Round 913, Train average loss 0.097 Test accuracy 37.230\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2871 \n",
      "Accuracy: 3826/10000 (38.26%)\n",
      "\n",
      "Round 914, Train average loss 0.107 Test accuracy 38.260\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3900 \n",
      "Accuracy: 3695/10000 (36.95%)\n",
      "\n",
      "Round 915, Train average loss 0.096 Test accuracy 36.950\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3515 \n",
      "Accuracy: 3766/10000 (37.66%)\n",
      "\n",
      "Round 916, Train average loss 0.095 Test accuracy 37.660\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3458 \n",
      "Accuracy: 3774/10000 (37.74%)\n",
      "\n",
      "Round 917, Train average loss 0.102 Test accuracy 37.740\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4839 \n",
      "Accuracy: 3775/10000 (37.75%)\n",
      "\n",
      "Round 918, Train average loss 0.097 Test accuracy 37.750\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2460 \n",
      "Accuracy: 3921/10000 (39.21%)\n",
      "\n",
      "Round 919, Train average loss 0.103 Test accuracy 39.210\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2794 \n",
      "Accuracy: 3822/10000 (38.22%)\n",
      "\n",
      "Round 920, Train average loss 0.102 Test accuracy 38.220\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3081 \n",
      "Accuracy: 3862/10000 (38.62%)\n",
      "\n",
      "Round 921, Train average loss 0.091 Test accuracy 38.620\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2627 \n",
      "Accuracy: 3899/10000 (38.99%)\n",
      "\n",
      "Round 922, Train average loss 0.092 Test accuracy 38.990\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2816 \n",
      "Accuracy: 3883/10000 (38.83%)\n",
      "\n",
      "Round 923, Train average loss 0.091 Test accuracy 38.830\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4930 \n",
      "Accuracy: 3743/10000 (37.43%)\n",
      "\n",
      "Round 924, Train average loss 0.078 Test accuracy 37.430\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3241 \n",
      "Accuracy: 3883/10000 (38.83%)\n",
      "\n",
      "Round 925, Train average loss 0.098 Test accuracy 38.830\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3897 \n",
      "Accuracy: 3711/10000 (37.11%)\n",
      "\n",
      "Round 926, Train average loss 0.098 Test accuracy 37.110\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4234 \n",
      "Accuracy: 3640/10000 (36.40%)\n",
      "\n",
      "Round 927, Train average loss 0.099 Test accuracy 36.400\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2689 \n",
      "Accuracy: 3941/10000 (39.41%)\n",
      "\n",
      "Round 928, Train average loss 0.101 Test accuracy 39.410\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2705 \n",
      "Accuracy: 3897/10000 (38.97%)\n",
      "\n",
      "Round 929, Train average loss 0.089 Test accuracy 38.970\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4244 \n",
      "Accuracy: 3820/10000 (38.20%)\n",
      "\n",
      "Round 930, Train average loss 0.094 Test accuracy 38.200\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4525 \n",
      "Accuracy: 3762/10000 (37.62%)\n",
      "\n",
      "Round 931, Train average loss 0.089 Test accuracy 37.620\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4059 \n",
      "Accuracy: 3675/10000 (36.75%)\n",
      "\n",
      "Round 932, Train average loss 0.103 Test accuracy 36.750\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.6488 \n",
      "Accuracy: 3570/10000 (35.70%)\n",
      "\n",
      "Round 933, Train average loss 0.117 Test accuracy 35.700\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2970 \n",
      "Accuracy: 3799/10000 (37.99%)\n",
      "\n",
      "Round 934, Train average loss 0.114 Test accuracy 37.990\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3190 \n",
      "Accuracy: 3843/10000 (38.43%)\n",
      "\n",
      "Round 935, Train average loss 0.093 Test accuracy 38.430\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2819 \n",
      "Accuracy: 3883/10000 (38.83%)\n",
      "\n",
      "Round 936, Train average loss 0.096 Test accuracy 38.830\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3154 \n",
      "Accuracy: 3836/10000 (38.36%)\n",
      "\n",
      "Round 937, Train average loss 0.105 Test accuracy 38.360\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2725 \n",
      "Accuracy: 3835/10000 (38.35%)\n",
      "\n",
      "Round 938, Train average loss 0.098 Test accuracy 38.350\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3996 \n",
      "Accuracy: 3752/10000 (37.52%)\n",
      "\n",
      "Round 939, Train average loss 0.096 Test accuracy 37.520\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3903 \n",
      "Accuracy: 3743/10000 (37.43%)\n",
      "\n",
      "Round 940, Train average loss 0.109 Test accuracy 37.430\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4989 \n",
      "Accuracy: 3703/10000 (37.03%)\n",
      "\n",
      "Round 941, Train average loss 0.086 Test accuracy 37.030\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3526 \n",
      "Accuracy: 3781/10000 (37.81%)\n",
      "\n",
      "Round 942, Train average loss 0.094 Test accuracy 37.810\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3422 \n",
      "Accuracy: 3781/10000 (37.81%)\n",
      "\n",
      "Round 943, Train average loss 0.091 Test accuracy 37.810\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3774 \n",
      "Accuracy: 3757/10000 (37.57%)\n",
      "\n",
      "Round 944, Train average loss 0.096 Test accuracy 37.570\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4479 \n",
      "Accuracy: 3696/10000 (36.96%)\n",
      "\n",
      "Round 945, Train average loss 0.088 Test accuracy 36.960\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3503 \n",
      "Accuracy: 3732/10000 (37.32%)\n",
      "\n",
      "Round 946, Train average loss 0.100 Test accuracy 37.320\n",
      "lr= 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.2979 \n",
      "Accuracy: 3801/10000 (38.01%)\n",
      "\n",
      "Round 947, Train average loss 0.099 Test accuracy 38.010\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3102 \n",
      "Accuracy: 3808/10000 (38.08%)\n",
      "\n",
      "Round 948, Train average loss 0.099 Test accuracy 38.080\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2849 \n",
      "Accuracy: 3784/10000 (37.84%)\n",
      "\n",
      "Round 949, Train average loss 0.101 Test accuracy 37.840\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2979 \n",
      "Accuracy: 3896/10000 (38.96%)\n",
      "\n",
      "Round 950, Train average loss 0.079 Test accuracy 38.960\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4062 \n",
      "Accuracy: 3713/10000 (37.13%)\n",
      "\n",
      "Round 951, Train average loss 0.112 Test accuracy 37.130\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3116 \n",
      "Accuracy: 3819/10000 (38.19%)\n",
      "\n",
      "Round 952, Train average loss 0.102 Test accuracy 38.190\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3326 \n",
      "Accuracy: 3768/10000 (37.68%)\n",
      "\n",
      "Round 953, Train average loss 0.091 Test accuracy 37.680\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4123 \n",
      "Accuracy: 3859/10000 (38.59%)\n",
      "\n",
      "Round 954, Train average loss 0.092 Test accuracy 38.590\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2770 \n",
      "Accuracy: 3902/10000 (39.02%)\n",
      "\n",
      "Round 955, Train average loss 0.105 Test accuracy 39.020\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5625 \n",
      "Accuracy: 3529/10000 (35.29%)\n",
      "\n",
      "Round 956, Train average loss 0.082 Test accuracy 35.290\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3300 \n",
      "Accuracy: 3844/10000 (38.44%)\n",
      "\n",
      "Round 957, Train average loss 0.091 Test accuracy 38.440\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3362 \n",
      "Accuracy: 3804/10000 (38.04%)\n",
      "\n",
      "Round 958, Train average loss 0.085 Test accuracy 38.040\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2942 \n",
      "Accuracy: 3911/10000 (39.11%)\n",
      "\n",
      "Round 959, Train average loss 0.083 Test accuracy 39.110\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3028 \n",
      "Accuracy: 3897/10000 (38.97%)\n",
      "\n",
      "Round 960, Train average loss 0.097 Test accuracy 38.970\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3791 \n",
      "Accuracy: 3738/10000 (37.38%)\n",
      "\n",
      "Round 961, Train average loss 0.092 Test accuracy 37.380\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2541 \n",
      "Accuracy: 3830/10000 (38.30%)\n",
      "\n",
      "Round 962, Train average loss 0.102 Test accuracy 38.300\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3395 \n",
      "Accuracy: 3779/10000 (37.79%)\n",
      "\n",
      "Round 963, Train average loss 0.088 Test accuracy 37.790\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2859 \n",
      "Accuracy: 3758/10000 (37.58%)\n",
      "\n",
      "Round 964, Train average loss 0.100 Test accuracy 37.580\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3488 \n",
      "Accuracy: 3756/10000 (37.56%)\n",
      "\n",
      "Round 965, Train average loss 0.081 Test accuracy 37.560\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3103 \n",
      "Accuracy: 3750/10000 (37.50%)\n",
      "\n",
      "Round 966, Train average loss 0.099 Test accuracy 37.500\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3620 \n",
      "Accuracy: 3802/10000 (38.02%)\n",
      "\n",
      "Round 967, Train average loss 0.087 Test accuracy 38.020\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3185 \n",
      "Accuracy: 3857/10000 (38.57%)\n",
      "\n",
      "Round 968, Train average loss 0.093 Test accuracy 38.570\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3959 \n",
      "Accuracy: 3732/10000 (37.32%)\n",
      "\n",
      "Round 969, Train average loss 0.080 Test accuracy 37.320\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4979 \n",
      "Accuracy: 3639/10000 (36.39%)\n",
      "\n",
      "Round 970, Train average loss 0.085 Test accuracy 36.390\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3452 \n",
      "Accuracy: 3880/10000 (38.80%)\n",
      "\n",
      "Round 971, Train average loss 0.089 Test accuracy 38.800\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3680 \n",
      "Accuracy: 3707/10000 (37.07%)\n",
      "\n",
      "Round 972, Train average loss 0.107 Test accuracy 37.070\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3780 \n",
      "Accuracy: 3757/10000 (37.57%)\n",
      "\n",
      "Round 973, Train average loss 0.086 Test accuracy 37.570\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3072 \n",
      "Accuracy: 3773/10000 (37.73%)\n",
      "\n",
      "Round 974, Train average loss 0.096 Test accuracy 37.730\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4071 \n",
      "Accuracy: 3745/10000 (37.45%)\n",
      "\n",
      "Round 975, Train average loss 0.089 Test accuracy 37.450\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4025 \n",
      "Accuracy: 3826/10000 (38.26%)\n",
      "\n",
      "Round 976, Train average loss 0.101 Test accuracy 38.260\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2990 \n",
      "Accuracy: 3912/10000 (39.12%)\n",
      "\n",
      "Round 977, Train average loss 0.082 Test accuracy 39.120\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3640 \n",
      "Accuracy: 3769/10000 (37.69%)\n",
      "\n",
      "Round 978, Train average loss 0.089 Test accuracy 37.690\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5918 \n",
      "Accuracy: 3570/10000 (35.70%)\n",
      "\n",
      "Round 979, Train average loss 0.073 Test accuracy 35.700\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3385 \n",
      "Accuracy: 3764/10000 (37.64%)\n",
      "\n",
      "Round 980, Train average loss 0.099 Test accuracy 37.640\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3966 \n",
      "Accuracy: 3770/10000 (37.70%)\n",
      "\n",
      "Round 981, Train average loss 0.076 Test accuracy 37.700\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4212 \n",
      "Accuracy: 3704/10000 (37.04%)\n",
      "\n",
      "Round 982, Train average loss 0.088 Test accuracy 37.040\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2838 \n",
      "Accuracy: 3822/10000 (38.22%)\n",
      "\n",
      "Round 983, Train average loss 0.098 Test accuracy 38.220\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3634 \n",
      "Accuracy: 3863/10000 (38.63%)\n",
      "\n",
      "Round 984, Train average loss 0.077 Test accuracy 38.630\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5542 \n",
      "Accuracy: 3588/10000 (35.88%)\n",
      "\n",
      "Round 985, Train average loss 0.081 Test accuracy 35.880\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4444 \n",
      "Accuracy: 3780/10000 (37.80%)\n",
      "\n",
      "Round 986, Train average loss 0.077 Test accuracy 37.800\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4344 \n",
      "Accuracy: 3846/10000 (38.46%)\n",
      "\n",
      "Round 987, Train average loss 0.084 Test accuracy 38.460\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5162 \n",
      "Accuracy: 3731/10000 (37.31%)\n",
      "\n",
      "Round 988, Train average loss 0.091 Test accuracy 37.310\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5679 \n",
      "Accuracy: 3666/10000 (36.66%)\n",
      "\n",
      "Round 989, Train average loss 0.068 Test accuracy 36.660\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5637 \n",
      "Accuracy: 3735/10000 (37.35%)\n",
      "\n",
      "Round 990, Train average loss 0.091 Test accuracy 37.350\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4294 \n",
      "Accuracy: 3751/10000 (37.51%)\n",
      "\n",
      "Round 991, Train average loss 0.092 Test accuracy 37.510\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3927 \n",
      "Accuracy: 3823/10000 (38.23%)\n",
      "\n",
      "Round 992, Train average loss 0.093 Test accuracy 38.230\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2971 \n",
      "Accuracy: 3895/10000 (38.95%)\n",
      "\n",
      "Round 993, Train average loss 0.083 Test accuracy 38.950\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.6250 \n",
      "Accuracy: 3616/10000 (36.16%)\n",
      "\n",
      "Round 994, Train average loss 0.088 Test accuracy 36.160\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2543 \n",
      "Accuracy: 3888/10000 (38.88%)\n",
      "\n",
      "Round 995, Train average loss 0.112 Test accuracy 38.880\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5406 \n",
      "Accuracy: 3501/10000 (35.01%)\n",
      "\n",
      "Round 996, Train average loss 0.087 Test accuracy 35.010\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4407 \n",
      "Accuracy: 3691/10000 (36.91%)\n",
      "\n",
      "Round 997, Train average loss 0.079 Test accuracy 36.910\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2798 \n",
      "Accuracy: 3865/10000 (38.65%)\n",
      "\n",
      "Round 998, Train average loss 0.096 Test accuracy 38.650\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3315 \n",
      "Accuracy: 3859/10000 (38.59%)\n",
      "\n",
      "Round 999, Train average loss 0.081 Test accuracy 38.590\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3257 \n",
      "Accuracy: 3842/10000 (38.42%)\n",
      "\n",
      "Round 1000, Train average loss 0.085 Test accuracy 38.420\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4755 \n",
      "Accuracy: 3709/10000 (37.09%)\n",
      "\n",
      "Round 1001, Train average loss 0.074 Test accuracy 37.090\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5786 \n",
      "Accuracy: 3567/10000 (35.67%)\n",
      "\n",
      "Round 1002, Train average loss 0.076 Test accuracy 35.670\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5646 \n",
      "Accuracy: 3726/10000 (37.26%)\n",
      "\n",
      "Round 1003, Train average loss 0.067 Test accuracy 37.260\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4106 \n",
      "Accuracy: 3800/10000 (38.00%)\n",
      "\n",
      "Round 1004, Train average loss 0.094 Test accuracy 38.000\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4218 \n",
      "Accuracy: 3755/10000 (37.55%)\n",
      "\n",
      "Round 1005, Train average loss 0.081 Test accuracy 37.550\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4860 \n",
      "Accuracy: 3668/10000 (36.68%)\n",
      "\n",
      "Round 1006, Train average loss 0.083 Test accuracy 36.680\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3736 \n",
      "Accuracy: 3912/10000 (39.12%)\n",
      "\n",
      "Round 1007, Train average loss 0.088 Test accuracy 39.120\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4343 \n",
      "Accuracy: 3776/10000 (37.76%)\n",
      "\n",
      "Round 1008, Train average loss 0.088 Test accuracy 37.760\n",
      "lr= 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.4356 \n",
      "Accuracy: 3755/10000 (37.55%)\n",
      "\n",
      "Round 1009, Train average loss 0.089 Test accuracy 37.550\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3595 \n",
      "Accuracy: 3784/10000 (37.84%)\n",
      "\n",
      "Round 1010, Train average loss 0.090 Test accuracy 37.840\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3541 \n",
      "Accuracy: 3816/10000 (38.16%)\n",
      "\n",
      "Round 1011, Train average loss 0.083 Test accuracy 38.160\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4773 \n",
      "Accuracy: 3662/10000 (36.62%)\n",
      "\n",
      "Round 1012, Train average loss 0.089 Test accuracy 36.620\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4909 \n",
      "Accuracy: 3687/10000 (36.87%)\n",
      "\n",
      "Round 1013, Train average loss 0.072 Test accuracy 36.870\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.6089 \n",
      "Accuracy: 3530/10000 (35.30%)\n",
      "\n",
      "Round 1014, Train average loss 0.090 Test accuracy 35.300\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3953 \n",
      "Accuracy: 3751/10000 (37.51%)\n",
      "\n",
      "Round 1015, Train average loss 0.086 Test accuracy 37.510\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5031 \n",
      "Accuracy: 3699/10000 (36.99%)\n",
      "\n",
      "Round 1016, Train average loss 0.071 Test accuracy 36.990\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3420 \n",
      "Accuracy: 3861/10000 (38.61%)\n",
      "\n",
      "Round 1017, Train average loss 0.094 Test accuracy 38.610\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5117 \n",
      "Accuracy: 3631/10000 (36.31%)\n",
      "\n",
      "Round 1018, Train average loss 0.082 Test accuracy 36.310\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4499 \n",
      "Accuracy: 3800/10000 (38.00%)\n",
      "\n",
      "Round 1019, Train average loss 0.083 Test accuracy 38.000\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4965 \n",
      "Accuracy: 3679/10000 (36.79%)\n",
      "\n",
      "Round 1020, Train average loss 0.094 Test accuracy 36.790\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5272 \n",
      "Accuracy: 3596/10000 (35.96%)\n",
      "\n",
      "Round 1021, Train average loss 0.084 Test accuracy 35.960\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3767 \n",
      "Accuracy: 3780/10000 (37.80%)\n",
      "\n",
      "Round 1022, Train average loss 0.084 Test accuracy 37.800\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4975 \n",
      "Accuracy: 3651/10000 (36.51%)\n",
      "\n",
      "Round 1023, Train average loss 0.093 Test accuracy 36.510\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4105 \n",
      "Accuracy: 3822/10000 (38.22%)\n",
      "\n",
      "Round 1024, Train average loss 0.081 Test accuracy 38.220\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2902 \n",
      "Accuracy: 3860/10000 (38.60%)\n",
      "\n",
      "Round 1025, Train average loss 0.086 Test accuracy 38.600\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3399 \n",
      "Accuracy: 3890/10000 (38.90%)\n",
      "\n",
      "Round 1026, Train average loss 0.085 Test accuracy 38.900\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3775 \n",
      "Accuracy: 3731/10000 (37.31%)\n",
      "\n",
      "Round 1027, Train average loss 0.096 Test accuracy 37.310\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4002 \n",
      "Accuracy: 3723/10000 (37.23%)\n",
      "\n",
      "Round 1028, Train average loss 0.090 Test accuracy 37.230\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4556 \n",
      "Accuracy: 3738/10000 (37.38%)\n",
      "\n",
      "Round 1029, Train average loss 0.075 Test accuracy 37.380\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.6000 \n",
      "Accuracy: 3713/10000 (37.13%)\n",
      "\n",
      "Round 1030, Train average loss 0.075 Test accuracy 37.130\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.6364 \n",
      "Accuracy: 3750/10000 (37.50%)\n",
      "\n",
      "Round 1031, Train average loss 0.078 Test accuracy 37.500\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4645 \n",
      "Accuracy: 3774/10000 (37.74%)\n",
      "\n",
      "Round 1032, Train average loss 0.099 Test accuracy 37.740\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3659 \n",
      "Accuracy: 3807/10000 (38.07%)\n",
      "\n",
      "Round 1033, Train average loss 0.100 Test accuracy 38.070\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3885 \n",
      "Accuracy: 3798/10000 (37.98%)\n",
      "\n",
      "Round 1034, Train average loss 0.093 Test accuracy 37.980\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4068 \n",
      "Accuracy: 3851/10000 (38.51%)\n",
      "\n",
      "Round 1035, Train average loss 0.077 Test accuracy 38.510\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3822 \n",
      "Accuracy: 3877/10000 (38.77%)\n",
      "\n",
      "Round 1036, Train average loss 0.079 Test accuracy 38.770\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3234 \n",
      "Accuracy: 3920/10000 (39.20%)\n",
      "\n",
      "Round 1037, Train average loss 0.084 Test accuracy 39.200\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3966 \n",
      "Accuracy: 3749/10000 (37.49%)\n",
      "\n",
      "Round 1038, Train average loss 0.088 Test accuracy 37.490\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3114 \n",
      "Accuracy: 3859/10000 (38.59%)\n",
      "\n",
      "Round 1039, Train average loss 0.097 Test accuracy 38.590\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3991 \n",
      "Accuracy: 3766/10000 (37.66%)\n",
      "\n",
      "Round 1040, Train average loss 0.080 Test accuracy 37.660\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4280 \n",
      "Accuracy: 3719/10000 (37.19%)\n",
      "\n",
      "Round 1041, Train average loss 0.093 Test accuracy 37.190\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4580 \n",
      "Accuracy: 3764/10000 (37.64%)\n",
      "\n",
      "Round 1042, Train average loss 0.091 Test accuracy 37.640\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3545 \n",
      "Accuracy: 3809/10000 (38.09%)\n",
      "\n",
      "Round 1043, Train average loss 0.083 Test accuracy 38.090\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5127 \n",
      "Accuracy: 3626/10000 (36.26%)\n",
      "\n",
      "Round 1044, Train average loss 0.079 Test accuracy 36.260\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3202 \n",
      "Accuracy: 3779/10000 (37.79%)\n",
      "\n",
      "Round 1045, Train average loss 0.098 Test accuracy 37.790\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3838 \n",
      "Accuracy: 3778/10000 (37.78%)\n",
      "\n",
      "Round 1046, Train average loss 0.082 Test accuracy 37.780\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4026 \n",
      "Accuracy: 3805/10000 (38.05%)\n",
      "\n",
      "Round 1047, Train average loss 0.085 Test accuracy 38.050\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2954 \n",
      "Accuracy: 3921/10000 (39.21%)\n",
      "\n",
      "Round 1048, Train average loss 0.082 Test accuracy 39.210\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4983 \n",
      "Accuracy: 3650/10000 (36.50%)\n",
      "\n",
      "Round 1049, Train average loss 0.077 Test accuracy 36.500\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4067 \n",
      "Accuracy: 3744/10000 (37.44%)\n",
      "\n",
      "Round 1050, Train average loss 0.089 Test accuracy 37.440\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5729 \n",
      "Accuracy: 3640/10000 (36.40%)\n",
      "\n",
      "Round 1051, Train average loss 0.066 Test accuracy 36.400\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4722 \n",
      "Accuracy: 3728/10000 (37.28%)\n",
      "\n",
      "Round 1052, Train average loss 0.077 Test accuracy 37.280\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4542 \n",
      "Accuracy: 3736/10000 (37.36%)\n",
      "\n",
      "Round 1053, Train average loss 0.079 Test accuracy 37.360\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3505 \n",
      "Accuracy: 3830/10000 (38.30%)\n",
      "\n",
      "Round 1054, Train average loss 0.087 Test accuracy 38.300\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4463 \n",
      "Accuracy: 3723/10000 (37.23%)\n",
      "\n",
      "Round 1055, Train average loss 0.089 Test accuracy 37.230\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3044 \n",
      "Accuracy: 3868/10000 (38.68%)\n",
      "\n",
      "Round 1056, Train average loss 0.096 Test accuracy 38.680\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2767 \n",
      "Accuracy: 3937/10000 (39.37%)\n",
      "\n",
      "Round 1057, Train average loss 0.095 Test accuracy 39.370\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2875 \n",
      "Accuracy: 3879/10000 (38.79%)\n",
      "\n",
      "Round 1058, Train average loss 0.087 Test accuracy 38.790\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4571 \n",
      "Accuracy: 3617/10000 (36.17%)\n",
      "\n",
      "Round 1059, Train average loss 0.090 Test accuracy 36.170\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4115 \n",
      "Accuracy: 3888/10000 (38.88%)\n",
      "\n",
      "Round 1060, Train average loss 0.081 Test accuracy 38.880\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5559 \n",
      "Accuracy: 3634/10000 (36.34%)\n",
      "\n",
      "Round 1061, Train average loss 0.077 Test accuracy 36.340\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4132 \n",
      "Accuracy: 3802/10000 (38.02%)\n",
      "\n",
      "Round 1062, Train average loss 0.078 Test accuracy 38.020\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5393 \n",
      "Accuracy: 3650/10000 (36.50%)\n",
      "\n",
      "Round 1063, Train average loss 0.069 Test accuracy 36.500\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4750 \n",
      "Accuracy: 3660/10000 (36.60%)\n",
      "\n",
      "Round 1064, Train average loss 0.089 Test accuracy 36.600\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5361 \n",
      "Accuracy: 3708/10000 (37.08%)\n",
      "\n",
      "Round 1065, Train average loss 0.076 Test accuracy 37.080\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5150 \n",
      "Accuracy: 3710/10000 (37.10%)\n",
      "\n",
      "Round 1066, Train average loss 0.076 Test accuracy 37.100\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3854 \n",
      "Accuracy: 3806/10000 (38.06%)\n",
      "\n",
      "Round 1067, Train average loss 0.094 Test accuracy 38.060\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4026 \n",
      "Accuracy: 3806/10000 (38.06%)\n",
      "\n",
      "Round 1068, Train average loss 0.083 Test accuracy 38.060\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4407 \n",
      "Accuracy: 3807/10000 (38.07%)\n",
      "\n",
      "Round 1069, Train average loss 0.071 Test accuracy 38.070\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4743 \n",
      "Accuracy: 3712/10000 (37.12%)\n",
      "\n",
      "Round 1070, Train average loss 0.075 Test accuracy 37.120\n",
      "lr= 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.3750 \n",
      "Accuracy: 3773/10000 (37.73%)\n",
      "\n",
      "Round 1071, Train average loss 0.103 Test accuracy 37.730\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3682 \n",
      "Accuracy: 3749/10000 (37.49%)\n",
      "\n",
      "Round 1072, Train average loss 0.095 Test accuracy 37.490\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2730 \n",
      "Accuracy: 3873/10000 (38.73%)\n",
      "\n",
      "Round 1073, Train average loss 0.079 Test accuracy 38.730\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3732 \n",
      "Accuracy: 3832/10000 (38.32%)\n",
      "\n",
      "Round 1074, Train average loss 0.079 Test accuracy 38.320\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2826 \n",
      "Accuracy: 3936/10000 (39.36%)\n",
      "\n",
      "Round 1075, Train average loss 0.084 Test accuracy 39.360\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3320 \n",
      "Accuracy: 3884/10000 (38.84%)\n",
      "\n",
      "Round 1076, Train average loss 0.086 Test accuracy 38.840\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4294 \n",
      "Accuracy: 3734/10000 (37.34%)\n",
      "\n",
      "Round 1077, Train average loss 0.083 Test accuracy 37.340\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4472 \n",
      "Accuracy: 3828/10000 (38.28%)\n",
      "\n",
      "Round 1078, Train average loss 0.072 Test accuracy 38.280\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.6413 \n",
      "Accuracy: 3591/10000 (35.91%)\n",
      "\n",
      "Round 1079, Train average loss 0.075 Test accuracy 35.910\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4533 \n",
      "Accuracy: 3750/10000 (37.50%)\n",
      "\n",
      "Round 1080, Train average loss 0.084 Test accuracy 37.500\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4938 \n",
      "Accuracy: 3729/10000 (37.29%)\n",
      "\n",
      "Round 1081, Train average loss 0.076 Test accuracy 37.290\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3030 \n",
      "Accuracy: 3852/10000 (38.52%)\n",
      "\n",
      "Round 1082, Train average loss 0.097 Test accuracy 38.520\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3155 \n",
      "Accuracy: 3849/10000 (38.49%)\n",
      "\n",
      "Round 1083, Train average loss 0.081 Test accuracy 38.490\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5050 \n",
      "Accuracy: 3537/10000 (35.37%)\n",
      "\n",
      "Round 1084, Train average loss 0.089 Test accuracy 35.370\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2936 \n",
      "Accuracy: 3836/10000 (38.36%)\n",
      "\n",
      "Round 1085, Train average loss 0.099 Test accuracy 38.360\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4200 \n",
      "Accuracy: 3737/10000 (37.37%)\n",
      "\n",
      "Round 1086, Train average loss 0.070 Test accuracy 37.370\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5246 \n",
      "Accuracy: 3639/10000 (36.39%)\n",
      "\n",
      "Round 1087, Train average loss 0.084 Test accuracy 36.390\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5689 \n",
      "Accuracy: 3627/10000 (36.27%)\n",
      "\n",
      "Round 1088, Train average loss 0.087 Test accuracy 36.270\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5195 \n",
      "Accuracy: 3692/10000 (36.92%)\n",
      "\n",
      "Round 1089, Train average loss 0.073 Test accuracy 36.920\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3482 \n",
      "Accuracy: 3900/10000 (39.00%)\n",
      "\n",
      "Round 1090, Train average loss 0.092 Test accuracy 39.000\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3430 \n",
      "Accuracy: 3839/10000 (38.39%)\n",
      "\n",
      "Round 1091, Train average loss 0.080 Test accuracy 38.390\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3270 \n",
      "Accuracy: 3875/10000 (38.75%)\n",
      "\n",
      "Round 1092, Train average loss 0.076 Test accuracy 38.750\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3484 \n",
      "Accuracy: 3751/10000 (37.51%)\n",
      "\n",
      "Round 1093, Train average loss 0.089 Test accuracy 37.510\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4241 \n",
      "Accuracy: 3730/10000 (37.30%)\n",
      "\n",
      "Round 1094, Train average loss 0.072 Test accuracy 37.300\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4258 \n",
      "Accuracy: 3863/10000 (38.63%)\n",
      "\n",
      "Round 1095, Train average loss 0.073 Test accuracy 38.630\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2867 \n",
      "Accuracy: 3845/10000 (38.45%)\n",
      "\n",
      "Round 1096, Train average loss 0.095 Test accuracy 38.450\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4112 \n",
      "Accuracy: 3717/10000 (37.17%)\n",
      "\n",
      "Round 1097, Train average loss 0.088 Test accuracy 37.170\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2891 \n",
      "Accuracy: 3875/10000 (38.75%)\n",
      "\n",
      "Round 1098, Train average loss 0.086 Test accuracy 38.750\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2922 \n",
      "Accuracy: 3854/10000 (38.54%)\n",
      "\n",
      "Round 1099, Train average loss 0.087 Test accuracy 38.540\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2913 \n",
      "Accuracy: 3860/10000 (38.60%)\n",
      "\n",
      "Round 1100, Train average loss 0.082 Test accuracy 38.600\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3702 \n",
      "Accuracy: 3746/10000 (37.46%)\n",
      "\n",
      "Round 1101, Train average loss 0.084 Test accuracy 37.460\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.6163 \n",
      "Accuracy: 3569/10000 (35.69%)\n",
      "\n",
      "Round 1102, Train average loss 0.081 Test accuracy 35.690\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5915 \n",
      "Accuracy: 3511/10000 (35.11%)\n",
      "\n",
      "Round 1103, Train average loss 0.078 Test accuracy 35.110\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3274 \n",
      "Accuracy: 3773/10000 (37.73%)\n",
      "\n",
      "Round 1104, Train average loss 0.094 Test accuracy 37.730\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4600 \n",
      "Accuracy: 3675/10000 (36.75%)\n",
      "\n",
      "Round 1105, Train average loss 0.075 Test accuracy 36.750\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5668 \n",
      "Accuracy: 3574/10000 (35.74%)\n",
      "\n",
      "Round 1106, Train average loss 0.093 Test accuracy 35.740\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3704 \n",
      "Accuracy: 3824/10000 (38.24%)\n",
      "\n",
      "Round 1107, Train average loss 0.078 Test accuracy 38.240\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4209 \n",
      "Accuracy: 3800/10000 (38.00%)\n",
      "\n",
      "Round 1108, Train average loss 0.074 Test accuracy 38.000\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.6262 \n",
      "Accuracy: 3705/10000 (37.05%)\n",
      "\n",
      "Round 1109, Train average loss 0.066 Test accuracy 37.050\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4063 \n",
      "Accuracy: 3822/10000 (38.22%)\n",
      "\n",
      "Round 1110, Train average loss 0.074 Test accuracy 38.220\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4199 \n",
      "Accuracy: 3781/10000 (37.81%)\n",
      "\n",
      "Round 1111, Train average loss 0.074 Test accuracy 37.810\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5226 \n",
      "Accuracy: 3672/10000 (36.72%)\n",
      "\n",
      "Round 1112, Train average loss 0.075 Test accuracy 36.720\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.6228 \n",
      "Accuracy: 3651/10000 (36.51%)\n",
      "\n",
      "Round 1113, Train average loss 0.066 Test accuracy 36.510\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4255 \n",
      "Accuracy: 3749/10000 (37.49%)\n",
      "\n",
      "Round 1114, Train average loss 0.086 Test accuracy 37.490\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3948 \n",
      "Accuracy: 3813/10000 (38.13%)\n",
      "\n",
      "Round 1115, Train average loss 0.081 Test accuracy 38.130\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5512 \n",
      "Accuracy: 3598/10000 (35.98%)\n",
      "\n",
      "Round 1116, Train average loss 0.070 Test accuracy 35.980\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3011 \n",
      "Accuracy: 3798/10000 (37.98%)\n",
      "\n",
      "Round 1117, Train average loss 0.094 Test accuracy 37.980\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.6310 \n",
      "Accuracy: 3628/10000 (36.28%)\n",
      "\n",
      "Round 1118, Train average loss 0.067 Test accuracy 36.280\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3771 \n",
      "Accuracy: 3867/10000 (38.67%)\n",
      "\n",
      "Round 1119, Train average loss 0.078 Test accuracy 38.670\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4692 \n",
      "Accuracy: 3766/10000 (37.66%)\n",
      "\n",
      "Round 1120, Train average loss 0.079 Test accuracy 37.660\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5016 \n",
      "Accuracy: 3713/10000 (37.13%)\n",
      "\n",
      "Round 1121, Train average loss 0.086 Test accuracy 37.130\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5076 \n",
      "Accuracy: 3624/10000 (36.24%)\n",
      "\n",
      "Round 1122, Train average loss 0.093 Test accuracy 36.240\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3722 \n",
      "Accuracy: 3720/10000 (37.20%)\n",
      "\n",
      "Round 1123, Train average loss 0.091 Test accuracy 37.200\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3087 \n",
      "Accuracy: 3853/10000 (38.53%)\n",
      "\n",
      "Round 1124, Train average loss 0.082 Test accuracy 38.530\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3407 \n",
      "Accuracy: 3956/10000 (39.56%)\n",
      "\n",
      "Round 1125, Train average loss 0.073 Test accuracy 39.560\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4755 \n",
      "Accuracy: 3792/10000 (37.92%)\n",
      "\n",
      "Round 1126, Train average loss 0.069 Test accuracy 37.920\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5004 \n",
      "Accuracy: 3686/10000 (36.86%)\n",
      "\n",
      "Round 1127, Train average loss 0.090 Test accuracy 36.860\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5620 \n",
      "Accuracy: 3769/10000 (37.69%)\n",
      "\n",
      "Round 1128, Train average loss 0.062 Test accuracy 37.690\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4994 \n",
      "Accuracy: 3710/10000 (37.10%)\n",
      "\n",
      "Round 1129, Train average loss 0.099 Test accuracy 37.100\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4827 \n",
      "Accuracy: 3770/10000 (37.70%)\n",
      "\n",
      "Round 1130, Train average loss 0.066 Test accuracy 37.700\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5709 \n",
      "Accuracy: 3714/10000 (37.14%)\n",
      "\n",
      "Round 1131, Train average loss 0.079 Test accuracy 37.140\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3475 \n",
      "Accuracy: 3839/10000 (38.39%)\n",
      "\n",
      "Round 1132, Train average loss 0.081 Test accuracy 38.390\n",
      "lr= 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.6360 \n",
      "Accuracy: 3585/10000 (35.85%)\n",
      "\n",
      "Round 1133, Train average loss 0.076 Test accuracy 35.850\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4432 \n",
      "Accuracy: 3698/10000 (36.98%)\n",
      "\n",
      "Round 1134, Train average loss 0.079 Test accuracy 36.980\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5882 \n",
      "Accuracy: 3728/10000 (37.28%)\n",
      "\n",
      "Round 1135, Train average loss 0.073 Test accuracy 37.280\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3580 \n",
      "Accuracy: 3917/10000 (39.17%)\n",
      "\n",
      "Round 1136, Train average loss 0.071 Test accuracy 39.170\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4074 \n",
      "Accuracy: 3755/10000 (37.55%)\n",
      "\n",
      "Round 1137, Train average loss 0.070 Test accuracy 37.550\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2923 \n",
      "Accuracy: 3922/10000 (39.22%)\n",
      "\n",
      "Round 1138, Train average loss 0.079 Test accuracy 39.220\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3632 \n",
      "Accuracy: 3900/10000 (39.00%)\n",
      "\n",
      "Round 1139, Train average loss 0.077 Test accuracy 39.000\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4530 \n",
      "Accuracy: 3797/10000 (37.97%)\n",
      "\n",
      "Round 1140, Train average loss 0.083 Test accuracy 37.970\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4008 \n",
      "Accuracy: 3806/10000 (38.06%)\n",
      "\n",
      "Round 1141, Train average loss 0.085 Test accuracy 38.060\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3631 \n",
      "Accuracy: 3863/10000 (38.63%)\n",
      "\n",
      "Round 1142, Train average loss 0.080 Test accuracy 38.630\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2902 \n",
      "Accuracy: 3880/10000 (38.80%)\n",
      "\n",
      "Round 1143, Train average loss 0.076 Test accuracy 38.800\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4209 \n",
      "Accuracy: 3816/10000 (38.16%)\n",
      "\n",
      "Round 1144, Train average loss 0.072 Test accuracy 38.160\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.7043 \n",
      "Accuracy: 3601/10000 (36.01%)\n",
      "\n",
      "Round 1145, Train average loss 0.077 Test accuracy 36.010\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4988 \n",
      "Accuracy: 3609/10000 (36.09%)\n",
      "\n",
      "Round 1146, Train average loss 0.097 Test accuracy 36.090\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4030 \n",
      "Accuracy: 3793/10000 (37.93%)\n",
      "\n",
      "Round 1147, Train average loss 0.088 Test accuracy 37.930\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4296 \n",
      "Accuracy: 3730/10000 (37.30%)\n",
      "\n",
      "Round 1148, Train average loss 0.085 Test accuracy 37.300\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3242 \n",
      "Accuracy: 3824/10000 (38.24%)\n",
      "\n",
      "Round 1149, Train average loss 0.080 Test accuracy 38.240\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3195 \n",
      "Accuracy: 3847/10000 (38.47%)\n",
      "\n",
      "Round 1150, Train average loss 0.074 Test accuracy 38.470\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3686 \n",
      "Accuracy: 3697/10000 (36.97%)\n",
      "\n",
      "Round 1151, Train average loss 0.080 Test accuracy 36.970\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3261 \n",
      "Accuracy: 3892/10000 (38.92%)\n",
      "\n",
      "Round 1152, Train average loss 0.079 Test accuracy 38.920\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4417 \n",
      "Accuracy: 3771/10000 (37.71%)\n",
      "\n",
      "Round 1153, Train average loss 0.067 Test accuracy 37.710\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.6537 \n",
      "Accuracy: 3553/10000 (35.53%)\n",
      "\n",
      "Round 1154, Train average loss 0.078 Test accuracy 35.530\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3593 \n",
      "Accuracy: 3850/10000 (38.50%)\n",
      "\n",
      "Round 1155, Train average loss 0.081 Test accuracy 38.500\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5011 \n",
      "Accuracy: 3670/10000 (36.70%)\n",
      "\n",
      "Round 1156, Train average loss 0.071 Test accuracy 36.700\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2982 \n",
      "Accuracy: 3902/10000 (39.02%)\n",
      "\n",
      "Round 1157, Train average loss 0.088 Test accuracy 39.020\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5382 \n",
      "Accuracy: 3670/10000 (36.70%)\n",
      "\n",
      "Round 1158, Train average loss 0.064 Test accuracy 36.700\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4846 \n",
      "Accuracy: 3690/10000 (36.90%)\n",
      "\n",
      "Round 1159, Train average loss 0.091 Test accuracy 36.900\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4814 \n",
      "Accuracy: 3707/10000 (37.07%)\n",
      "\n",
      "Round 1160, Train average loss 0.068 Test accuracy 37.070\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5503 \n",
      "Accuracy: 3678/10000 (36.78%)\n",
      "\n",
      "Round 1161, Train average loss 0.069 Test accuracy 36.780\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3541 \n",
      "Accuracy: 3823/10000 (38.23%)\n",
      "\n",
      "Round 1162, Train average loss 0.080 Test accuracy 38.230\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4313 \n",
      "Accuracy: 3756/10000 (37.56%)\n",
      "\n",
      "Round 1163, Train average loss 0.069 Test accuracy 37.560\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5300 \n",
      "Accuracy: 3721/10000 (37.21%)\n",
      "\n",
      "Round 1164, Train average loss 0.060 Test accuracy 37.210\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5888 \n",
      "Accuracy: 3717/10000 (37.17%)\n",
      "\n",
      "Round 1165, Train average loss 0.070 Test accuracy 37.170\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4254 \n",
      "Accuracy: 3769/10000 (37.69%)\n",
      "\n",
      "Round 1166, Train average loss 0.088 Test accuracy 37.690\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5151 \n",
      "Accuracy: 3702/10000 (37.02%)\n",
      "\n",
      "Round 1167, Train average loss 0.069 Test accuracy 37.020\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3761 \n",
      "Accuracy: 3780/10000 (37.80%)\n",
      "\n",
      "Round 1168, Train average loss 0.076 Test accuracy 37.800\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3488 \n",
      "Accuracy: 3858/10000 (38.58%)\n",
      "\n",
      "Round 1169, Train average loss 0.090 Test accuracy 38.580\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4409 \n",
      "Accuracy: 3794/10000 (37.94%)\n",
      "\n",
      "Round 1170, Train average loss 0.070 Test accuracy 37.940\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2794 \n",
      "Accuracy: 3868/10000 (38.68%)\n",
      "\n",
      "Round 1171, Train average loss 0.085 Test accuracy 38.680\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4047 \n",
      "Accuracy: 3793/10000 (37.93%)\n",
      "\n",
      "Round 1172, Train average loss 0.078 Test accuracy 37.930\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3165 \n",
      "Accuracy: 3808/10000 (38.08%)\n",
      "\n",
      "Round 1173, Train average loss 0.089 Test accuracy 38.080\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3501 \n",
      "Accuracy: 3871/10000 (38.71%)\n",
      "\n",
      "Round 1174, Train average loss 0.076 Test accuracy 38.710\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3554 \n",
      "Accuracy: 3771/10000 (37.71%)\n",
      "\n",
      "Round 1175, Train average loss 0.080 Test accuracy 37.710\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4273 \n",
      "Accuracy: 3847/10000 (38.47%)\n",
      "\n",
      "Round 1176, Train average loss 0.072 Test accuracy 38.470\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3076 \n",
      "Accuracy: 3915/10000 (39.15%)\n",
      "\n",
      "Round 1177, Train average loss 0.068 Test accuracy 39.150\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4932 \n",
      "Accuracy: 3778/10000 (37.78%)\n",
      "\n",
      "Round 1178, Train average loss 0.066 Test accuracy 37.780\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4163 \n",
      "Accuracy: 3679/10000 (36.79%)\n",
      "\n",
      "Round 1179, Train average loss 0.094 Test accuracy 36.790\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5347 \n",
      "Accuracy: 3639/10000 (36.39%)\n",
      "\n",
      "Round 1180, Train average loss 0.076 Test accuracy 36.390\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3214 \n",
      "Accuracy: 3824/10000 (38.24%)\n",
      "\n",
      "Round 1181, Train average loss 0.085 Test accuracy 38.240\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3825 \n",
      "Accuracy: 3843/10000 (38.43%)\n",
      "\n",
      "Round 1182, Train average loss 0.067 Test accuracy 38.430\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3552 \n",
      "Accuracy: 3887/10000 (38.87%)\n",
      "\n",
      "Round 1183, Train average loss 0.076 Test accuracy 38.870\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3951 \n",
      "Accuracy: 3722/10000 (37.22%)\n",
      "\n",
      "Round 1184, Train average loss 0.083 Test accuracy 37.220\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3182 \n",
      "Accuracy: 3812/10000 (38.12%)\n",
      "\n",
      "Round 1185, Train average loss 0.072 Test accuracy 38.120\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4283 \n",
      "Accuracy: 3786/10000 (37.86%)\n",
      "\n",
      "Round 1186, Train average loss 0.078 Test accuracy 37.860\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5557 \n",
      "Accuracy: 3551/10000 (35.51%)\n",
      "\n",
      "Round 1187, Train average loss 0.087 Test accuracy 35.510\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3825 \n",
      "Accuracy: 3797/10000 (37.97%)\n",
      "\n",
      "Round 1188, Train average loss 0.072 Test accuracy 37.970\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4279 \n",
      "Accuracy: 3780/10000 (37.80%)\n",
      "\n",
      "Round 1189, Train average loss 0.076 Test accuracy 37.800\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4274 \n",
      "Accuracy: 3706/10000 (37.06%)\n",
      "\n",
      "Round 1190, Train average loss 0.082 Test accuracy 37.060\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5455 \n",
      "Accuracy: 3593/10000 (35.93%)\n",
      "\n",
      "Round 1191, Train average loss 0.081 Test accuracy 35.930\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.2966 \n",
      "Accuracy: 3913/10000 (39.13%)\n",
      "\n",
      "Round 1192, Train average loss 0.084 Test accuracy 39.130\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4762 \n",
      "Accuracy: 3842/10000 (38.42%)\n",
      "\n",
      "Round 1193, Train average loss 0.058 Test accuracy 38.420\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4198 \n",
      "Accuracy: 3780/10000 (37.80%)\n",
      "\n",
      "Round 1194, Train average loss 0.086 Test accuracy 37.800\n",
      "lr= 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.4143 \n",
      "Accuracy: 3793/10000 (37.93%)\n",
      "\n",
      "Round 1195, Train average loss 0.070 Test accuracy 37.930\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.4894 \n",
      "Accuracy: 3693/10000 (36.93%)\n",
      "\n",
      "Round 1196, Train average loss 0.070 Test accuracy 36.930\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3253 \n",
      "Accuracy: 3853/10000 (38.53%)\n",
      "\n",
      "Round 1197, Train average loss 0.077 Test accuracy 38.530\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.3487 \n",
      "Accuracy: 3841/10000 (38.41%)\n",
      "\n",
      "Round 1198, Train average loss 0.080 Test accuracy 38.410\n",
      "lr= 0.0016\n",
      "\n",
      "Test set: Average loss: 2.5827 \n",
      "Accuracy: 3659/10000 (36.59%)\n",
      "\n",
      "Round 1199, Train average loss 0.064 Test accuracy 36.590\n"
     ]
    }
   ],
   "source": [
    "from models.Nets import NIN,CNN_moderate, CNNCifar3\n",
    "\n",
    "p = 0.3\n",
    "N = 40\n",
    "K = 8\n",
    "\n",
    "N_trials = 1\n",
    "Max_iter = 1200\n",
    "\n",
    "args.opt = 'SGD'\n",
    "\n",
    "lr_array = [0.01]\n",
    "\n",
    "args.local_ep = 1\n",
    "args.local_bs = 50\n",
    "args.weight_decay = 5e-4\n",
    "\n",
    "acc_test_arr_random  = np.zeros((len(lr_array),N_trials,Max_iter))\n",
    "loss_test_arr_random = np.zeros((len(lr_array),N_trials,Max_iter))\n",
    "\n",
    "P_random = []\n",
    "\n",
    "for lr_idx in range(len(lr_array)):\n",
    "    \n",
    "    for trial_idx in range(N_trials):\n",
    "        \n",
    "        args.lr       = lr_array[lr_idx]\n",
    "        \n",
    "        net_glob = CNNCifar(args)\n",
    "        \n",
    "        net_glob = net_glob.cuda()\n",
    "        \n",
    "        print(net_glob)\n",
    "\n",
    "        net_glob.train()\n",
    "        \n",
    "        P_random = []\n",
    "\n",
    "        # copy weights\n",
    "        w_glob = net_glob.state_dict()\n",
    "        for iter in range(Max_iter): #args.epochs\n",
    "            \n",
    "            \n",
    "            if iter == 400 or iter == 800:\n",
    "                args.lr = args.lr * 0.4\n",
    "            \n",
    "            print('lr=',args.lr)\n",
    "            \n",
    "            w_locals, loss_locals = [], []\n",
    "\n",
    "            ###############################\n",
    "            # 0. Dropout Realization\n",
    "            ###############################    \n",
    "            \n",
    "            u = np.ones((N,))\n",
    "            for u_idx in range(N):\n",
    "                p_sel = p_per_user[u_idx]\n",
    "                u[u_idx] = np.random.binomial(1, 1-p_sel, size=1)[0]\n",
    "            \n",
    "            result = np.where(u == 1)\n",
    "            drop_result = np.where(u == 0)\n",
    "\n",
    "            ###############################\n",
    "            # 1. Weighted Random Selection\n",
    "            ###############################\n",
    "\n",
    "            #idxs_users = np.random.choice(range(N), K, replace=False)\n",
    "            \n",
    "            idxs_users = np.random.choice(result[0], K, replace=False)\n",
    "\n",
    "\n",
    "            p_tmp = np.zeros(N)\n",
    "            p_tmp[idxs_users] = 1\n",
    "\n",
    "            P_random.append(p_tmp)\n",
    "\n",
    "        #     idxs_users = np.random.choice(range(N), K, replace=False)\n",
    "            for idx in idxs_users:\n",
    "        #         print(idx)\n",
    "                local = LocalUpdate(args=args, dataset=dataset_train, idxs=dict_users[idx])\n",
    "                w, loss = local.train(net=copy.deepcopy(net_glob).to(args.device))\n",
    "                w_locals.append(copy.deepcopy(w))\n",
    "                loss_locals.append(copy.deepcopy(loss))\n",
    "            # update global weights\n",
    "            w_glob = FedAvg(w_locals)\n",
    "\n",
    "            # copy weight to net_glob\n",
    "            net_glob.load_state_dict(w_glob)\n",
    "\n",
    "            # print loss\n",
    "            loss_avg = sum(loss_locals) / len(loss_locals)\n",
    "\n",
    "            #loss_train.append(loss_avg)\n",
    "\n",
    "            acc_test, loss_test = test_img(net_glob, dataset_test, args)\n",
    "            acc_test_arr_random[lr_idx][trial_idx][iter]  = acc_test\n",
    "            loss_test_arr_random[lr_idx][trial_idx][iter] = loss_test\n",
    "            if iter % 1 ==0:\n",
    "                print('Round {:3d}, Train average loss {:.3f} Test accuracy {:.3f}'.format(iter, loss_avg,acc_test))\n",
    "            #print(loss_train)\n",
    "            \n",
    "            if iter % 100 == 99:\n",
    "                PATH = \"./save_models/CIFAR10_NonIID_CNN_N40_K8_net_glob_iter\"+str(iter)\n",
    "                torch.save(net_glob.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62006\n"
     ]
    }
   ],
   "source": [
    "from models.Nets import *\n",
    "from utils.functions import *\n",
    "\n",
    "net_glob = CNNCifar(args)\n",
    "net_glob = net_glob.cuda()\n",
    "\n",
    "net_glob.train()\n",
    "# copy weights\n",
    "w_glob = net_glob.state_dict()\n",
    "\n",
    "d = tensor_dim(w_glob)\n",
    "\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.2089 \n",
      "Accuracy: 3644/10000 (36.44%)\n",
      "\n",
      "\n",
      "Learning Rate = 0.03\n",
      "\n",
      "[[123.49016998]] [[123.48791882]] [[2.59083795e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2040 \n",
      "Accuracy: 3646/10000 (36.46%)\n",
      "\n",
      "Round   0, Train average loss 1.742 Test accuracy 36.460\n",
      "[[123.48791882]] [[123.4855979]] [[4.76466994e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1982 \n",
      "Accuracy: 3654/10000 (36.54%)\n",
      "\n",
      "Round   1, Train average loss 1.738 Test accuracy 36.540\n",
      "[[123.4855979]] [[123.48343926]] [[2.97452114e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1925 \n",
      "Accuracy: 3665/10000 (36.65%)\n",
      "\n",
      "Round   2, Train average loss 1.734 Test accuracy 36.650\n",
      "[[123.48343926]] [[123.48057445]] [[1.12189689e-05]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1825 \n",
      "Accuracy: 3664/10000 (36.64%)\n",
      "\n",
      "Round   3, Train average loss 1.729 Test accuracy 36.640\n",
      "[[123.48057445]] [[123.47805828]] [[5.61597041e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1749 \n",
      "Accuracy: 3677/10000 (36.77%)\n",
      "\n",
      "Round   4, Train average loss 1.721 Test accuracy 36.770\n",
      "[[123.47805828]] [[123.47554413]] [[3.99442808e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1722 \n",
      "Accuracy: 3672/10000 (36.72%)\n",
      "\n",
      "Round   5, Train average loss 1.715 Test accuracy 36.720\n",
      "[[123.47554413]] [[123.47359795]] [[3.89548104e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1672 \n",
      "Accuracy: 3696/10000 (36.96%)\n",
      "\n",
      "Round   6, Train average loss 1.712 Test accuracy 36.960\n",
      "[[123.47359795]] [[123.47137127]] [[3.21975232e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1651 \n",
      "Accuracy: 3690/10000 (36.90%)\n",
      "\n",
      "Round   7, Train average loss 1.708 Test accuracy 36.900\n",
      "[[123.47137127]] [[123.46910033]] [[3.24669211e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1587 \n",
      "Accuracy: 3698/10000 (36.98%)\n",
      "\n",
      "Round   8, Train average loss 1.707 Test accuracy 36.980\n",
      "[[123.46910033]] [[123.46664139]] [[4.1335534e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1525 \n",
      "Accuracy: 3708/10000 (37.08%)\n",
      "\n",
      "Round   9, Train average loss 1.702 Test accuracy 37.080\n",
      "[[123.46664139]] [[123.46513217]] [[3.61199124e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1552 \n",
      "Accuracy: 3712/10000 (37.12%)\n",
      "\n",
      "Round  10, Train average loss 1.696 Test accuracy 37.120\n",
      "[[123.46513217]] [[123.46306477]] [[3.26298519e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1533 \n",
      "Accuracy: 3707/10000 (37.07%)\n",
      "\n",
      "Round  11, Train average loss 1.699 Test accuracy 37.070\n",
      "[[123.46306477]] [[123.46125036]] [[4.84153266e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1481 \n",
      "Accuracy: 3709/10000 (37.09%)\n",
      "\n",
      "Round  12, Train average loss 1.698 Test accuracy 37.090\n",
      "[[123.46125036]] [[123.45924491]] [[3.00026993e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1467 \n",
      "Accuracy: 3701/10000 (37.01%)\n",
      "\n",
      "Round  13, Train average loss 1.694 Test accuracy 37.010\n",
      "[[123.45924491]] [[123.45721632]] [[5.09663557e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1440 \n",
      "Accuracy: 3703/10000 (37.03%)\n",
      "\n",
      "Round  14, Train average loss 1.693 Test accuracy 37.030\n",
      "[[123.45721632]] [[123.45542712]] [[3.72861775e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1403 \n",
      "Accuracy: 3704/10000 (37.04%)\n",
      "\n",
      "Round  15, Train average loss 1.691 Test accuracy 37.040\n",
      "[[123.45542712]] [[123.45293042]] [[4.48550739e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1349 \n",
      "Accuracy: 3712/10000 (37.12%)\n",
      "\n",
      "Round  16, Train average loss 1.688 Test accuracy 37.120\n",
      "[[123.45293042]] [[123.45078472]] [[2.96538787e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1321 \n",
      "Accuracy: 3717/10000 (37.17%)\n",
      "\n",
      "Round  17, Train average loss 1.683 Test accuracy 37.170\n",
      "[[123.45078472]] [[123.44828424]] [[7.20125897e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1269 \n",
      "Accuracy: 3729/10000 (37.29%)\n",
      "\n",
      "Round  18, Train average loss 1.681 Test accuracy 37.290\n",
      "[[123.44828424]] [[123.4461915]] [[5.67528243e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1230 \n",
      "Accuracy: 3730/10000 (37.30%)\n",
      "\n",
      "Round  19, Train average loss 1.677 Test accuracy 37.300\n",
      "[[123.4461915]] [[123.44458733]] [[3.02091467e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1228 \n",
      "Accuracy: 3725/10000 (37.25%)\n",
      "\n",
      "Round  20, Train average loss 1.674 Test accuracy 37.250\n",
      "[[123.44458733]] [[123.44261257]] [[5.02279465e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1220 \n",
      "Accuracy: 3722/10000 (37.22%)\n",
      "\n",
      "Round  21, Train average loss 1.674 Test accuracy 37.220\n",
      "[[123.44261257]] [[123.44077049]] [[2.26927103e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1202 \n",
      "Accuracy: 3723/10000 (37.23%)\n",
      "\n",
      "Round  22, Train average loss 1.673 Test accuracy 37.230\n",
      "[[123.44077049]] [[123.43855338]] [[3.39430551e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1173 \n",
      "Accuracy: 3730/10000 (37.30%)\n",
      "\n",
      "Round  23, Train average loss 1.672 Test accuracy 37.300\n",
      "[[123.43855338]] [[123.4366592]] [[3.18951254e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1154 \n",
      "Accuracy: 3736/10000 (37.36%)\n",
      "\n",
      "Round  24, Train average loss 1.670 Test accuracy 37.360\n",
      "[[123.4366592]] [[123.43468819]] [[1.94443926e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1152 \n",
      "Accuracy: 3735/10000 (37.35%)\n",
      "\n",
      "Round  25, Train average loss 1.668 Test accuracy 37.350\n",
      "[[123.43468819]] [[123.43228816]] [[3.41600954e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1122 \n",
      "Accuracy: 3748/10000 (37.48%)\n",
      "\n",
      "Round  26, Train average loss 1.668 Test accuracy 37.480\n",
      "[[123.43228816]] [[123.4297432]] [[6.20945683e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1077 \n",
      "Accuracy: 3752/10000 (37.52%)\n",
      "\n",
      "Round  27, Train average loss 1.666 Test accuracy 37.520\n",
      "[[123.4297432]] [[123.42790828]] [[4.405441e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1048 \n",
      "Accuracy: 3747/10000 (37.47%)\n",
      "\n",
      "Round  28, Train average loss 1.663 Test accuracy 37.470\n",
      "[[123.42790828]] [[123.42557687]] [[4.99466383e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1022 \n",
      "Accuracy: 3752/10000 (37.52%)\n",
      "\n",
      "Round  29, Train average loss 1.660 Test accuracy 37.520\n",
      "[[123.42557687]] [[123.4228299]] [[6.55844784e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0984 \n",
      "Accuracy: 3757/10000 (37.57%)\n",
      "\n",
      "Round  30, Train average loss 1.658 Test accuracy 37.570\n",
      "[[123.4228299]] [[123.42039451]] [[5.03383452e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0940 \n",
      "Accuracy: 3766/10000 (37.66%)\n",
      "\n",
      "Round  31, Train average loss 1.655 Test accuracy 37.660\n",
      "[[123.42039451]] [[123.41827696]] [[4.85238712e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0910 \n",
      "Accuracy: 3765/10000 (37.65%)\n",
      "\n",
      "Round  32, Train average loss 1.651 Test accuracy 37.650\n",
      "[[123.41827696]] [[123.4160633]] [[1.77638155e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0894 \n",
      "Accuracy: 3762/10000 (37.62%)\n",
      "\n",
      "Round  33, Train average loss 1.649 Test accuracy 37.620\n",
      "[[123.4160633]] [[123.41394874]] [[5.12780633e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0858 \n",
      "Accuracy: 3768/10000 (37.68%)\n",
      "\n",
      "Round  34, Train average loss 1.648 Test accuracy 37.680\n",
      "[[123.41394874]] [[123.41199675]] [[9.13785383e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0810 \n",
      "Accuracy: 3766/10000 (37.66%)\n",
      "\n",
      "Round  35, Train average loss 1.645 Test accuracy 37.660\n",
      "[[123.41199675]] [[123.40998718]] [[4.13639188e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0807 \n",
      "Accuracy: 3760/10000 (37.60%)\n",
      "\n",
      "Round  36, Train average loss 1.641 Test accuracy 37.600\n",
      "[[123.40998718]] [[123.4083481]] [[5.0256741e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0789 \n",
      "Accuracy: 3768/10000 (37.68%)\n",
      "\n",
      "Round  37, Train average loss 1.641 Test accuracy 37.680\n",
      "[[123.4083481]] [[123.40671442]] [[4.23141327e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0784 \n",
      "Accuracy: 3767/10000 (37.67%)\n",
      "\n",
      "Round  38, Train average loss 1.639 Test accuracy 37.670\n",
      "[[123.40671442]] [[123.40481583]] [[2.99499858e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0763 \n",
      "Accuracy: 3768/10000 (37.68%)\n",
      "\n",
      "Round  39, Train average loss 1.639 Test accuracy 37.680\n",
      "[[123.40481583]] [[123.40286437]] [[2.51965209e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0758 \n",
      "Accuracy: 3773/10000 (37.73%)\n",
      "\n",
      "Round  40, Train average loss 1.637 Test accuracy 37.730\n",
      "[[123.40286437]] [[123.40058355]] [[4.24793423e-06]]\n",
      "net_glob is updated !!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.0732 \n",
      "Accuracy: 3775/10000 (37.75%)\n",
      "\n",
      "Round  41, Train average loss 1.637 Test accuracy 37.750\n",
      "[[123.40058355]] [[123.39907821]] [[6.06731831e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0707 \n",
      "Accuracy: 3778/10000 (37.78%)\n",
      "\n",
      "Round  42, Train average loss 1.635 Test accuracy 37.780\n",
      "[[123.39907821]] [[123.39697535]] [[4.21568608e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0679 \n",
      "Accuracy: 3789/10000 (37.89%)\n",
      "\n",
      "Round  43, Train average loss 1.633 Test accuracy 37.890\n",
      "[[123.39697535]] [[123.39495957]] [[1.59910838e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0681 \n",
      "Accuracy: 3777/10000 (37.77%)\n",
      "\n",
      "Round  44, Train average loss 1.630 Test accuracy 37.770\n",
      "[[123.39495957]] [[123.39324806]] [[1.60047193e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0677 \n",
      "Accuracy: 3776/10000 (37.76%)\n",
      "\n",
      "Round  45, Train average loss 1.631 Test accuracy 37.760\n",
      "[[123.39324806]] [[123.39162277]] [[8.8009499e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0669 \n",
      "Accuracy: 3772/10000 (37.72%)\n",
      "\n",
      "Round  46, Train average loss 1.630 Test accuracy 37.720\n",
      "[[123.39162277]] [[123.3899117]] [[3.44707963e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0648 \n",
      "Accuracy: 3776/10000 (37.76%)\n",
      "\n",
      "Round  47, Train average loss 1.630 Test accuracy 37.760\n",
      "[[123.3899117]] [[123.38784607]] [[2.89362642e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0646 \n",
      "Accuracy: 3787/10000 (37.87%)\n",
      "\n",
      "Round  48, Train average loss 1.629 Test accuracy 37.870\n",
      "[[123.38784607]] [[123.38604476]] [[6.9777734e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0646 \n",
      "Accuracy: 3794/10000 (37.94%)\n",
      "\n",
      "Round  49, Train average loss 1.628 Test accuracy 37.940\n",
      "[[123.38604476]] [[123.38430707]] [[2.52740476e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0658 \n",
      "Accuracy: 3785/10000 (37.85%)\n",
      "\n",
      "Round  50, Train average loss 1.628 Test accuracy 37.850\n",
      "[[123.38430707]] [[123.38204594]] [[5.56877497e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0631 \n",
      "Accuracy: 3782/10000 (37.82%)\n",
      "\n",
      "Round  51, Train average loss 1.630 Test accuracy 37.820\n",
      "[[123.38204594]] [[123.38002409]] [[6.75646932e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0604 \n",
      "Accuracy: 3773/10000 (37.73%)\n",
      "\n",
      "Round  52, Train average loss 1.627 Test accuracy 37.730\n",
      "[[123.38002409]] [[123.3784183]] [[3.31926644e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0600 \n",
      "Accuracy: 3776/10000 (37.76%)\n",
      "\n",
      "Round  53, Train average loss 1.625 Test accuracy 37.760\n",
      "[[123.3784183]] [[123.37640399]] [[4.6759152e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0574 \n",
      "Accuracy: 3773/10000 (37.73%)\n",
      "\n",
      "Round  54, Train average loss 1.625 Test accuracy 37.730\n",
      "[[123.37640399]] [[123.37435514]] [[2.02999719e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0560 \n",
      "Accuracy: 3765/10000 (37.65%)\n",
      "\n",
      "Round  55, Train average loss 1.623 Test accuracy 37.650\n",
      "[[123.37435514]] [[123.37258166]] [[5.44183134e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0541 \n",
      "Accuracy: 3787/10000 (37.87%)\n",
      "\n",
      "Round  56, Train average loss 1.622 Test accuracy 37.870\n",
      "[[123.37258166]] [[123.37083726]] [[8.52250677e-07]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0537 \n",
      "Accuracy: 3780/10000 (37.80%)\n",
      "\n",
      "Round  57, Train average loss 1.621 Test accuracy 37.800\n",
      "[[123.37083726]] [[123.36910178]] [[1.09120646e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0524 \n",
      "Accuracy: 3788/10000 (37.88%)\n",
      "\n",
      "Round  58, Train average loss 1.620 Test accuracy 37.880\n",
      "[[123.36910178]] [[123.36694829]] [[3.19071864e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0506 \n",
      "Accuracy: 3780/10000 (37.80%)\n",
      "\n",
      "Round  59, Train average loss 1.619 Test accuracy 37.800\n",
      "[[123.36694829]] [[123.36492493]] [[2.73776367e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0484 \n",
      "Accuracy: 3791/10000 (37.91%)\n",
      "\n",
      "Round  60, Train average loss 1.618 Test accuracy 37.910\n",
      "[[123.36492493]] [[123.36301758]] [[4.14026074e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0475 \n",
      "Accuracy: 3794/10000 (37.94%)\n",
      "\n",
      "Round  61, Train average loss 1.616 Test accuracy 37.940\n",
      "[[123.36301758]] [[123.36152111]] [[2.59261383e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0469 \n",
      "Accuracy: 3801/10000 (38.01%)\n",
      "\n",
      "Round  62, Train average loss 1.615 Test accuracy 38.010\n",
      "[[123.36152111]] [[123.35976253]] [[5.80914392e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0458 \n",
      "Accuracy: 3798/10000 (37.98%)\n",
      "\n",
      "Round  63, Train average loss 1.615 Test accuracy 37.980\n",
      "[[123.35976253]] [[123.35771099]] [[2.24581785e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0449 \n",
      "Accuracy: 3800/10000 (38.00%)\n",
      "\n",
      "Round  64, Train average loss 1.614 Test accuracy 38.000\n",
      "[[123.35771099]] [[123.35542127]] [[6.64001757e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0431 \n",
      "Accuracy: 3795/10000 (37.95%)\n",
      "\n",
      "Round  65, Train average loss 1.613 Test accuracy 37.950\n",
      "[[123.35542127]] [[123.35326667]] [[3.55839819e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0426 \n",
      "Accuracy: 3801/10000 (38.01%)\n",
      "\n",
      "Round  66, Train average loss 1.612 Test accuracy 38.010\n",
      "[[123.35326667]] [[123.35083686]] [[5.18775283e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0410 \n",
      "Accuracy: 3797/10000 (37.97%)\n",
      "\n",
      "Round  67, Train average loss 1.612 Test accuracy 37.970\n",
      "[[123.35083686]] [[123.34898999]] [[2.68992963e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0397 \n",
      "Accuracy: 3789/10000 (37.89%)\n",
      "\n",
      "Round  68, Train average loss 1.610 Test accuracy 37.890\n",
      "[[123.34898999]] [[123.34721211]] [[4.0634975e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0398 \n",
      "Accuracy: 3789/10000 (37.89%)\n",
      "\n",
      "Round  69, Train average loss 1.609 Test accuracy 37.890\n",
      "[[123.34721211]] [[123.34526649]] [[2.54038807e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0389 \n",
      "Accuracy: 3788/10000 (37.88%)\n",
      "\n",
      "Round  70, Train average loss 1.610 Test accuracy 37.880\n",
      "[[123.34526649]] [[123.34382343]] [[2.70485445e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0377 \n",
      "Accuracy: 3797/10000 (37.97%)\n",
      "\n",
      "Round  71, Train average loss 1.609 Test accuracy 37.970\n",
      "[[123.34382343]] [[123.34188579]] [[3.7478764e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0367 \n",
      "Accuracy: 3804/10000 (38.04%)\n",
      "\n",
      "Round  72, Train average loss 1.608 Test accuracy 38.040\n",
      "[[123.34188579]] [[123.34019061]] [[4.40396182e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0366 \n",
      "Accuracy: 3792/10000 (37.92%)\n",
      "\n",
      "Round  73, Train average loss 1.607 Test accuracy 37.920\n",
      "[[123.34019061]] [[123.33855536]] [[2.68385564e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0359 \n",
      "Accuracy: 3802/10000 (38.02%)\n",
      "\n",
      "Round  74, Train average loss 1.607 Test accuracy 38.020\n",
      "[[123.33855536]] [[123.33620909]] [[5.81817536e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0344 \n",
      "Accuracy: 3796/10000 (37.96%)\n",
      "\n",
      "Round  75, Train average loss 1.606 Test accuracy 37.960\n",
      "[[123.33620909]] [[123.3339997]] [[7.47068398e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0325 \n",
      "Accuracy: 3803/10000 (38.03%)\n",
      "\n",
      "Round  76, Train average loss 1.605 Test accuracy 38.030\n",
      "[[123.3339997]] [[123.33206099]] [[3.37002618e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0317 \n",
      "Accuracy: 3805/10000 (38.05%)\n",
      "\n",
      "Round  77, Train average loss 1.604 Test accuracy 38.050\n",
      "[[123.33206099]] [[123.33018832]] [[3.42328081e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0306 \n",
      "Accuracy: 3812/10000 (38.12%)\n",
      "\n",
      "Round  78, Train average loss 1.603 Test accuracy 38.120\n",
      "[[123.33018832]] [[123.32838027]] [[1.86186953e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0299 \n",
      "Accuracy: 3803/10000 (38.03%)\n",
      "\n",
      "Round  79, Train average loss 1.602 Test accuracy 38.030\n",
      "[[123.32838027]] [[123.32629555]] [[3.15623347e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0290 \n",
      "Accuracy: 3807/10000 (38.07%)\n",
      "\n",
      "Round  80, Train average loss 1.602 Test accuracy 38.070\n",
      "[[123.32629555]] [[123.32426847]] [[4.55128455e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0284 \n",
      "Accuracy: 3815/10000 (38.15%)\n",
      "\n",
      "Round  81, Train average loss 1.601 Test accuracy 38.150\n",
      "[[123.32426847]] [[123.32220346]] [[6.71261434e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0275 \n",
      "Accuracy: 3821/10000 (38.21%)\n",
      "\n",
      "Round  82, Train average loss 1.600 Test accuracy 38.210\n",
      "[[123.32220346]] [[123.32025623]] [[6.52948904e-06]]\n",
      "net_glob is updated !!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.0261 \n",
      "Accuracy: 3812/10000 (38.12%)\n",
      "\n",
      "Round  83, Train average loss 1.599 Test accuracy 38.120\n",
      "[[123.32025623]] [[123.31841323]] [[2.62544913e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0256 \n",
      "Accuracy: 3815/10000 (38.15%)\n",
      "\n",
      "Round  84, Train average loss 1.598 Test accuracy 38.150\n",
      "[[123.31841323]] [[123.3167396]] [[2.26772847e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0253 \n",
      "Accuracy: 3811/10000 (38.11%)\n",
      "\n",
      "Round  85, Train average loss 1.598 Test accuracy 38.110\n",
      "[[123.3167396]] [[123.31489963]] [[2.0581365e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0244 \n",
      "Accuracy: 3810/10000 (38.10%)\n",
      "\n",
      "Round  86, Train average loss 1.598 Test accuracy 38.100\n",
      "[[123.31489963]] [[123.31335978]] [[1.93350443e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0241 \n",
      "Accuracy: 3810/10000 (38.10%)\n",
      "\n",
      "Round  87, Train average loss 1.597 Test accuracy 38.100\n",
      "[[123.31335978]] [[123.31150578]] [[3.0738932e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0231 \n",
      "Accuracy: 3817/10000 (38.17%)\n",
      "\n",
      "Round  88, Train average loss 1.597 Test accuracy 38.170\n",
      "[[123.31150578]] [[123.30938612]] [[3.35164218e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0219 \n",
      "Accuracy: 3814/10000 (38.14%)\n",
      "\n",
      "Round  89, Train average loss 1.596 Test accuracy 38.140\n",
      "[[123.30938612]] [[123.30770649]] [[7.34942646e-07]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0214 \n",
      "Accuracy: 3814/10000 (38.14%)\n",
      "\n",
      "Round  90, Train average loss 1.595 Test accuracy 38.140\n",
      "[[123.30770649]] [[123.3056955]] [[3.74709283e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0222 \n",
      "Accuracy: 3804/10000 (38.04%)\n",
      "\n",
      "Round  91, Train average loss 1.595 Test accuracy 38.040\n",
      "[[123.3056955]] [[123.30394772]] [[4.4908305e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0224 \n",
      "Accuracy: 3816/10000 (38.16%)\n",
      "\n",
      "Round  92, Train average loss 1.596 Test accuracy 38.160\n",
      "[[123.30394772]] [[123.30225406]] [[4.96205641e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0220 \n",
      "Accuracy: 3815/10000 (38.15%)\n",
      "\n",
      "Round  93, Train average loss 1.596 Test accuracy 38.150\n",
      "[[123.30225406]] [[123.3007335]] [[3.39146393e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0201 \n",
      "Accuracy: 3815/10000 (38.15%)\n",
      "\n",
      "Round  94, Train average loss 1.596 Test accuracy 38.150\n",
      "[[123.3007335]] [[123.2989697]] [[1.68226173e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0201 \n",
      "Accuracy: 3821/10000 (38.21%)\n",
      "\n",
      "Round  95, Train average loss 1.595 Test accuracy 38.210\n",
      "[[123.2989697]] [[123.29706798]] [[6.73079411e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0181 \n",
      "Accuracy: 3820/10000 (38.20%)\n",
      "\n",
      "Round  96, Train average loss 1.595 Test accuracy 38.200\n",
      "[[123.29706798]] [[123.29475731]] [[7.90427722e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0180 \n",
      "Accuracy: 3817/10000 (38.17%)\n",
      "\n",
      "Round  97, Train average loss 1.593 Test accuracy 38.170\n",
      "[[123.29475731]] [[123.29260055]] [[3.30144692e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0174 \n",
      "Accuracy: 3812/10000 (38.12%)\n",
      "\n",
      "Round  98, Train average loss 1.593 Test accuracy 38.120\n",
      "[[123.29260055]] [[123.29102947]] [[2.75822999e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.0160 \n",
      "Accuracy: 3821/10000 (38.21%)\n",
      "\n",
      "Round  99, Train average loss 1.592 Test accuracy 38.210\n",
      "[[98.32887089]] [[9.33875307]] [[115.68649739]]\n",
      "[[98.70334129]] [[5.83006144]] [[89.83286]]\n",
      "[[97.80869195]] [[21.98917907]] [[48.16736201]]\n",
      "[[93.22286985]] [[11.007302]] [[119.6096766]]\n",
      "[[94.05403685]] [[7.82907904]] [[94.5445063]]\n",
      "[[93.75043042]] [[7.63514285]] [[118.21085142]]\n",
      "[[94.78471489]] [[6.31071455]] [[108.95186444]]\n",
      "[[95.00747906]] [[6.36351654]] [[88.40431111]]\n",
      "[[93.99822417]] [[8.10176467]] [[68.42997016]]\n",
      "[[91.96680482]] [[7.07950283]] [[118.16376465]]\n",
      "[[93.15041242]] [[6.39545098]] [[113.74687797]]\n",
      "[[93.71315501]] [[9.48940402]] [[81.43650368]]\n",
      "[[92.11799837]] [[5.88052906]] [[113.06789104]]\n",
      "[[92.70347089]] [[9.98940572]] [[80.87638032]]\n",
      "[[91.41005976]] [[7.30809078]] [[109.00565016]]\n",
      "[[91.80320353]] [[8.79159449]] [[120.86940893]]\n",
      "[[92.96877955]] [[5.81216022]] [[111.30391954]]\n",
      "[[93.7240698]] [[14.11446759]] [[80.75851306]]\n",
      "[[91.82770118]] [[11.12355356]] [[100.78497298]]\n",
      "[[91.4660597]] [[5.92099276]] [[91.83338078]]\n",
      "[[91.28382473]] [[9.84467751]] [[75.73328274]]\n",
      "[[89.55234889]] [[4.44777121]] [[83.40314993]]\n",
      "[[88.91289894]] [[6.65283881]] [[85.47204935]]\n",
      "[[88.18113075]] [[6.25144457]] [[60.09816112]]\n",
      "[[85.94983309]] [[3.81110095]] [[77.74425888]]\n",
      "[[85.20666559]] [[6.69537869]] [[105.80218603]]\n",
      "[[85.93980211]] [[12.17053539]] [[123.25045958]]\n",
      "[[87.38063566]] [[8.63466436]] [[89.64711181]]\n",
      "[[86.94751804]] [[9.78954111]] [[83.52370211]]\n",
      "[[86.13759443]] [[12.85455776]] [[114.01526719]]\n",
      "[[86.95566862]] [[9.86631567]] [[96.35976666]]\n",
      "[[87.02893514]] [[9.51067876]] [[56.34802304]]\n",
      "[[84.53442035]] [[3.48170784]] [[101.23554027]]\n",
      "[[85.28385645]] [[10.0505004]] [[66.25343239]]\n",
      "[[83.70985403]] [[17.9101935]] [[51.43111136]]\n",
      "[[80.63942692]] [[8.10732809]] [[60.82144973]]\n",
      "[[79.03087935]] [[9.85032123]] [[60.20841291]]\n",
      "[[77.22932215]] [[8.29357001]] [[102.62824047]]\n",
      "[[78.24968143]] [[5.87019722]] [[82.67406965]]\n",
      "[[78.2665047]] [[4.93851809]] [[93.74914376]]\n",
      "[[78.78544389]] [[8.32595108]] [[57.46952321]]\n",
      "[[77.11142424]] [[11.89194389]] [[111.18417637]]\n",
      "[[78.48493862]] [[8.26274471]] [[84.99065648]]\n",
      "[[78.40349979]] [[3.13425243]] [[96.85484963]]\n",
      "[[79.26555379]] [[3.13692499]] [[92.91894105]]\n",
      "[[79.84488092]] [[17.2498618]] [[80.81814273]]\n",
      "[[78.45759841]] [[6.75627607]] [[57.44415081]]\n",
      "[[76.83221702]] [[5.67150778]] [[60.65564912]]\n",
      "[[75.63132208]] [[13.67643587]] [[102.95644871]]\n",
      "[[76.41909268]] [[4.95371334]] [[71.22422324]]\n",
      "[[75.751337]] [[10.91479894]] [[105.58536424]]\n",
      "[[76.8478761]] [[13.24267987]] [[111.52343418]]\n",
      "[[78.00490189]] [[6.50576222]] [[100.00458847]]\n",
      "[[78.82153331]] [[9.1647938]] [[80.99867335]]\n",
      "[[78.18585467]] [[3.97879449]] [[68.55937244]]\n",
      "[[77.3072018]] [[10.66598943]] [[69.80142754]]\n",
      "[[76.22273648]] [[1.67041133]] [[68.12290342]]\n",
      "[[75.64550487]] [[2.13876467]] [[69.96377419]]\n",
      "[[75.14075367]] [[6.25380854]] [[63.07889744]]\n",
      "[[74.08012028]] [[5.36601679]] [[82.09039991]]\n",
      "[[74.36181296]] [[8.11491104]] [[77.91898973]]\n",
      "[[74.1724535]] [[5.08152311]] [[102.04640469]]\n",
      "[[75.43600262]] [[11.38592208]] [[95.63536801]]\n",
      "[[76.0253905]] [[4.40180299]] [[68.93378266]]\n",
      "[[75.38817177]] [[13.01443445]] [[104.54909033]]\n",
      "[[76.16820576]] [[6.97446046]] [[73.47483813]]\n",
      "[[75.40691787]] [[10.16799554]] [[81.19811886]]\n",
      "[[75.21365229]] [[5.27226207]] [[94.87017799]]\n",
      "[[76.02979537]] [[7.96445511]] [[47.08649622]]\n",
      "[[73.74025078]] [[4.97916062]] [[74.50404688]]\n",
      "[[73.47808931]] [[5.30151472]] [[79.48999091]]\n",
      "[[73.5697001]] [[7.34583774]] [[97.57150146]]\n",
      "[[74.62018438]] [[8.63176516]] [[81.9858228]]\n",
      "[[74.40808284]] [[5.26035706]] [[91.88111741]]\n",
      "[[75.12575654]] [[11.40362371]] [[82.54820884]]\n",
      "[[74.77618818]] [[14.6425406]] [[115.25879312]]\n",
      "[[76.29929522]] [[6.60525132]] [[97.80201044]]\n",
      "[[77.06741077]] [[6.70963039]] [[96.45049567]]\n",
      "[[77.814462]] [[3.64926427]] [[69.66833125]]\n",
      "[[77.05943113]] [[6.1862176]] [[86.01430632]]\n",
      "[[77.2595202]] [[8.92051772]] [[93.61325839]]\n",
      "[[77.84448656]] [[13.1567241]] [[94.87392042]]\n",
      "[[78.27374944]] [[12.79779852]] [[96.97230922]]\n",
      "[[78.54788505]] [[5.14588029]] [[85.35048552]]\n",
      "[[78.72145258]] [[4.4447478]] [[106.18013864]]\n",
      "[[80.11425118]] [[4.03394753]] [[81.77509861]]\n",
      "[[79.85832061]] [[3.78966868]] [[100.26898333]]\n",
      "[[80.76789575]] [[6.02483067]] [[75.35018215]]\n",
      "[[79.98996686]] [[6.56921868]] [[76.16158085]]\n",
      "[[79.26064937]] [[1.44048759]] [[91.81081897]]\n",
      "[[79.73290814]] [[7.34430194]] [[107.08512952]]\n",
      "[[81.00249605]] [[8.80202779]] [[114.01802444]]\n",
      "[[82.54069556]] [[9.72563056]] [[112.19518592]]\n",
      "[[83.5702874]] [[6.6472693]] [[63.72354817]]\n",
      "[[81.9812388]] [[3.29723299]] [[96.4491139]]\n",
      "[[82.52825099]] [[13.19235645]] [[40.7242996]]\n",
      "[[79.45621389]] [[15.49238334]] [[78.25073591]]\n",
      "[[78.47222541]] [[6.47083597]] [[69.745769]]\n",
      "(100, 40)\n",
      "[18. 25. 16. 19. 30. 25. 23. 23. 19. 24. 20. 15. 17. 11. 24. 19. 19. 18.\n",
      " 25. 23. 17. 18. 20. 17. 21. 19. 23. 18. 18. 18. 22. 30. 25. 14. 18. 19.\n",
      " 17. 22. 18. 13.]\n",
      "(40, 50)\n",
      "40\n",
      "[[78.24968143]] [[26.30360816]] [[36.48419354]]\n",
      "[[53.58728376]] [[22.7579422]] [[34.82891798]]\n",
      "[[61.8201838]] [[28.62508516]] [[42.40072051]]\n",
      "[[73.38369192]] [[33.99474804]] [[42.78895403]]\n",
      "[[80.63984671]] [[37.29271766]] [[50.7094851]]\n",
      "[[62.2858303]] [[36.18522321]] [[30.31100944]]\n",
      "[[62.78169285]] [[30.05408883]] [[28.19874829]]\n",
      "[[49.34144402]] [[29.10894702]] [[32.99514105]]\n",
      "[[71.06981777]] [[28.0906423]] [[35.33700718]]\n",
      "[[59.94237685]] [[23.16419549]] [[33.75978687]]\n",
      "[[51.36335007]] [[31.74750924]] [[33.28988897]]\n",
      "[[70.42452621]] [[27.51143783]] [[38.05256708]]\n",
      "[[75.17859146]] [[27.34691008]] [[56.51298813]]\n",
      "[[80.34398997]] [[37.8526734]] [[43.70547527]]\n",
      "[[67.92213369]] [[76.07585131]] [[0.51661991]]\n",
      "[[70.62584142]] [[35.94750105]] [[25.31024501]]\n",
      "[[52.44894329]] [[24.41828023]] [[38.96513215]]\n",
      "[[79.23227819]] [[33.29332609]] [[44.07983381]]\n",
      "[[76.76115184]] [[33.27975623]] [[36.13786752]]\n",
      "[[60.40019422]] [[23.34198501]] [[32.95858906]]\n",
      "[[48.27742]] [[26.82062528]] [[28.61062374]]\n",
      "[[60.45503936]] [[37.82015555]] [[26.7888255]]\n",
      "[[68.71275185]] [[23.69863012]] [[32.34947294]]\n",
      "[[51.73982668]] [[19.71687028]] [[32.64819526]]\n",
      "[[60.72195353]] [[32.28023843]] [[28.82672125]]\n",
      "[[70.83906588]] [[27.38528548]] [[39.39015064]]\n",
      "[[80.16307545]] [[27.56409604]] [[39.75167444]]\n",
      "[[68.72352016]] [[20.54076882]] [[47.32657245]]\n",
      "[[50.90061525]] [[35.25518246]] [[30.64328948]]\n",
      "[[58.6389964]] [[31.15191205]] [[23.53841205]]\n",
      "[[66.17346389]] [[28.97509348]] [[37.87460726]]\n",
      "[[79.01964979]] [[25.82962973]] [[41.98780913]]\n",
      "[[58.87036135]] [[21.52856819]] [[34.68675488]]\n",
      "[[50.45999739]] [[24.51825252]] [[29.87925376]]\n",
      "[[78.46028882]] [[32.70602378]] [[37.66112049]]\n",
      "[[60.87394903]] [[29.18607716]] [[35.43919806]]\n",
      "[[67.93597017]] [[41.44210708]] [[41.64536602]]\n",
      "[[81.86823922]] [[32.22546206]] [[40.3930319]]\n",
      "[[62.50742857]] [[22.6094552]] [[37.65148607]]\n",
      "[[58.40664914]] [[22.6094552]] [[38.12984475]]\n",
      "\n",
      "\n",
      "[[75.63132208]] [[76.07969849]] [[0.55567405]]\n",
      "[[50.53351253]] [[49.71839947]] [[0.47520915]]\n",
      "[[60.52370856]] [[59.66945868]] [[0.24181779]]\n",
      "[[70.4213909]] [[79.68795044]] [[2.00548484]]\n",
      "[[77.39668394]] [[83.4024236]] [[0.40563239]]\n",
      "[[62.42832531]] [[89.96284414]] [[3.79053789]]\n",
      "[[61.67919144]] [[65.28936602]] [[0.68101907]]\n",
      "[[51.52296956]] [[52.5377484]] [[0.93822931]]\n",
      "[[71.68424957]] [[73.76432145]] [[0.29030582]]\n",
      "[[58.75469178]] [[57.73229642]] [[0.82320443]]\n",
      "[[48.32969249]] [[51.98981428]] [[1.80620153]]\n",
      "[[67.28608248]] [[61.3721281]] [[0.63483817]]\n",
      "[[74.94343529]] [[59.76615622]] [[2.91370119]]\n",
      "[[77.32345695]] [[80.19087155]] [[0.6888676]]\n",
      "[[68.8172025]] [[78.33890176]] [[0.96344694]]\n",
      "[[71.26079158]] [[74.65209701]] [[0.25574416]]\n",
      "[[49.53074605]] [[53.52800548]] [[0.30431734]]\n",
      "[[76.1252079]] [[74.34543596]] [[0.99383511]]\n",
      "[[73.60280551]] [[66.81564853]] [[0.47233488]]\n",
      "[[59.79445479]] [[59.27290522]] [[0.43212568]]\n",
      "[[50.52425775]] [[51.56011933]] [[0.15113067]]\n",
      "[[60.41869501]] [[60.88299028]] [[0.36161049]]\n",
      "[[63.81457031]] [[65.24701804]] [[1.37336912]]\n",
      "[[48.8643298]] [[57.10563767]] [[0.67291606]]\n",
      "[[60.84202082]] [[58.17012062]] [[0.62910271]]\n",
      "[[65.93681009]] [[60.72168044]] [[0.4229553]]\n",
      "[[80.08448189]] [[62.78775958]] [[3.07151932]]\n",
      "[[63.71149329]] [[59.66302406]] [[0.28847215]]\n",
      "[[53.42772306]] [[58.8558972]] [[0.61841237]]\n",
      "[[58.60706312]] [[72.48369812]] [[2.15570827]]\n",
      "[[61.26422195]] [[58.21929997]] [[0.41221975]]\n",
      "[[78.89670642]] [[63.48892364]] [[1.4077294]]\n",
      "[[58.18254812]] [[55.94408513]] [[0.3494183]]\n",
      "[[52.60556708]] [[55.14204857]] [[1.07759199]]\n",
      "[[75.28975277]] [[69.56084548]] [[0.65930407]]\n",
      "[[60.25425568]] [[64.7970882]] [[0.4476865]]\n",
      "[[68.5740605]] [[70.38875299]] [[0.23123153]]\n",
      "[[81.37774375]] [[95.47746082]] [[1.02309956]]\n",
      "[[61.3771549]] [[63.5284937]] [[0.3720448]]\n",
      "[[57.68129664]] [[63.31161848]] [[1.10319208]]\n",
      "0.5477470930570457\n",
      "0.014204108576261091\n",
      "38.56258139088569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.4159 \n",
      "Accuracy: 3686/10000 (36.86%)\n",
      "\n",
      "\n",
      "Learning Rate = 1.669449081803005e-05\n",
      "\n",
      "[[129.83220146]] [[129.82993934]] [[5.89974868e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.4013 \n",
      "Accuracy: 3694/10000 (36.94%)\n",
      "\n",
      "Round   0, Train average loss 1.872 Test accuracy 36.940\n",
      "[[129.82993934]] [[129.82773437]] [[5.23193529e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.3849 \n",
      "Accuracy: 3714/10000 (37.14%)\n",
      "\n",
      "Round   1, Train average loss 1.861 Test accuracy 37.140\n",
      "[[129.82773437]] [[129.82592509]] [[7.59725855e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.3727 \n",
      "Accuracy: 3727/10000 (37.27%)\n",
      "\n",
      "Round   2, Train average loss 1.848 Test accuracy 37.270\n",
      "[[129.82592509]] [[129.82358595]] [[7.3566993e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.3620 \n",
      "Accuracy: 3732/10000 (37.32%)\n",
      "\n",
      "Round   3, Train average loss 1.838 Test accuracy 37.320\n",
      "[[129.82358595]] [[129.82153539]] [[8.61210973e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.3515 \n",
      "Accuracy: 3725/10000 (37.25%)\n",
      "\n",
      "Round   4, Train average loss 1.830 Test accuracy 37.250\n",
      "[[129.82153539]] [[129.8194937]] [[7.11740907e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.3403 \n",
      "Accuracy: 3740/10000 (37.40%)\n",
      "\n",
      "Round   5, Train average loss 1.822 Test accuracy 37.400\n",
      "[[129.8194937]] [[129.81750402]] [[4.87309676e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.3312 \n",
      "Accuracy: 3744/10000 (37.44%)\n",
      "\n",
      "Round   6, Train average loss 1.814 Test accuracy 37.440\n",
      "[[129.81750402]] [[129.81474723]] [[1.22509056e-05]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.3134 \n",
      "Accuracy: 3764/10000 (37.64%)\n",
      "\n",
      "Round   7, Train average loss 1.806 Test accuracy 37.640\n",
      "[[129.81474723]] [[129.81248803]] [[4.01099035e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.3033 \n",
      "Accuracy: 3770/10000 (37.70%)\n",
      "\n",
      "Round   8, Train average loss 1.792 Test accuracy 37.700\n",
      "[[129.81248803]] [[129.81082285]] [[1.84840618e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2992 \n",
      "Accuracy: 3771/10000 (37.71%)\n",
      "\n",
      "Round   9, Train average loss 1.784 Test accuracy 37.710\n",
      "[[129.81082285]] [[129.80933534]] [[2.01683605e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2967 \n",
      "Accuracy: 3780/10000 (37.80%)\n",
      "\n",
      "Round  10, Train average loss 1.781 Test accuracy 37.800\n",
      "[[129.80933534]] [[129.80737916]] [[2.45981958e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2911 \n",
      "Accuracy: 3785/10000 (37.85%)\n",
      "\n",
      "Round  11, Train average loss 1.779 Test accuracy 37.850\n",
      "[[129.80737916]] [[129.80486027]] [[9.25620338e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2781 \n",
      "Accuracy: 3804/10000 (38.04%)\n",
      "\n",
      "Round  12, Train average loss 1.774 Test accuracy 38.040\n",
      "[[129.80486027]] [[129.80323919]] [[4.3318719e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2717 \n",
      "Accuracy: 3811/10000 (38.11%)\n",
      "\n",
      "Round  13, Train average loss 1.765 Test accuracy 38.110\n",
      "[[129.80323919]] [[129.80123379]] [[2.85577679e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2680 \n",
      "Accuracy: 3816/10000 (38.16%)\n",
      "\n",
      "Round  14, Train average loss 1.760 Test accuracy 38.160\n",
      "[[129.80123379]] [[129.79950638]] [[4.34794252e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2616 \n",
      "Accuracy: 3826/10000 (38.26%)\n",
      "\n",
      "Round  15, Train average loss 1.757 Test accuracy 38.260\n",
      "[[129.79950638]] [[129.79747411]] [[1.44085754e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2603 \n",
      "Accuracy: 3825/10000 (38.25%)\n",
      "\n",
      "Round  16, Train average loss 1.752 Test accuracy 38.250\n",
      "[[129.79747411]] [[129.79566826]] [[2.13112892e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2563 \n",
      "Accuracy: 3820/10000 (38.20%)\n",
      "\n",
      "Round  17, Train average loss 1.751 Test accuracy 38.200\n",
      "[[129.79566826]] [[129.7937567]] [[1.81970978e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2542 \n",
      "Accuracy: 3823/10000 (38.23%)\n",
      "\n",
      "Round  18, Train average loss 1.748 Test accuracy 38.230\n",
      "[[129.7937567]] [[129.79174924]] [[1.68913139e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2500 \n",
      "Accuracy: 3824/10000 (38.24%)\n",
      "\n",
      "Round  19, Train average loss 1.746 Test accuracy 38.240\n",
      "[[129.79174924]] [[129.78997178]] [[2.8364345e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2459 \n",
      "Accuracy: 3836/10000 (38.36%)\n",
      "\n",
      "Round  20, Train average loss 1.742 Test accuracy 38.360\n",
      "[[129.78997178]] [[129.78830836]] [[2.61735478e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2471 \n",
      "Accuracy: 3835/10000 (38.35%)\n",
      "\n",
      "Round  21, Train average loss 1.739 Test accuracy 38.350\n",
      "[[129.78830836]] [[129.7868241]] [[1.5882029e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2485 \n",
      "Accuracy: 3826/10000 (38.26%)\n",
      "\n",
      "Round  22, Train average loss 1.740 Test accuracy 38.260\n",
      "[[129.7868241]] [[129.78504035]] [[2.64935622e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2481 \n",
      "Accuracy: 3836/10000 (38.36%)\n",
      "\n",
      "Round  23, Train average loss 1.741 Test accuracy 38.360\n",
      "[[129.78504035]] [[129.78289222]] [[6.09447713e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2425 \n",
      "Accuracy: 3843/10000 (38.43%)\n",
      "\n",
      "Round  24, Train average loss 1.741 Test accuracy 38.430\n",
      "[[129.78289222]] [[129.78130791]] [[2.70969184e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2374 \n",
      "Accuracy: 3836/10000 (38.36%)\n",
      "\n",
      "Round  25, Train average loss 1.736 Test accuracy 38.360\n",
      "[[129.78130791]] [[129.77959962]] [[4.36548617e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2337 \n",
      "Accuracy: 3826/10000 (38.26%)\n",
      "\n",
      "Round  26, Train average loss 1.732 Test accuracy 38.260\n",
      "[[129.77959962]] [[129.77747916]] [[4.85017614e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2281 \n",
      "Accuracy: 3852/10000 (38.52%)\n",
      "\n",
      "Round  27, Train average loss 1.729 Test accuracy 38.520\n",
      "[[129.77747916]] [[129.77534173]] [[3.75325158e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2243 \n",
      "Accuracy: 3854/10000 (38.54%)\n",
      "\n",
      "Round  28, Train average loss 1.725 Test accuracy 38.540\n",
      "[[129.77534173]] [[129.77353544]] [[2.80786116e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2223 \n",
      "Accuracy: 3867/10000 (38.67%)\n",
      "\n",
      "Round  29, Train average loss 1.721 Test accuracy 38.670\n",
      "[[129.77353544]] [[129.77173787]] [[3.85499817e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2183 \n",
      "Accuracy: 3866/10000 (38.66%)\n",
      "\n",
      "Round  30, Train average loss 1.720 Test accuracy 38.660\n",
      "[[129.77173787]] [[129.76999897]] [[1.65702893e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2165 \n",
      "Accuracy: 3866/10000 (38.66%)\n",
      "\n",
      "Round  31, Train average loss 1.717 Test accuracy 38.660\n",
      "[[129.76999897]] [[129.76830661]] [[4.18140929e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2135 \n",
      "Accuracy: 3858/10000 (38.58%)\n",
      "\n",
      "Round  32, Train average loss 1.716 Test accuracy 38.580\n",
      "[[129.76830661]] [[129.76640808]] [[2.35903122e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2101 \n",
      "Accuracy: 3869/10000 (38.69%)\n",
      "\n",
      "Round  33, Train average loss 1.713 Test accuracy 38.690\n",
      "[[129.76640808]] [[129.76465067]] [[3.18673909e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2056 \n",
      "Accuracy: 3878/10000 (38.78%)\n",
      "\n",
      "Round  34, Train average loss 1.710 Test accuracy 38.780\n",
      "[[129.76465067]] [[129.76272505]] [[1.94380963e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2028 \n",
      "Accuracy: 3884/10000 (38.84%)\n",
      "\n",
      "Round  35, Train average loss 1.707 Test accuracy 38.840\n",
      "[[129.76272505]] [[129.76080141]] [[3.46452415e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2035 \n",
      "Accuracy: 3883/10000 (38.83%)\n",
      "\n",
      "Round  36, Train average loss 1.705 Test accuracy 38.830\n",
      "[[129.76080141]] [[129.75944155]] [[4.82750453e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2009 \n",
      "Accuracy: 3883/10000 (38.83%)\n",
      "\n",
      "Round  37, Train average loss 1.706 Test accuracy 38.830\n",
      "[[129.75944155]] [[129.75797289]] [[3.6135061e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2005 \n",
      "Accuracy: 3882/10000 (38.82%)\n",
      "\n",
      "Round  38, Train average loss 1.703 Test accuracy 38.820\n",
      "[[129.75797289]] [[129.75621049]] [[8.40361202e-07]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1987 \n",
      "Accuracy: 3881/10000 (38.81%)\n",
      "\n",
      "Round  39, Train average loss 1.703 Test accuracy 38.810\n",
      "[[129.75621049]] [[129.75457178]] [[1.9462883e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1976 \n",
      "Accuracy: 3887/10000 (38.87%)\n",
      "\n",
      "Round  40, Train average loss 1.702 Test accuracy 38.870\n",
      "[[129.75457178]] [[129.75286957]] [[3.33995012e-06]]\n",
      "net_glob is updated !!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.1939 \n",
      "Accuracy: 3889/10000 (38.89%)\n",
      "\n",
      "Round  41, Train average loss 1.701 Test accuracy 38.890\n",
      "[[129.75286957]] [[129.75127013]] [[2.72248164e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1966 \n",
      "Accuracy: 3888/10000 (38.88%)\n",
      "\n",
      "Round  42, Train average loss 1.698 Test accuracy 38.880\n",
      "[[129.75127013]] [[129.7492151]] [[2.95300097e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1916 \n",
      "Accuracy: 3883/10000 (38.83%)\n",
      "\n",
      "Round  43, Train average loss 1.700 Test accuracy 38.830\n",
      "[[129.7492151]] [[129.74765639]] [[3.75533712e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1931 \n",
      "Accuracy: 3882/10000 (38.82%)\n",
      "\n",
      "Round  44, Train average loss 1.696 Test accuracy 38.820\n",
      "[[129.74765639]] [[129.74565896]] [[2.97887917e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1893 \n",
      "Accuracy: 3875/10000 (38.75%)\n",
      "\n",
      "Round  45, Train average loss 1.697 Test accuracy 38.750\n",
      "[[129.74565896]] [[129.74350996]] [[4.22221481e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1854 \n",
      "Accuracy: 3884/10000 (38.84%)\n",
      "\n",
      "Round  46, Train average loss 1.694 Test accuracy 38.840\n",
      "[[129.74350996]] [[129.74160324]] [[4.66803722e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1834 \n",
      "Accuracy: 3888/10000 (38.88%)\n",
      "\n",
      "Round  47, Train average loss 1.691 Test accuracy 38.880\n",
      "[[129.74160324]] [[129.74005396]] [[2.3298736e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1806 \n",
      "Accuracy: 3895/10000 (38.95%)\n",
      "\n",
      "Round  48, Train average loss 1.689 Test accuracy 38.950\n",
      "[[129.74005396]] [[129.73847391]] [[3.82836753e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1795 \n",
      "Accuracy: 3904/10000 (39.04%)\n",
      "\n",
      "Round  49, Train average loss 1.687 Test accuracy 39.040\n",
      "[[129.73847391]] [[129.73694762]] [[2.45717152e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1791 \n",
      "Accuracy: 3896/10000 (38.96%)\n",
      "\n",
      "Round  50, Train average loss 1.687 Test accuracy 38.960\n",
      "[[129.73694762]] [[129.73554198]] [[2.52686356e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1799 \n",
      "Accuracy: 3896/10000 (38.96%)\n",
      "\n",
      "Round  51, Train average loss 1.687 Test accuracy 38.960\n",
      "[[129.73554198]] [[129.7339393]] [[2.76490179e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1789 \n",
      "Accuracy: 3892/10000 (38.92%)\n",
      "\n",
      "Round  52, Train average loss 1.687 Test accuracy 38.920\n",
      "[[129.7339393]] [[129.73239823]] [[3.006967e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1770 \n",
      "Accuracy: 3897/10000 (38.97%)\n",
      "\n",
      "Round  53, Train average loss 1.686 Test accuracy 38.970\n",
      "[[129.73239823]] [[129.7306049]] [[3.40084051e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1746 \n",
      "Accuracy: 3898/10000 (38.98%)\n",
      "\n",
      "Round  54, Train average loss 1.685 Test accuracy 38.980\n",
      "[[129.7306049]] [[129.72851045]] [[3.04414506e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1738 \n",
      "Accuracy: 3894/10000 (38.94%)\n",
      "\n",
      "Round  55, Train average loss 1.683 Test accuracy 38.940\n",
      "[[129.72851045]] [[129.72698411]] [[4.57005703e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1718 \n",
      "Accuracy: 3896/10000 (38.96%)\n",
      "\n",
      "Round  56, Train average loss 1.683 Test accuracy 38.960\n",
      "[[129.72698411]] [[129.72522835]] [[3.28801858e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1712 \n",
      "Accuracy: 3886/10000 (38.86%)\n",
      "\n",
      "Round  57, Train average loss 1.682 Test accuracy 38.860\n",
      "[[129.72522835]] [[129.72335813]] [[2.47324887e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1690 \n",
      "Accuracy: 3890/10000 (38.90%)\n",
      "\n",
      "Round  58, Train average loss 1.681 Test accuracy 38.900\n",
      "[[129.72335813]] [[129.72177625]] [[2.73180784e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1683 \n",
      "Accuracy: 3892/10000 (38.92%)\n",
      "\n",
      "Round  59, Train average loss 1.679 Test accuracy 38.920\n",
      "[[129.72177625]] [[129.71996984]] [[3.74769281e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1675 \n",
      "Accuracy: 3894/10000 (38.94%)\n",
      "\n",
      "Round  60, Train average loss 1.679 Test accuracy 38.940\n",
      "[[129.71996984]] [[129.71839846]] [[1.84026093e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1668 \n",
      "Accuracy: 3884/10000 (38.84%)\n",
      "\n",
      "Round  61, Train average loss 1.678 Test accuracy 38.840\n",
      "[[129.71839846]] [[129.71716411]] [[4.16956153e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1658 \n",
      "Accuracy: 3900/10000 (39.00%)\n",
      "\n",
      "Round  62, Train average loss 1.678 Test accuracy 39.000\n",
      "[[129.71716411]] [[129.71529635]] [[3.65727398e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1636 \n",
      "Accuracy: 3905/10000 (39.05%)\n",
      "\n",
      "Round  63, Train average loss 1.677 Test accuracy 39.050\n",
      "[[129.71529635]] [[129.71335402]] [[2.24619216e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1624 \n",
      "Accuracy: 3897/10000 (38.97%)\n",
      "\n",
      "Round  64, Train average loss 1.676 Test accuracy 38.970\n",
      "[[129.71335402]] [[129.71172814]] [[2.30687615e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1607 \n",
      "Accuracy: 3900/10000 (39.00%)\n",
      "\n",
      "Round  65, Train average loss 1.675 Test accuracy 39.000\n",
      "[[129.71172814]] [[129.71013073]] [[4.44546014e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1589 \n",
      "Accuracy: 3898/10000 (38.98%)\n",
      "\n",
      "Round  66, Train average loss 1.673 Test accuracy 38.980\n",
      "[[129.71013073]] [[129.70852928]] [[3.24881335e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1580 \n",
      "Accuracy: 3889/10000 (38.89%)\n",
      "\n",
      "Round  67, Train average loss 1.672 Test accuracy 38.890\n",
      "[[129.70852928]] [[129.70688761]] [[2.67373269e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1572 \n",
      "Accuracy: 3884/10000 (38.84%)\n",
      "\n",
      "Round  68, Train average loss 1.671 Test accuracy 38.840\n",
      "[[129.70688761]] [[129.70519392]] [[6.33521096e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1563 \n",
      "Accuracy: 3883/10000 (38.83%)\n",
      "\n",
      "Round  69, Train average loss 1.670 Test accuracy 38.830\n",
      "[[129.70519392]] [[129.70372859]] [[2.99943435e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1556 \n",
      "Accuracy: 3883/10000 (38.83%)\n",
      "\n",
      "Round  70, Train average loss 1.670 Test accuracy 38.830\n",
      "[[129.70372859]] [[129.70204146]] [[1.95165954e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1556 \n",
      "Accuracy: 3890/10000 (38.90%)\n",
      "\n",
      "Round  71, Train average loss 1.670 Test accuracy 38.900\n",
      "[[129.70204146]] [[129.70055446]] [[2.18454013e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1550 \n",
      "Accuracy: 3881/10000 (38.81%)\n",
      "\n",
      "Round  72, Train average loss 1.670 Test accuracy 38.810\n",
      "[[129.70055446]] [[129.69862233]] [[1.29008943e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1537 \n",
      "Accuracy: 3889/10000 (38.89%)\n",
      "\n",
      "Round  73, Train average loss 1.669 Test accuracy 38.890\n",
      "[[129.69862233]] [[129.69711082]] [[2.03321531e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1533 \n",
      "Accuracy: 3891/10000 (38.91%)\n",
      "\n",
      "Round  74, Train average loss 1.668 Test accuracy 38.910\n",
      "[[129.69711082]] [[129.69530837]] [[3.00477808e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1520 \n",
      "Accuracy: 3893/10000 (38.93%)\n",
      "\n",
      "Round  75, Train average loss 1.668 Test accuracy 38.930\n",
      "[[129.69530837]] [[129.69324662]] [[3.67700729e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1499 \n",
      "Accuracy: 3881/10000 (38.81%)\n",
      "\n",
      "Round  76, Train average loss 1.667 Test accuracy 38.810\n",
      "[[129.69324662]] [[129.69158105]] [[3.11859226e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1493 \n",
      "Accuracy: 3882/10000 (38.82%)\n",
      "\n",
      "Round  77, Train average loss 1.665 Test accuracy 38.820\n",
      "[[129.69158105]] [[129.68979716]] [[6.40511408e-07]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1487 \n",
      "Accuracy: 3886/10000 (38.86%)\n",
      "\n",
      "Round  78, Train average loss 1.665 Test accuracy 38.860\n",
      "[[129.68979716]] [[129.68802569]] [[3.57895225e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1472 \n",
      "Accuracy: 3892/10000 (38.92%)\n",
      "\n",
      "Round  79, Train average loss 1.664 Test accuracy 38.920\n",
      "[[129.68802569]] [[129.68633363]] [[2.38377185e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1468 \n",
      "Accuracy: 3886/10000 (38.86%)\n",
      "\n",
      "Round  80, Train average loss 1.664 Test accuracy 38.860\n",
      "[[129.68633363]] [[129.68457503]] [[6.2851771e-07]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1462 \n",
      "Accuracy: 3885/10000 (38.85%)\n",
      "\n",
      "Round  81, Train average loss 1.664 Test accuracy 38.850\n",
      "[[129.68457503]] [[129.6827891]] [[2.29006055e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1446 \n",
      "Accuracy: 3879/10000 (38.79%)\n",
      "\n",
      "Round  82, Train average loss 1.663 Test accuracy 38.790\n",
      "[[129.6827891]] [[129.68114035]] [[5.12989851e-06]]\n",
      "net_glob is updated !!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.1448 \n",
      "Accuracy: 3882/10000 (38.82%)\n",
      "\n",
      "Round  83, Train average loss 1.662 Test accuracy 38.820\n",
      "[[129.68114035]] [[129.67967639]] [[4.91657452e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1449 \n",
      "Accuracy: 3885/10000 (38.85%)\n",
      "\n",
      "Round  84, Train average loss 1.662 Test accuracy 38.850\n",
      "[[129.67967639]] [[129.67817691]] [[4.93422076e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1428 \n",
      "Accuracy: 3889/10000 (38.89%)\n",
      "\n",
      "Round  85, Train average loss 1.663 Test accuracy 38.890\n",
      "[[129.67817691]] [[129.6765437]] [[1.77764345e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1424 \n",
      "Accuracy: 3883/10000 (38.83%)\n",
      "\n",
      "Round  86, Train average loss 1.661 Test accuracy 38.830\n",
      "[[129.6765437]] [[129.67537742]] [[1.86381231e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1421 \n",
      "Accuracy: 3883/10000 (38.83%)\n",
      "\n",
      "Round  87, Train average loss 1.661 Test accuracy 38.830\n",
      "[[129.67537742]] [[129.67357572]] [[1.75560227e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1409 \n",
      "Accuracy: 3887/10000 (38.87%)\n",
      "\n",
      "Round  88, Train average loss 1.661 Test accuracy 38.870\n",
      "[[129.67357572]] [[129.6720631]] [[2.2880171e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1409 \n",
      "Accuracy: 3887/10000 (38.87%)\n",
      "\n",
      "Round  89, Train average loss 1.660 Test accuracy 38.870\n",
      "[[129.6720631]] [[129.67061045]] [[2.26101549e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1415 \n",
      "Accuracy: 3889/10000 (38.89%)\n",
      "\n",
      "Round  90, Train average loss 1.660 Test accuracy 38.890\n",
      "[[129.67061045]] [[129.66908565]] [[3.47247422e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1416 \n",
      "Accuracy: 3885/10000 (38.85%)\n",
      "\n",
      "Round  91, Train average loss 1.660 Test accuracy 38.850\n",
      "[[129.66908565]] [[129.66764209]] [[1.47993741e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1411 \n",
      "Accuracy: 3888/10000 (38.88%)\n",
      "\n",
      "Round  92, Train average loss 1.660 Test accuracy 38.880\n",
      "[[129.66764209]] [[129.66583691]] [[2.48076442e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1393 \n",
      "Accuracy: 3890/10000 (38.90%)\n",
      "\n",
      "Round  93, Train average loss 1.660 Test accuracy 38.900\n",
      "[[129.66583691]] [[129.66428869]] [[9.41358277e-07]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1383 \n",
      "Accuracy: 3888/10000 (38.88%)\n",
      "\n",
      "Round  94, Train average loss 1.658 Test accuracy 38.880\n",
      "[[129.66428869]] [[129.66280281]] [[3.15261055e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1389 \n",
      "Accuracy: 3884/10000 (38.84%)\n",
      "\n",
      "Round  95, Train average loss 1.657 Test accuracy 38.840\n",
      "[[129.66280281]] [[129.66119546]] [[2.93284944e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1378 \n",
      "Accuracy: 3888/10000 (38.88%)\n",
      "\n",
      "Round  96, Train average loss 1.658 Test accuracy 38.880\n",
      "[[129.66119546]] [[129.6593559]] [[1.12234058e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1368 \n",
      "Accuracy: 3888/10000 (38.88%)\n",
      "\n",
      "Round  97, Train average loss 1.657 Test accuracy 38.880\n",
      "[[129.6593559]] [[129.65808981]] [[1.46668759e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1361 \n",
      "Accuracy: 3888/10000 (38.88%)\n",
      "\n",
      "Round  98, Train average loss 1.656 Test accuracy 38.880\n",
      "[[129.65808981]] [[129.65663632]] [[1.25464902e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1359 \n",
      "Accuracy: 3897/10000 (38.97%)\n",
      "\n",
      "Round  99, Train average loss 1.656 Test accuracy 38.970\n",
      "[[102.77567816]] [[10.25459317]] [[80.25328272]]\n",
      "[[100.34154306]] [[14.89062676]] [[118.8588252]]\n",
      "[[100.24224303]] [[14.41913064]] [[83.07433578]]\n",
      "[[97.9672331]] [[16.87973507]] [[126.2982936]]\n",
      "[[98.12343852]] [[13.95012178]] [[75.68009862]]\n",
      "[[95.69772915]] [[9.55126965]] [[86.69627291]]\n",
      "[[94.47960483]] [[24.01177504]] [[44.66487674]]\n",
      "[[89.96397942]] [[7.86154108]] [[55.80750026]]\n",
      "[[87.41863438]] [[3.62287612]] [[98.86768403]]\n",
      "[[87.68356152]] [[3.95299867]] [[89.48887494]]\n",
      "[[87.45430378]] [[4.82124638]] [[58.90670944]]\n",
      "[[85.4323239]] [[18.14215862]] [[41.62635963]]\n",
      "[[81.32081648]] [[8.49046892]] [[74.08820029]]\n",
      "[[80.13235074]] [[5.5973225]] [[78.75318136]]\n",
      "[[79.73978256]] [[8.52196734]] [[98.4102184]]\n",
      "[[80.3430656]] [[2.82408078]] [[75.3394543]]\n",
      "[[79.91288847]] [[4.17701268]] [[78.67881321]]\n",
      "[[79.5306977]] [[3.56663116]] [[67.12438783]]\n",
      "[[78.61230795]] [[3.31069752]] [[69.93615528]]\n",
      "[[77.89610662]] [[5.55941162]] [[72.44502797]]\n",
      "[[77.21520736]] [[5.13001537]] [[74.0516201]]\n",
      "[[76.97915965]] [[3.11287769]] [[71.52535158]]\n",
      "[[76.50432778]] [[5.19273819]] [[78.31187333]]\n",
      "[[76.31578908]] [[11.94517517]] [[85.75031478]]\n",
      "[[76.1410135]] [[5.310996]] [[88.47863861]]\n",
      "[[76.44707829]] [[8.5563529]] [[66.30125517]]\n",
      "[[75.23597174]] [[9.50634523]] [[61.75112387]]\n",
      "[[73.80095667]] [[7.35637309]] [[80.47487694]]\n",
      "[[73.87981701]] [[5.50340787]] [[73.66260865]]\n",
      "[[73.44097649]] [[7.55579641]] [[90.91406965]]\n",
      "[[73.89090705]] [[3.24777671]] [[87.41040581]]\n",
      "[[74.38546055]] [[8.19556221]] [[83.63411844]]\n",
      "[[74.41631805]] [[4.62370119]] [[74.44095381]]\n",
      "[[74.197505]] [[6.24600861]] [[55.47349362]]\n",
      "[[72.47699823]] [[3.80986687]] [[72.44803285]]\n",
      "[[72.29245251]] [[6.79046733]] [[76.60465082]]\n",
      "[[72.06612149]] [[9.46190889]] [[86.29282002]]\n",
      "[[72.33237214]] [[7.08247195]] [[71.85068885]]\n",
      "[[71.89021037]] [[1.64710796]] [[68.20899364]]\n",
      "[[71.51386044]] [[3.81472507]] [[73.05254795]]\n",
      "[[71.41915415]] [[6.54630223]] [[83.1966884]]\n",
      "[[71.73754361]] [[5.33606402]] [[71.48782515]]\n",
      "[[71.45348088]] [[5.78788189]] [[63.34952247]]\n",
      "[[70.45609896]] [[7.36046075]] [[91.77269576]]\n",
      "[[71.39781595]] [[5.83860318]] [[46.77802552]]\n",
      "[[69.31196546]] [[8.27554102]] [[67.40124973]]\n",
      "[[68.68593543]] [[9.14935296]] [[60.17045816]]\n",
      "[[67.53614873]] [[4.56655226]] [[80.29898522]]\n",
      "[[67.88627017]] [[7.50360036]] [[83.44788168]]\n",
      "[[68.27447891]] [[4.81605619]] [[72.05502538]]\n",
      "[[68.2480285]] [[4.95265258]] [[83.07804479]]\n",
      "[[68.99244995]] [[5.4192075]] [[75.93857569]]\n",
      "[[68.94738892]] [[5.89365533]] [[87.00698106]]\n",
      "[[69.64461353]] [[6.66564739]] [[76.10137225]]\n",
      "[[69.46118138]] [[5.96652432]] [[71.45035037]]\n",
      "[[69.18795168]] [[8.95731178]] [[56.03661286]]\n",
      "[[67.81193085]] [[6.44451641]] [[56.90245568]]\n",
      "[[66.63575356]] [[4.84756778]] [[49.9616731]]\n",
      "[[65.38049076]] [[5.35434336]] [[55.97306042]]\n",
      "[[64.41384739]] [[7.3454779]] [[61.54402518]]\n",
      "[[63.9214296]] [[3.60691142]] [[57.82230099]]\n",
      "[[63.36830128]] [[8.17234059]] [[52.09922248]]\n",
      "[[62.08597087]] [[7.16825701]] [[33.63326382]]\n",
      "[[59.96519839]] [[4.40253663]] [[49.38529405]]\n",
      "[[59.10857456]] [[4.52147726]] [[72.97290848]]\n",
      "[[59.58404853]] [[8.71310187]] [[68.16598154]]\n",
      "[[59.60103041]] [[6.36767417]] [[42.5175599]]\n",
      "[[58.14249968]] [[5.24051608]] [[76.28210161]]\n",
      "[[58.98944094]] [[12.41701347]] [[28.54209892]]\n",
      "[[56.38968269]] [[5.87889132]] [[58.12131899]]\n",
      "[[56.04443019]] [[3.82525271]] [[45.24115403]]\n",
      "[[55.18473096]] [[4.28169865]] [[79.00328625]]\n",
      "[[56.40042336]] [[2.52857529]] [[53.81948485]]\n",
      "[[56.08231997]] [[3.98510201]] [[59.5680017]]\n",
      "[[56.07879393]] [[5.88936503]] [[55.14938422]]\n",
      "[[55.60716957]] [[7.20693429]] [[81.842573]]\n",
      "[[56.83150066]] [[6.11244083]] [[43.78707031]]\n",
      "[[55.65207383]] [[1.25540236]] [[52.85292807]]\n",
      "[[55.36933921]] [[7.01474642]] [[47.01306623]]\n",
      "[[54.32764967]] [[4.67219282]] [[67.50954087]]\n",
      "[[54.80529933]] [[1.23189471]] [[53.1893203]]\n",
      "[[54.62444924]] [[4.48851868]] [[77.84228957]]\n",
      "[[55.72285923]] [[10.05460109]] [[40.51013602]]\n",
      "[[54.16155253]] [[9.63648606]] [[67.8885452]]\n",
      "[[54.28439016]] [[9.6710727]] [[80.34220934]]\n",
      "[[55.31816877]] [[3.48418117]] [[53.60338788]]\n",
      "[[54.95629992]] [[3.65307214]] [[60.03376473]]\n",
      "[[55.0424099]] [[3.44098044]] [[60.15285981]]\n",
      "[[55.20080332]] [[4.48451352]] [[39.51545338]]\n",
      "[[54.06024392]] [[4.43159036]] [[43.46277543]]\n",
      "[[53.19142187]] [[6.80604947]] [[73.07135202]]\n",
      "[[54.0528399]] [[2.90067733]] [[57.56644314]]\n",
      "[[54.04754616]] [[4.86229827]] [[63.17178631]]\n",
      "[[54.25387978]] [[1.84506222]] [[55.28443767]]\n",
      "[[54.17803559]] [[6.17911668]] [[57.59272278]]\n",
      "[[53.99138776]] [[5.74838491]] [[52.59342123]]\n",
      "[[53.54208669]] [[2.19978753]] [[51.306638]]\n",
      "[[53.34286853]] [[2.87470767]] [[68.05918806]]\n",
      "(100, 40)\n",
      "[27. 22. 18. 18. 29. 19. 15. 20. 15. 24. 15. 23. 15. 19. 22. 26. 13. 21.\n",
      " 24. 17. 33. 19. 15. 16. 20. 13. 14. 19. 21. 20. 22. 23. 19. 24. 28. 15.\n",
      " 19. 18. 17. 23.]\n",
      "(40, 50)\n",
      "40\n",
      "[[71.89021037]] [[38.15994862]] [[26.36108664]]\n",
      "[[39.23486735]] [[30.94997272]] [[35.29031175]]\n",
      "[[60.51010462]] [[21.69624384]] [[36.76536511]]\n",
      "[[47.76838344]] [[25.89494776]] [[28.77032684]]\n",
      "[[74.39932522]] [[29.01257373]] [[43.03555231]]\n",
      "[[84.41405019]] [[28.2666885]] [[37.47033431]]\n",
      "[[61.05998065]] [[21.93528855]] [[29.31959021]]\n",
      "[[47.5021822]] [[21.18282422]] [[30.19481972]]\n",
      "[[63.81176379]] [[26.27508467]] [[29.3218625]]\n",
      "[[58.25210159]] [[21.38205629]] [[26.92788247]]\n",
      "[[37.08831407]] [[20.80370505]] [[22.37295268]]\n",
      "[[45.14746643]] [[35.96711494]] [[33.03114874]]\n",
      "[[61.29185159]] [[21.20151271]] [[31.91411133]]\n",
      "[[73.5645468]] [[31.84590514]] [[38.25559396]]\n",
      "[[62.32246927]] [[62.90334656]] [[0.99127303]]\n",
      "[[63.50019093]] [[30.56548754]] [[27.15599325]]\n",
      "[[38.74004359]] [[18.72431818]] [[24.95481464]]\n",
      "[[73.14186492]] [[21.82081262]] [[44.6107]]\n",
      "[[48.155347]] [[21.52445719]] [[25.34270817]]\n",
      "[[43.4098759]] [[15.57405902]] [[32.70962593]]\n",
      "[[45.13773025]] [[37.53323874]] [[34.52386998]]\n",
      "[[80.86749197]] [[36.15140368]] [[27.41079499]]\n",
      "[[41.46822339]] [[19.39717097]] [[22.43691404]]\n",
      "[[37.83358291]] [[22.95038051]] [[32.40491613]]\n",
      "[[81.37460384]] [[34.33049189]] [[52.91687969]]\n",
      "[[42.59113395]] [[36.53006144]] [[35.05615826]]\n",
      "[[66.03747423]] [[30.97302879]] [[31.22558678]]\n",
      "[[40.98148012]] [[16.36598473]] [[26.55173808]]\n",
      "[[47.7924643]] [[30.94568069]] [[28.12262543]]\n",
      "[[78.43745355]] [[32.92468878]] [[34.58264036]]\n",
      "[[40.51228051]] [[26.42102299]] [[27.45853255]]\n",
      "[[65.01042173]] [[19.29272249]] [[32.47502431]]\n",
      "[[41.48786495]] [[17.61438159]] [[25.70161941]]\n",
      "[[48.14653554]] [[18.87751181]] [[28.33598598]]\n",
      "[[51.13613753]] [[23.16452593]] [[29.19662509]]\n",
      "[[44.22234937]] [[24.11433972]] [[23.04700576]]\n",
      "[[61.94176554]] [[31.44977146]] [[34.62993083]]\n",
      "[[66.08777654]] [[28.41878081]] [[32.06616944]]\n",
      "[[61.32895142]] [[18.76836257]] [[33.59392613]]\n",
      "[[41.16008791]] [[18.76836257]] [[31.72698682]]\n",
      "\n",
      "\n",
      "[[67.88627017]] [[75.06949697]] [[1.93693661]]\n",
      "[[40.73882846]] [[48.8458286]] [[13.45448555]]\n",
      "[[55.03787374]] [[57.45866086]] [[0.28806177]]\n",
      "[[45.28161116]] [[53.85548584]] [[1.28062269]]\n",
      "[[70.41135252]] [[61.88642781]] [[1.10507045]]\n",
      "[[81.51983028]] [[73.01316595]] [[1.48543245]]\n",
      "[[55.11463927]] [[55.38496224]] [[0.55241045]]\n",
      "[[44.28807197]] [[39.93728713]] [[2.62983451]]\n",
      "[[65.19752724]] [[60.28524845]] [[1.37448965]]\n",
      "[[52.86220581]] [[58.84914959]] [[1.17339317]]\n",
      "[[39.04290959]] [[37.84495029]] [[1.0549396]]\n",
      "[[42.80439169]] [[49.64399981]] [[0.68987996]]\n",
      "[[59.82461744]] [[84.60930138]] [[7.87705203]]\n",
      "[[69.54711896]] [[66.50522984]] [[0.3611135]]\n",
      "[[63.45145232]] [[67.72813109]] [[0.48955925]]\n",
      "[[64.67460324]] [[61.81890311]] [[3.96468153]]\n",
      "[[40.19782235]] [[39.89237704]] [[0.75266268]]\n",
      "[[69.18020189]] [[55.41533094]] [[1.17138909]]\n",
      "[[45.67587873]] [[52.7722288]] [[1.52256717]]\n",
      "[[45.71478398]] [[37.19224915]] [[2.01249966]]\n",
      "[[42.13402657]] [[45.7728836]] [[1.74461187]]\n",
      "[[78.45055154]] [[83.42421181]] [[0.36161338]]\n",
      "[[45.62365263]] [[48.42645465]] [[0.86914938]]\n",
      "[[39.3822064]] [[43.36647796]] [[0.55869177]]\n",
      "[[78.83269714]] [[77.03453244]] [[0.42304616]]\n",
      "[[47.03189983]] [[84.22933651]] [[20.9708195]]\n",
      "[[64.22031554]] [[60.31023379]] [[2.39823993]]\n",
      "[[45.34152613]] [[71.50422371]] [[9.78527601]]\n",
      "[[44.67853661]] [[47.68005852]] [[0.37826791]]\n",
      "[[76.03901714]] [[73.46939921]] [[1.20640627]]\n",
      "[[44.65326338]] [[49.56414522]] [[0.76838271]]\n",
      "[[63.4505844]] [[61.96813644]] [[0.4200444]]\n",
      "[[43.70109263]] [[40.28112707]] [[0.54273187]]\n",
      "[[45.07363091]] [[44.12853008]] [[0.20487709]]\n",
      "[[48.76195758]] [[46.61744574]] [[0.2328303]]\n",
      "[[46.37285435]] [[55.06199146]] [[0.8305516]]\n",
      "[[63.33889139]] [[52.59081728]] [[1.95634696]]\n",
      "[[64.65051772]] [[66.84951617]] [[0.95027888]]\n",
      "[[55.77240987]] [[50.28246532]] [[1.69897233]]\n",
      "[[43.37491979]] [[34.98835095]] [[3.9081158]]\n",
      "0.5713529478374066\n",
      "0.04846390851427977\n",
      "11.789246170045466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.3315 \n",
      "Accuracy: 3859/10000 (38.59%)\n",
      "\n",
      "\n",
      "Learning Rate = 1.2515644555694618e-05\n",
      "\n",
      "[[130.92893587]] [[130.92731682]] [[1.91271051e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.3252 \n",
      "Accuracy: 3864/10000 (38.64%)\n",
      "\n",
      "Round   0, Train average loss 1.731 Test accuracy 38.640\n",
      "[[130.92731682]] [[130.92604227]] [[3.61671436e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.3237 \n",
      "Accuracy: 3862/10000 (38.62%)\n",
      "\n",
      "Round   1, Train average loss 1.727 Test accuracy 38.620\n",
      "[[130.92604227]] [[130.92460337]] [[3.86000344e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.3200 \n",
      "Accuracy: 3876/10000 (38.76%)\n",
      "\n",
      "Round   2, Train average loss 1.726 Test accuracy 38.760\n",
      "[[130.92460337]] [[130.92302161]] [[3.46662004e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.3160 \n",
      "Accuracy: 3878/10000 (38.78%)\n",
      "\n",
      "Round   3, Train average loss 1.723 Test accuracy 38.780\n",
      "[[130.92302161]] [[130.92154535]] [[2.88511971e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.3099 \n",
      "Accuracy: 3867/10000 (38.67%)\n",
      "\n",
      "Round   4, Train average loss 1.720 Test accuracy 38.670\n",
      "[[130.92154535]] [[130.91963939]] [[1.35517017e-05]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2863 \n",
      "Accuracy: 3899/10000 (38.99%)\n",
      "\n",
      "Round   5, Train average loss 1.716 Test accuracy 38.990\n",
      "[[130.91963939]] [[130.9185785]] [[5.26478163e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2937 \n",
      "Accuracy: 3884/10000 (38.84%)\n",
      "\n",
      "Round   6, Train average loss 1.698 Test accuracy 38.840\n",
      "[[130.9185785]] [[130.91700693]] [[3.66984917e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2828 \n",
      "Accuracy: 3911/10000 (39.11%)\n",
      "\n",
      "Round   7, Train average loss 1.704 Test accuracy 39.110\n",
      "[[130.91700693]] [[130.91534667]] [[5.69473074e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2739 \n",
      "Accuracy: 3911/10000 (39.11%)\n",
      "\n",
      "Round   8, Train average loss 1.696 Test accuracy 39.110\n",
      "[[130.91534667]] [[130.91361281]] [[4.13281676e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2681 \n",
      "Accuracy: 3914/10000 (39.14%)\n",
      "\n",
      "Round   9, Train average loss 1.689 Test accuracy 39.140\n",
      "[[130.91361281]] [[130.91206603]] [[8.85688008e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2608 \n",
      "Accuracy: 3913/10000 (39.13%)\n",
      "\n",
      "Round  10, Train average loss 1.684 Test accuracy 39.130\n",
      "[[130.91206603]] [[130.91066584]] [[5.09908195e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2657 \n",
      "Accuracy: 3901/10000 (39.01%)\n",
      "\n",
      "Round  11, Train average loss 1.679 Test accuracy 39.010\n",
      "[[130.91066584]] [[130.90916168]] [[4.35099195e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2631 \n",
      "Accuracy: 3898/10000 (38.98%)\n",
      "\n",
      "Round  12, Train average loss 1.683 Test accuracy 38.980\n",
      "[[130.90916168]] [[130.90746759]] [[4.01479022e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2601 \n",
      "Accuracy: 3898/10000 (38.98%)\n",
      "\n",
      "Round  13, Train average loss 1.681 Test accuracy 38.980\n",
      "[[130.90746759]] [[130.90621073]] [[2.90028112e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2592 \n",
      "Accuracy: 3895/10000 (38.95%)\n",
      "\n",
      "Round  14, Train average loss 1.679 Test accuracy 38.950\n",
      "[[130.90621073]] [[130.90485742]] [[1.59563173e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2565 \n",
      "Accuracy: 3913/10000 (39.13%)\n",
      "\n",
      "Round  15, Train average loss 1.678 Test accuracy 39.130\n",
      "[[130.90485742]] [[130.9034561]] [[1.50621185e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2535 \n",
      "Accuracy: 3914/10000 (39.14%)\n",
      "\n",
      "Round  16, Train average loss 1.676 Test accuracy 39.140\n",
      "[[130.9034561]] [[130.90193154]] [[1.00577366e-05]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2437 \n",
      "Accuracy: 3908/10000 (39.08%)\n",
      "\n",
      "Round  17, Train average loss 1.674 Test accuracy 39.080\n",
      "[[130.90193154]] [[130.90037125]] [[2.13937585e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2413 \n",
      "Accuracy: 3915/10000 (39.15%)\n",
      "\n",
      "Round  18, Train average loss 1.667 Test accuracy 39.150\n",
      "[[130.90037125]] [[130.89906043]] [[3.58406208e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2368 \n",
      "Accuracy: 3914/10000 (39.14%)\n",
      "\n",
      "Round  19, Train average loss 1.665 Test accuracy 39.140\n",
      "[[130.89906043]] [[130.89740952]] [[4.42780851e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2340 \n",
      "Accuracy: 3943/10000 (39.43%)\n",
      "\n",
      "Round  20, Train average loss 1.662 Test accuracy 39.430\n",
      "[[130.89740952]] [[130.8960347]] [[3.71260906e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2272 \n",
      "Accuracy: 3926/10000 (39.26%)\n",
      "\n",
      "Round  21, Train average loss 1.660 Test accuracy 39.260\n",
      "[[130.8960347]] [[130.89460983]] [[3.93975502e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2278 \n",
      "Accuracy: 3930/10000 (39.30%)\n",
      "\n",
      "Round  22, Train average loss 1.654 Test accuracy 39.300\n",
      "[[130.89460983]] [[130.89312747]] [[4.82643796e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2271 \n",
      "Accuracy: 3917/10000 (39.17%)\n",
      "\n",
      "Round  23, Train average loss 1.655 Test accuracy 39.170\n",
      "[[130.89312747]] [[130.89214578]] [[4.23659771e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2311 \n",
      "Accuracy: 3912/10000 (39.12%)\n",
      "\n",
      "Round  24, Train average loss 1.655 Test accuracy 39.120\n",
      "[[130.89214578]] [[130.89074541]] [[3.81050924e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2272 \n",
      "Accuracy: 3919/10000 (39.19%)\n",
      "\n",
      "Round  25, Train average loss 1.658 Test accuracy 39.190\n",
      "[[130.89074541]] [[130.88916762]] [[5.39935997e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2204 \n",
      "Accuracy: 3929/10000 (39.29%)\n",
      "\n",
      "Round  26, Train average loss 1.655 Test accuracy 39.290\n",
      "[[130.88916762]] [[130.88778757]] [[2.64427341e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2211 \n",
      "Accuracy: 3926/10000 (39.26%)\n",
      "\n",
      "Round  27, Train average loss 1.650 Test accuracy 39.260\n",
      "[[130.88778757]] [[130.88645542]] [[1.97200328e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2222 \n",
      "Accuracy: 3916/10000 (39.16%)\n",
      "\n",
      "Round  28, Train average loss 1.651 Test accuracy 39.160\n",
      "[[130.88645542]] [[130.88481674]] [[4.15264708e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2141 \n",
      "Accuracy: 3925/10000 (39.25%)\n",
      "\n",
      "Round  29, Train average loss 1.652 Test accuracy 39.250\n",
      "[[130.88481674]] [[130.88332903]] [[5.591196e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2084 \n",
      "Accuracy: 3939/10000 (39.39%)\n",
      "\n",
      "Round  30, Train average loss 1.646 Test accuracy 39.390\n",
      "[[130.88332903]] [[130.88223105]] [[4.65855645e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2097 \n",
      "Accuracy: 3931/10000 (39.31%)\n",
      "\n",
      "Round  31, Train average loss 1.641 Test accuracy 39.310\n",
      "[[130.88223105]] [[130.88072063]] [[2.6043313e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2073 \n",
      "Accuracy: 3923/10000 (39.23%)\n",
      "\n",
      "Round  32, Train average loss 1.642 Test accuracy 39.230\n",
      "[[130.88072063]] [[130.87951714]] [[4.11335017e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.2039 \n",
      "Accuracy: 3940/10000 (39.40%)\n",
      "\n",
      "Round  33, Train average loss 1.640 Test accuracy 39.400\n",
      "[[130.87951714]] [[130.87771406]] [[4.00578142e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1997 \n",
      "Accuracy: 3948/10000 (39.48%)\n",
      "\n",
      "Round  34, Train average loss 1.637 Test accuracy 39.480\n",
      "[[130.87771406]] [[130.87642332]] [[3.12721536e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1995 \n",
      "Accuracy: 3946/10000 (39.46%)\n",
      "\n",
      "Round  35, Train average loss 1.634 Test accuracy 39.460\n",
      "[[130.87642332]] [[130.87511799]] [[3.56594357e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1973 \n",
      "Accuracy: 3938/10000 (39.38%)\n",
      "\n",
      "Round  36, Train average loss 1.634 Test accuracy 39.380\n",
      "[[130.87511799]] [[130.8734659]] [[4.50955852e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1944 \n",
      "Accuracy: 3939/10000 (39.39%)\n",
      "\n",
      "Round  37, Train average loss 1.633 Test accuracy 39.390\n",
      "[[130.8734659]] [[130.87199149]] [[1.66442293e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1909 \n",
      "Accuracy: 3935/10000 (39.35%)\n",
      "\n",
      "Round  38, Train average loss 1.630 Test accuracy 39.350\n",
      "[[130.87199149]] [[130.87032938]] [[4.04970987e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1891 \n",
      "Accuracy: 3947/10000 (39.47%)\n",
      "\n",
      "Round  39, Train average loss 1.628 Test accuracy 39.470\n",
      "[[130.87032938]] [[130.86877668]] [[1.02083219e-05]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1876 \n",
      "Accuracy: 3949/10000 (39.49%)\n",
      "\n",
      "Round  40, Train average loss 1.627 Test accuracy 39.490\n",
      "[[130.86877668]] [[130.8674994]] [[7.580335e-06]]\n",
      "net_glob is updated !!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.1904 \n",
      "Accuracy: 3948/10000 (39.48%)\n",
      "\n",
      "Round  41, Train average loss 1.625 Test accuracy 39.480\n",
      "[[130.8674994]] [[130.86619385]] [[3.93841678e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1898 \n",
      "Accuracy: 3962/10000 (39.62%)\n",
      "\n",
      "Round  42, Train average loss 1.627 Test accuracy 39.620\n",
      "[[130.86619385]] [[130.86505152]] [[2.35067844e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1886 \n",
      "Accuracy: 3950/10000 (39.50%)\n",
      "\n",
      "Round  43, Train average loss 1.626 Test accuracy 39.500\n",
      "[[130.86505152]] [[130.86353886]] [[5.40802333e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1854 \n",
      "Accuracy: 3949/10000 (39.49%)\n",
      "\n",
      "Round  44, Train average loss 1.626 Test accuracy 39.490\n",
      "[[130.86353886]] [[130.86176695]] [[8.04249562e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1825 \n",
      "Accuracy: 3949/10000 (39.49%)\n",
      "\n",
      "Round  45, Train average loss 1.624 Test accuracy 39.490\n",
      "[[130.86176695]] [[130.86032812]] [[4.3109453e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1824 \n",
      "Accuracy: 3935/10000 (39.35%)\n",
      "\n",
      "Round  46, Train average loss 1.622 Test accuracy 39.350\n",
      "[[130.86032812]] [[130.85897359]] [[6.04587027e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1782 \n",
      "Accuracy: 3942/10000 (39.42%)\n",
      "\n",
      "Round  47, Train average loss 1.622 Test accuracy 39.420\n",
      "[[130.85897359]] [[130.85777428]] [[4.1127021e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1761 \n",
      "Accuracy: 3944/10000 (39.44%)\n",
      "\n",
      "Round  48, Train average loss 1.619 Test accuracy 39.440\n",
      "[[130.85777428]] [[130.85652834]] [[4.25202562e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1765 \n",
      "Accuracy: 3933/10000 (39.33%)\n",
      "\n",
      "Round  49, Train average loss 1.617 Test accuracy 39.330\n",
      "[[130.85652834]] [[130.85547715]] [[4.41068226e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1759 \n",
      "Accuracy: 3945/10000 (39.45%)\n",
      "\n",
      "Round  50, Train average loss 1.618 Test accuracy 39.450\n",
      "[[130.85547715]] [[130.85413878]] [[5.4094201e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1762 \n",
      "Accuracy: 3931/10000 (39.31%)\n",
      "\n",
      "Round  51, Train average loss 1.618 Test accuracy 39.310\n",
      "[[130.85413878]] [[130.85263178]] [[3.33096728e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1737 \n",
      "Accuracy: 3936/10000 (39.36%)\n",
      "\n",
      "Round  52, Train average loss 1.619 Test accuracy 39.360\n",
      "[[130.85263178]] [[130.85138218]] [[2.34865759e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1738 \n",
      "Accuracy: 3933/10000 (39.33%)\n",
      "\n",
      "Round  53, Train average loss 1.617 Test accuracy 39.330\n",
      "[[130.85138218]] [[130.84983381]] [[3.12558338e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1717 \n",
      "Accuracy: 3941/10000 (39.41%)\n",
      "\n",
      "Round  54, Train average loss 1.617 Test accuracy 39.410\n",
      "[[130.84983381]] [[130.84836424]] [[7.5507182e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1710 \n",
      "Accuracy: 3930/10000 (39.30%)\n",
      "\n",
      "Round  55, Train average loss 1.615 Test accuracy 39.300\n",
      "[[130.84836424]] [[130.84696926]] [[3.45924328e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1688 \n",
      "Accuracy: 3946/10000 (39.46%)\n",
      "\n",
      "Round  56, Train average loss 1.614 Test accuracy 39.460\n",
      "[[130.84696926]] [[130.84579144]] [[4.36078655e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1688 \n",
      "Accuracy: 3948/10000 (39.48%)\n",
      "\n",
      "Round  57, Train average loss 1.613 Test accuracy 39.480\n",
      "[[130.84579144]] [[130.84442044]] [[2.94183775e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1688 \n",
      "Accuracy: 3951/10000 (39.51%)\n",
      "\n",
      "Round  58, Train average loss 1.612 Test accuracy 39.510\n",
      "[[130.84442044]] [[130.84294583]] [[4.84257496e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1675 \n",
      "Accuracy: 3951/10000 (39.51%)\n",
      "\n",
      "Round  59, Train average loss 1.613 Test accuracy 39.510\n",
      "[[130.84294583]] [[130.84197864]] [[7.53348686e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1671 \n",
      "Accuracy: 3947/10000 (39.47%)\n",
      "\n",
      "Round  60, Train average loss 1.612 Test accuracy 39.470\n",
      "[[130.84197864]] [[130.84068521]] [[2.84900935e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1667 \n",
      "Accuracy: 3935/10000 (39.35%)\n",
      "\n",
      "Round  61, Train average loss 1.612 Test accuracy 39.350\n",
      "[[130.84068521]] [[130.83957864]] [[1.81657554e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1679 \n",
      "Accuracy: 3958/10000 (39.58%)\n",
      "\n",
      "Round  62, Train average loss 1.612 Test accuracy 39.580\n",
      "[[130.83957864]] [[130.83794133]] [[3.29204599e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1665 \n",
      "Accuracy: 3938/10000 (39.38%)\n",
      "\n",
      "Round  63, Train average loss 1.612 Test accuracy 39.380\n",
      "[[130.83794133]] [[130.83661695]] [[4.23507603e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1670 \n",
      "Accuracy: 3937/10000 (39.37%)\n",
      "\n",
      "Round  64, Train average loss 1.612 Test accuracy 39.370\n",
      "[[130.83661695]] [[130.83523787]] [[5.01933605e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1653 \n",
      "Accuracy: 3949/10000 (39.49%)\n",
      "\n",
      "Round  65, Train average loss 1.612 Test accuracy 39.490\n",
      "[[130.83523787]] [[130.83379661]] [[5.54093317e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1654 \n",
      "Accuracy: 3932/10000 (39.32%)\n",
      "\n",
      "Round  66, Train average loss 1.610 Test accuracy 39.320\n",
      "[[130.83379661]] [[130.83232453]] [[4.98022307e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1641 \n",
      "Accuracy: 3939/10000 (39.39%)\n",
      "\n",
      "Round  67, Train average loss 1.610 Test accuracy 39.390\n",
      "[[130.83232453]] [[130.83111441]] [[2.56341089e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1648 \n",
      "Accuracy: 3928/10000 (39.28%)\n",
      "\n",
      "Round  68, Train average loss 1.610 Test accuracy 39.280\n",
      "[[130.83111441]] [[130.82972577]] [[4.22357872e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1635 \n",
      "Accuracy: 3940/10000 (39.40%)\n",
      "\n",
      "Round  69, Train average loss 1.610 Test accuracy 39.400\n",
      "[[130.82972577]] [[130.82825326]] [[3.41918417e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1627 \n",
      "Accuracy: 3936/10000 (39.36%)\n",
      "\n",
      "Round  70, Train average loss 1.609 Test accuracy 39.360\n",
      "[[130.82825326]] [[130.82721317]] [[2.57391286e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1629 \n",
      "Accuracy: 3946/10000 (39.46%)\n",
      "\n",
      "Round  71, Train average loss 1.609 Test accuracy 39.460\n",
      "[[130.82721317]] [[130.8261413]] [[2.83977304e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1642 \n",
      "Accuracy: 3959/10000 (39.59%)\n",
      "\n",
      "Round  72, Train average loss 1.609 Test accuracy 39.590\n",
      "[[130.8261413]] [[130.82493763]] [[3.8001044e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1630 \n",
      "Accuracy: 3944/10000 (39.44%)\n",
      "\n",
      "Round  73, Train average loss 1.610 Test accuracy 39.440\n",
      "[[130.82493763]] [[130.82368775]] [[2.58534832e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1626 \n",
      "Accuracy: 3960/10000 (39.60%)\n",
      "\n",
      "Round  74, Train average loss 1.609 Test accuracy 39.600\n",
      "[[130.82368775]] [[130.82236637]] [[4.02051076e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1628 \n",
      "Accuracy: 3939/10000 (39.39%)\n",
      "\n",
      "Round  75, Train average loss 1.608 Test accuracy 39.390\n",
      "[[130.82236637]] [[130.82088502]] [[3.64925969e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1621 \n",
      "Accuracy: 3943/10000 (39.43%)\n",
      "\n",
      "Round  76, Train average loss 1.609 Test accuracy 39.430\n",
      "[[130.82088502]] [[130.81964985]] [[3.32600011e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1627 \n",
      "Accuracy: 3938/10000 (39.38%)\n",
      "\n",
      "Round  77, Train average loss 1.609 Test accuracy 39.380\n",
      "[[130.81964985]] [[130.81840992]] [[4.36005653e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1646 \n",
      "Accuracy: 3941/10000 (39.41%)\n",
      "\n",
      "Round  78, Train average loss 1.609 Test accuracy 39.410\n",
      "[[130.81840992]] [[130.81727521]] [[3.07271292e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1664 \n",
      "Accuracy: 3945/10000 (39.45%)\n",
      "\n",
      "Round  79, Train average loss 1.611 Test accuracy 39.450\n",
      "[[130.81727521]] [[130.81584721]] [[4.41245742e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1665 \n",
      "Accuracy: 3943/10000 (39.43%)\n",
      "\n",
      "Round  80, Train average loss 1.612 Test accuracy 39.430\n",
      "[[130.81584721]] [[130.81479142]] [[3.07150724e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1700 \n",
      "Accuracy: 3938/10000 (39.38%)\n",
      "\n",
      "Round  81, Train average loss 1.612 Test accuracy 39.380\n",
      "[[130.81479142]] [[130.81344167]] [[3.44076685e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1690 \n",
      "Accuracy: 3946/10000 (39.46%)\n",
      "\n",
      "Round  82, Train average loss 1.615 Test accuracy 39.460\n",
      "[[130.81344167]] [[130.81204253]] [[7.22881174e-07]]\n",
      "net_glob is updated !!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.1674 \n",
      "Accuracy: 3945/10000 (39.45%)\n",
      "\n",
      "Round  83, Train average loss 1.614 Test accuracy 39.450\n",
      "[[130.81204253]] [[130.81090359]] [[7.47117701e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1687 \n",
      "Accuracy: 3943/10000 (39.43%)\n",
      "\n",
      "Round  84, Train average loss 1.613 Test accuracy 39.430\n",
      "[[130.81090359]] [[130.80947871]] [[3.32539957e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1713 \n",
      "Accuracy: 3940/10000 (39.40%)\n",
      "\n",
      "Round  85, Train average loss 1.614 Test accuracy 39.400\n",
      "[[130.80947871]] [[130.80825191]] [[2.08430046e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1707 \n",
      "Accuracy: 3948/10000 (39.48%)\n",
      "\n",
      "Round  86, Train average loss 1.616 Test accuracy 39.480\n",
      "[[130.80825191]] [[130.80694388]] [[4.70651058e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1689 \n",
      "Accuracy: 3949/10000 (39.49%)\n",
      "\n",
      "Round  87, Train average loss 1.616 Test accuracy 39.490\n",
      "[[130.80694388]] [[130.80549743]] [[4.76495452e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1692 \n",
      "Accuracy: 3947/10000 (39.47%)\n",
      "\n",
      "Round  88, Train average loss 1.614 Test accuracy 39.470\n",
      "[[130.80549743]] [[130.80426254]] [[4.53967823e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1671 \n",
      "Accuracy: 3952/10000 (39.52%)\n",
      "\n",
      "Round  89, Train average loss 1.614 Test accuracy 39.520\n",
      "[[130.80426254]] [[130.80292553]] [[2.34104382e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1673 \n",
      "Accuracy: 3933/10000 (39.33%)\n",
      "\n",
      "Round  90, Train average loss 1.613 Test accuracy 39.330\n",
      "[[130.80292553]] [[130.80185609]] [[4.30833199e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1696 \n",
      "Accuracy: 3929/10000 (39.29%)\n",
      "\n",
      "Round  91, Train average loss 1.613 Test accuracy 39.290\n",
      "[[130.80185609]] [[130.8006129]] [[1.67768542e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1695 \n",
      "Accuracy: 3936/10000 (39.36%)\n",
      "\n",
      "Round  92, Train average loss 1.615 Test accuracy 39.360\n",
      "[[130.8006129]] [[130.79938722]] [[4.9941224e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1658 \n",
      "Accuracy: 3933/10000 (39.33%)\n",
      "\n",
      "Round  93, Train average loss 1.615 Test accuracy 39.330\n",
      "[[130.79938722]] [[130.7981765]] [[3.12036321e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1674 \n",
      "Accuracy: 3928/10000 (39.28%)\n",
      "\n",
      "Round  94, Train average loss 1.612 Test accuracy 39.280\n",
      "[[130.7981765]] [[130.79690687]] [[2.389966e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1663 \n",
      "Accuracy: 3938/10000 (39.38%)\n",
      "\n",
      "Round  95, Train average loss 1.613 Test accuracy 39.380\n",
      "[[130.79690687]] [[130.79536842]] [[3.31569773e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1616 \n",
      "Accuracy: 3929/10000 (39.29%)\n",
      "\n",
      "Round  96, Train average loss 1.612 Test accuracy 39.290\n",
      "[[130.79536842]] [[130.7936169]] [[1.07640267e-05]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1572 \n",
      "Accuracy: 3949/10000 (39.49%)\n",
      "\n",
      "Round  97, Train average loss 1.609 Test accuracy 39.490\n",
      "[[130.7936169]] [[130.7924425]] [[2.18674804e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1551 \n",
      "Accuracy: 3954/10000 (39.54%)\n",
      "\n",
      "Round  98, Train average loss 1.605 Test accuracy 39.540\n",
      "[[130.7924425]] [[130.79090268]] [[4.04258242e-06]]\n",
      "net_glob is updated !!\n",
      "\n",
      "Test set: Average loss: 2.1551 \n",
      "Accuracy: 3961/10000 (39.61%)\n",
      "\n",
      "Round  99, Train average loss 1.604 Test accuracy 39.610\n",
      "[[64.54312287]] [[7.08876014]] [[71.10798285]]\n",
      "[[64.54497895]] [[7.56560673]] [[54.60110006]]\n",
      "[[62.70939656]] [[6.79457527]] [[63.17819901]]\n",
      "[[61.98204255]] [[5.65483462]] [[57.43061786]]\n",
      "[[60.93813106]] [[26.56133529]] [[112.28694859]]\n",
      "[[63.67790434]] [[10.31897199]] [[40.3982355]]\n",
      "[[60.32082372]] [[7.19290438]] [[77.68227384]]\n",
      "[[61.3757257]] [[11.16167225]] [[92.67777866]]\n",
      "[[63.63226653]] [[8.10032085]] [[76.04701317]]\n",
      "[[64.09900805]] [[17.35948496]] [[106.27068566]]\n",
      "[[66.75594348]] [[9.99420062]] [[52.38296706]]\n",
      "[[64.29907362]] [[8.52794423]] [[67.90653418]]\n",
      "[[63.6995764]] [[7.86898882]] [[75.65405288]]\n",
      "[[64.18810352]] [[5.684551]] [[58.17211452]]\n",
      "[[62.8576501]] [[3.12743818]] [[69.69643499]]\n",
      "[[63.14645208]] [[2.95217523]] [[71.70453115]]\n",
      "[[63.68639051]] [[19.71316373]] [[114.02042848]]\n",
      "[[66.95937047]] [[4.19317667]] [[67.28653942]]\n",
      "[[66.50920758]] [[7.02476168]] [[92.25269269]]\n",
      "[[68.57945674]] [[8.67850468]] [[70.61883949]]\n",
      "[[67.8756766]] [[7.27671376]] [[103.60665153]]\n",
      "[[71.11247873]] [[7.72191984]] [[55.86546807]]\n",
      "[[68.59867872]] [[9.4598184]] [[77.48253573]]\n",
      "[[68.51047776]] [[8.30373151]] [[94.84610128]]\n",
      "[[70.56675398]] [[7.46859811]] [[96.78878824]]\n",
      "[[72.53850949]] [[10.58274555]] [[109.26328391]]\n",
      "[[75.28579984]] [[5.18277589]] [[51.51785119]]\n",
      "[[72.26689769]] [[3.86512644]] [[69.79019505]]\n",
      "[[71.72416773]] [[8.13918827]] [[101.48088829]]\n",
      "[[74.00302621]] [[10.95874415]] [[107.0046727]]\n",
      "[[76.57174639]] [[9.13077064]] [[99.44076728]]\n",
      "[[77.96312093]] [[5.10448935]] [[100.91172676]]\n",
      "[[79.89160348]] [[8.06216633]] [[88.91998167]]\n",
      "[[80.10199733]] [[7.85133158]] [[89.2322911]]\n",
      "[[80.22325956]] [[6.12934211]] [[81.83760874]]\n",
      "[[79.78298335]] [[6.98924939]] [[88.90994397]]\n",
      "[[79.82151961]] [[8.8387347]] [[65.24648335]]\n",
      "[[77.45719251]] [[3.26226894]] [[80.09023394]]\n",
      "[[77.40138837]] [[7.93743135]] [[104.32664735]]\n",
      "[[79.48874519]] [[20.00831089]] [[71.22732604]]\n",
      "[[76.90974043]] [[14.85745661]] [[59.34800229]]\n",
      "[[73.58713772]] [[7.71929689]] [[103.41513688]]\n",
      "[[76.03932132]] [[4.60732975]] [[78.6765402]]\n",
      "[[75.72935833]] [[10.59972573]] [[100.35600793]]\n",
      "[[77.30587207]] [[15.76329142]] [[74.50172457]]\n",
      "[[75.33426057]] [[8.44945279]] [[105.20124103]]\n",
      "[[77.68401713]] [[11.84990572]] [[113.84678078]]\n",
      "[[80.24582816]] [[8.06089612]] [[86.22195692]]\n",
      "[[79.9933415]] [[8.33397021]] [[105.60415681]]\n",
      "[[81.75443348]] [[8.64493724]] [[108.50701618]]\n",
      "[[83.67878667]] [[10.60246339]] [[107.84761189]]\n",
      "[[84.99690587]] [[6.52869587]] [[71.22841531]]\n",
      "[[82.88336791]] [[4.60336887]] [[75.64765508]]\n",
      "[[81.45665113]] [[6.12614342]] [[91.50073991]]\n",
      "[[82.07383211]] [[14.79940767]] [[115.03928357]]\n",
      "[[84.4570999]] [[6.78011683]] [[65.91751868]]\n",
      "[[81.72571793]] [[8.54714163]] [[110.88759286]]\n",
      "[[84.08962175]] [[5.76600199]] [[102.35203101]]\n",
      "[[85.40996005]] [[9.49144693]] [[56.00497337]]\n",
      "[[81.33391953]] [[14.76563425]] [[115.69431356]]\n",
      "[[83.1544095]] [[5.58405833]] [[86.66609913]]\n",
      "[[82.71725529]] [[3.56048805]] [[98.65755142]]\n",
      "[[83.98993227]] [[6.45241014]] [[93.66709696]]\n",
      "[[84.34827522]] [[8.30074901]] [[71.01021137]]\n",
      "[[82.07221803]] [[9.83789867]] [[84.89204521]]\n",
      "[[81.62933818]] [[10.86022901]] [[120.39754225]]\n",
      "[[84.65598301]] [[9.76123722]] [[73.17445089]]\n",
      "[[82.22384149]] [[5.02428535]] [[94.09264371]]\n",
      "[[82.81231079]] [[8.27821428]] [[56.85503943]]\n",
      "[[79.23907863]] [[6.70160098]] [[84.65968068]]\n",
      "[[79.30121278]] [[5.0448692]] [[83.67857563]]\n",
      "[[79.27666159]] [[5.56595516]] [[86.89683716]]\n",
      "[[79.58000247]] [[7.44820462]] [[93.30766618]]\n",
      "[[80.38568655]] [[5.06728271]] [[69.668353]]\n",
      "[[78.6956306]] [[7.88020108]] [[76.99883814]]\n",
      "[[77.37630239]] [[7.152549]] [[108.36409771]]\n",
      "[[79.97728409]] [[6.51896022]] [[55.5417723]]\n",
      "[[76.67015813]] [[8.54571081]] [[71.39211796]]\n",
      "[[74.96154229]] [[6.02251732]] [[71.61824386]]\n",
      "[[73.89527316]] [[8.64841655]] [[76.43220736]]\n",
      "[[73.28535948]] [[6.02015419]] [[74.25907202]]\n",
      "[[72.6485183]] [[6.74390303]] [[91.21592267]]\n",
      "[[73.94688529]] [[1.4168471]] [[71.11979748]]\n",
      "[[73.39111835]] [[14.64350695]] [[104.53932994]]\n",
      "[[75.39874835]] [[6.51778316]] [[58.61252577]]\n",
      "[[72.90499013]] [[4.08522889]] [[56.45752725]]\n",
      "[[70.84044671]] [[9.22476073]] [[103.83732417]]\n",
      "[[73.34471563]] [[9.33931086]] [[106.29157919]]\n",
      "[[75.98090358]] [[8.89776934]] [[66.69466501]]\n",
      "[[74.05541049]] [[4.58844589]] [[95.25793045]]\n",
      "[[75.90307977]] [[8.44433069]] [[70.00689864]]\n",
      "[[74.09977783]] [[3.28826342]] [[89.36488689]]\n",
      "[[75.25529467]] [[9.78847991]] [[109.67738976]]\n",
      "[[78.02366569]] [[6.11591189]] [[92.36895207]]\n",
      "[[78.93714078]] [[4.68433337]] [[56.30046001]]\n",
      "[[76.0926567]] [[6.49876756]] [[78.26020738]]\n",
      "[[75.70789615]] [[21.09749232]] [[85.9477401]]\n",
      "[[74.82403111]] [[4.28602616]] [[79.22027299]]\n",
      "(100, 40)\n",
      "[18. 12. 24. 21. 19. 16. 19. 25. 28. 23. 24. 19. 20. 26. 19. 20. 14. 23.\n",
      " 19. 15. 28. 13. 14. 18. 24. 18. 20. 21. 18. 19. 16. 23. 19. 23. 16. 22.\n",
      " 22. 17. 16. 29.]\n",
      "(40, 50)\n",
      "40\n",
      "[[77.40138837]] [[26.51954918]] [[38.96719322]]\n",
      "[[54.82949054]] [[28.50378829]] [[43.89257742]]\n",
      "[[60.90248163]] [[23.51248089]] [[35.35914827]]\n",
      "[[62.41042649]] [[32.10935028]] [[42.60264119]]\n",
      "[[81.49658186]] [[59.81841047]] [[55.39064123]]\n",
      "[[102.58160223]] [[47.50432546]] [[39.07586164]]\n",
      "[[61.17161724]] [[21.31606979]] [[29.68248263]]\n",
      "[[61.09529899]] [[47.66713743]] [[46.52117222]]\n",
      "[[98.39512304]] [[44.01073624]] [[44.97932381]]\n",
      "[[57.14713069]] [[31.65928006]] [[32.97253437]]\n",
      "[[55.07691678]] [[25.9365028]] [[27.25986021]]\n",
      "[[60.02909532]] [[36.96595889]] [[41.79561138]]\n",
      "[[82.18695659]] [[37.17017448]] [[49.67160581]]\n",
      "[[78.95197018]] [[37.63450098]] [[42.1483165]]\n",
      "[[94.79046373]] [[76.67313554]] [[1.84409546]]\n",
      "[[98.85299643]] [[36.07314158]] [[39.79067654]]\n",
      "[[55.78398651]] [[26.25051419]] [[49.40794988]]\n",
      "[[81.35977342]] [[34.9191317]] [[39.83395275]]\n",
      "[[62.85437246]] [[49.91524033]] [[38.3718102]]\n",
      "[[72.31082083]] [[35.28221236]] [[27.04298162]]\n",
      "[[56.18269529]] [[49.44703002]] [[51.73981425]]\n",
      "[[96.55459468]] [[44.13722945]] [[36.49147274]]\n",
      "[[81.76606612]] [[24.04069447]] [[63.17336968]]\n",
      "[[54.21028829]] [[25.65352396]] [[43.22390155]]\n",
      "[[96.80052852]] [[51.69404526]] [[35.44187177]]\n",
      "[[82.32773164]] [[48.40985036]] [[30.8003959]]\n",
      "[[87.25095811]] [[33.72774013]] [[45.17704973]]\n",
      "[[80.13191404]] [[20.75444114]] [[56.11563237]]\n",
      "[[60.41086407]] [[44.01139624]] [[64.23712153]]\n",
      "[[95.00792824]] [[46.39772441]] [[40.21957585]]\n",
      "[[80.88826861]] [[39.7378595]] [[50.56301005]]\n",
      "[[87.09049221]] [[41.75374192]] [[53.43230288]]\n",
      "[[70.29540207]] [[27.09337644]] [[29.26633406]]\n",
      "[[61.93491139]] [[27.10834777]] [[30.37122745]]\n",
      "[[67.47922684]] [[26.69562993]] [[40.87749288]]\n",
      "[[72.32458957]] [[43.12136352]] [[49.64002428]]\n",
      "[[95.29394262]] [[53.47141538]] [[41.84478503]]\n",
      "[[88.31613666]] [[33.33520362]] [[40.58203972]]\n",
      "[[60.55330045]] [[24.71292654]] [[47.30899926]]\n",
      "[[69.61080613]] [[24.71292654]] [[41.98881043]]\n",
      "\n",
      "\n",
      "[[79.9933415]] [[72.14421071]] [[1.7666377]]\n",
      "[[54.66054006]] [[52.85474663]] [[1.55960489]]\n",
      "[[64.32120095]] [[74.60861927]] [[1.17009442]]\n",
      "[[60.26073878]] [[57.01934141]] [[1.42087733]]\n",
      "[[84.21607922]] [[97.430861]] [[3.6097709]]\n",
      "[[100.69731358]] [[120.4546058]] [[5.76717759]]\n",
      "[[64.92258482]] [[54.03423475]] [[11.47821198]]\n",
      "[[65.51534049]] [[65.77550096]] [[1.4485558]]\n",
      "[[92.70453035]] [[105.93838527]] [[1.10241583]]\n",
      "[[60.84057893]] [[69.75180499]] [[1.48162866]]\n",
      "[[54.66123605]] [[62.50941354]] [[2.62955724]]\n",
      "[[58.30959357]] [[65.75099373]] [[1.1194627]]\n",
      "[[78.58026909]] [[88.25513846]] [[2.00990362]]\n",
      "[[81.96246562]] [[79.40958876]] [[2.58886666]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[89.67429957]] [[63.49149079]] [[3.85065238]]\n",
      "[[93.66718018]] [[92.5743847]] [[1.0236677]]\n",
      "[[55.61978852]] [[51.44982584]] [[3.15783009]]\n",
      "[[84.15703747]] [[86.84331962]] [[0.98513798]]\n",
      "[[60.7931714]] [[65.48420448]] [[0.62778028]]\n",
      "[[73.99048513]] [[107.23125445]] [[9.3166131]]\n",
      "[[60.54181121]] [[56.87797312]] [[4.77183194]]\n",
      "[[94.76899819]] [[123.39512748]] [[5.75341667]]\n",
      "[[72.57501318]] [[55.7106807]] [[9.38539037]]\n",
      "[[53.63415169]] [[59.62727488]] [[4.49627261]]\n",
      "[[95.02044159]] [[93.51545821]] [[5.04852903]]\n",
      "[[73.23501852]] [[101.81389258]] [[4.91627734]]\n",
      "[[83.27428558]] [[71.39224184]] [[8.16270621]]\n",
      "[[71.42505971]] [[50.81032842]] [[7.12186231]]\n",
      "[[64.80558614]] [[49.56988249]] [[9.70929959]]\n",
      "[[93.11238685]] [[110.02897648]] [[6.43233996]]\n",
      "[[71.8345607]] [[61.32232354]] [[3.82208978]]\n",
      "[[83.07292912]] [[87.3370908]] [[2.38346929]]\n",
      "[[72.01761681]] [[87.66717766]] [[2.70514916]]\n",
      "[[66.57393884]] [[51.88205182]] [[1.90956443]]\n",
      "[[65.39260443]] [[53.15421916]] [[5.42902659]]\n",
      "[[74.08092182]] [[74.6188736]] [[0.93718981]]\n",
      "[[90.30915663]] [[115.18109535]] [[3.4383451]]\n",
      "[[84.40161675]] [[85.11900197]] [[0.39760786]]\n",
      "[[64.27398472]] [[54.37932329]] [[2.01112792]]\n",
      "[[71.43011986]] [[71.72620374]] [[6.54145629]]\n",
      "0.5763521090151955\n",
      "0.052744638327808555\n",
      "10.927217007976436\n"
     ]
    }
   ],
   "source": [
    "p = 0\n",
    "N = 40\n",
    "K = 8\n",
    "\n",
    "args.local_ep=1\n",
    "\n",
    "N_trials = 1\n",
    "Max_iter = 100\n",
    "\n",
    "lr_array = [0.01]\n",
    "\n",
    "\n",
    "starting_iter_array = [599, 799, 999]\n",
    "\n",
    "recon_array_proposed = []\n",
    "recon_array_random = []\n",
    "\n",
    "gain_array = []\n",
    "\n",
    "for ii in range(len(starting_iter_array)):\n",
    "    starting_iter = starting_iter_array[ii]\n",
    "\n",
    "\n",
    "\n",
    "    net_glob = CNNCifar(args)\n",
    "    net_glob = net_glob.cuda()\n",
    "\n",
    "    PATH = \"./save_models/CIFAR10_NonIID_CNN_N40_K8_net_glob_iter\"+str(starting_iter)\n",
    "    net_glob.load_state_dict(torch.load(PATH))\n",
    "    net_glob.eval()\n",
    "\n",
    "    acc_test, loss_test = test_img(net_glob, dataset_test, args)\n",
    "\n",
    "\n",
    "    acc_test_arr_v2  = np.zeros((len(lr_array), N_trials, Max_iter))\n",
    "    loss_test_arr_v2 = np.zeros((len(lr_array), N_trials, Max_iter))\n",
    "\n",
    "\n",
    "\n",
    "    P_random = []\n",
    "\n",
    "\n",
    "    for trial_idx in range(N_trials):\n",
    "\n",
    "\n",
    "        for lr_idx in range(len(lr_array)):\n",
    "\n",
    "            print()\n",
    "            print('Learning Rate =',args.lr)\n",
    "            print()\n",
    "    #         net_glob = CNNMnist2(args)\n",
    "    #         net_glob = net_glob.cuda()\n",
    "    #         print(net_glob)\n",
    "\n",
    "            net_glob.train()\n",
    "\n",
    "            # copy weights\n",
    "            w_glob = net_glob.state_dict()\n",
    "\n",
    "    #         w_glob_array = []\n",
    "    #         w_locals_array = []\n",
    "\n",
    "            w_locals_array_np_v2 = np.zeros((Max_iter,N,d))\n",
    "            w_glob_array_np_v2 = np.zeros((Max_iter,d))\n",
    "\n",
    "            w_glob_array = []\n",
    "\n",
    "            for iter in range(Max_iter): #args.epochs\n",
    "\n",
    "                args.lr = lr_array[lr_idx]/(starting_iter)\n",
    "    #             if iter >= 200:\n",
    "    #                 args.lr = lr_array[lr_idx] * 0.1\n",
    "    #             elif iter >= 300:\n",
    "    #                 args.lr = lr_array[lr_idx] * 0.01\n",
    "\n",
    "                w_locals, loss_locals = [], []\n",
    "                w_locals_all = []\n",
    "\n",
    "    # #             u = np.random.binomial(1, 1-p, size=(N))\n",
    "    #             u = np.ones((N,))\n",
    "    #             for u_idx in range(N):\n",
    "    #                 p_sel = p_per_user[u_idx]\n",
    "    #                 u[u_idx] = np.random.binomial(1, 1-p_sel, size=1)[0]\n",
    "\n",
    "    #             result = np.where(u == 1)\n",
    "\n",
    "                ###############################\n",
    "                # 1. Random Selection\n",
    "                ###############################\n",
    "                idxs_users = np.random.choice(N, K, replace=False)\n",
    "\n",
    "                p_tmp = np.zeros(N)\n",
    "                p_tmp[idxs_users] = 1\n",
    "\n",
    "                P_random.append(p_tmp)\n",
    "\n",
    "    #             print('Learning Rate =',args.lr)\n",
    "            #     idxs_users = np.random.choice(range(N), K, replace=False)\n",
    "                for idx in range(N):\n",
    "            #         print(idx)\n",
    "                    local = LocalUpdate(args=args, dataset=dataset_train, idxs=dict_users[idx])\n",
    "                    w, loss = local.train(net=copy.deepcopy(net_glob).to(args.device))\n",
    "\n",
    "                    w_locals_all.append(copy.deepcopy(w))\n",
    "                    loss_locals.append(copy.deepcopy(loss))\n",
    "\n",
    "                    if idx in idxs_users:\n",
    "                        w_locals.append(copy.deepcopy(w))\n",
    "\n",
    "                    stt_pos = 0\n",
    "                    for k in w.keys():\n",
    "                        tmp1 = w[k].cpu().detach().numpy()\n",
    "                        cur_shape = tmp1.shape\n",
    "                        _d = np.prod(cur_shape)\n",
    "\n",
    "                        end_pos = stt_pos + _d\n",
    "\n",
    "    #                     w_glob_array_np[iter,stt_pos:end_pos] = np.reshape(tmp1,(_d,))        \n",
    "\n",
    "\n",
    "                        w_locals_array_np_v2[iter,idx,stt_pos:end_pos] = np.reshape(tmp1,(_d,))\n",
    "\n",
    "                        stt_pos = end_pos\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # update global weights\n",
    "                w_glob = FedAvg(w_locals)\n",
    "\n",
    "\n",
    "                stt_pos = 0\n",
    "                for k in w_glob.keys():\n",
    "                    tmp2 = w_glob[k].cpu().detach().numpy()\n",
    "                    cur_shape = tmp2.shape\n",
    "                    _d = np.prod(cur_shape)\n",
    "\n",
    "                    end_pos = stt_pos + _d\n",
    "\n",
    "    #                 print(_d, stt_pose, end_pos)\n",
    "\n",
    "                    w_glob_array_np_v2[iter,stt_pos:end_pos] = np.reshape(tmp2,(_d,))\n",
    "\n",
    "                    stt_pos = end_pos\n",
    "\n",
    "\n",
    "    #             w_locals_array.append(w_locals_all)\n",
    "                w_glob_array.append(w_glob)\n",
    "\n",
    "                ModelDiff_tensor(net_glob.state_dict(), w_glob_array[iter])     \n",
    "\n",
    "                # copy weight to net_glob\n",
    "                if iter < 1000:\n",
    "                    print('net_glob is updated !!')\n",
    "                    net_glob.load_state_dict(w_glob)\n",
    "    #             else:\n",
    "    #                 net_glob.load_state_dict(w_glob_prev)\n",
    "\n",
    "                # print loss\n",
    "                loss_avg = sum(loss_locals) / len(loss_locals)\n",
    "\n",
    "        #         loss_train.append(loss_avg)\n",
    "\n",
    "                acc_test, loss_test = test_img(net_glob, dataset_test, args)\n",
    "                acc_test_arr_v2[lr_idx][trial_idx][iter]  = acc_test\n",
    "                loss_test_arr_v2[lr_idx][trial_idx][iter] = loss_test\n",
    "                if iter % 1 ==0:\n",
    "                    print('Round {:3d}, Train average loss {:.3f} Test accuracy {:.3f}'.format(iter, loss_avg,acc_test))\n",
    "                #print(loss_train)\n",
    "\n",
    "#                 if iter % 100 == 99:\n",
    "#                     PATH = \"./save_models/MNIST_NonIID_CNN_N40_K8_net_glob_iter\"+str(1400+iter)\n",
    "#                     torch.save(net_glob.state_dict(), PATH)\n",
    "                    \n",
    "    grad_locals_array_np_v2 = np.zeros((100,N,d))\n",
    "    grad_glob_array_np_v2 = np.zeros((100,d))\n",
    "\n",
    "    for i in range(1, 99):\n",
    "    #     print(i)\n",
    "        grad_locals_array_np_v2[i+1,:,:] = (w_locals_array_np_v2[i,:,:] - w_glob_array_np_v2[i-1,:])*1400\n",
    "\n",
    "        grad_glob_array_np_v2[i-1,:] = (w_glob_array_np_v2[i,:] - w_glob_array_np_v2[i-1,:])*1400\n",
    "\n",
    "        ModelDiff_np(grad_locals_array_np_v2[i+1,0,:], grad_glob_array_np_v2[i-1,:])\n",
    "        \n",
    "    P_random = np.array(P_random)\n",
    "\n",
    "    print(np.shape(P_random))\n",
    "\n",
    "    print(np.sum(P_random, axis=0))\n",
    "    \n",
    "    # Pseudo Inversion\n",
    "\n",
    "    offset = 1\n",
    "    P_random_tmp = P_random[40+offset:90+offset,:]\n",
    "\n",
    "    PT = P_random_tmp.transpose()\n",
    "\n",
    "    print(np.shape(PT))\n",
    "\n",
    "    PTP = np.matmul(P_random_tmp.transpose(), P_random_tmp)\n",
    "\n",
    "    print(np.linalg.matrix_rank(PTP))\n",
    "\n",
    "    PTP_inv=np.linalg.pinv(PTP)\n",
    "\n",
    "\n",
    "    # print(np.shape(PT), np.shape(w_glob_array_np[10:60,:]))\n",
    "    Pw_glob = np.matmul(PT, grad_glob_array_np_v2[40:90,:])\n",
    "    grad_recon_np = K * np.matmul(PTP_inv, Pw_glob)\n",
    "\n",
    "    # ModelDiff_np(w_locals_array_np[-1,1,:], w_recon_np[1])\n",
    "    l2_diff = np.zeros((N))\n",
    "    l2_diff_ = np.zeros((N))\n",
    "    for i in range(N):\n",
    "        if i == N-1:\n",
    "            l2_diff_[i] = ModelDiff_np(grad_locals_array_np_v2[40,i,:], (grad_recon_np[i-1]+grad_recon_np[i])/2)\n",
    "        else:\n",
    "            l2_diff_[i] = ModelDiff_np(grad_locals_array_np_v2[40,i,:], (grad_recon_np[i]+grad_recon_np[i+1])/2)\n",
    "    print()\n",
    "    print()\n",
    "    for i in range(N):\n",
    "        l2_diff[i] = ModelDiff_np(grad_locals_array_np_v2[50,i,:], (grad_recon_np[i]))\n",
    "        \n",
    "    gain = np.sum(l2_diff_)/np.sum(l2_diff)\n",
    "\n",
    "    print(np.sum(l2_diff_)/N)\n",
    "    print(np.sum(l2_diff)/N)\n",
    "\n",
    "    print(np.sum(l2_diff_)/np.sum(l2_diff))\n",
    "    \n",
    "    recon_array_proposed.append(l2_diff_)\n",
    "    \n",
    "    recon_array_random.append(l2_diff)\n",
    "    \n",
    "    gain_array.append(gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
